{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0cbIaeP9pX07"
   },
   "source": [
    "# Natural Language Processing - Assignment 2\n",
    "# Sentiment analysis for movie reviews\n",
    "\n",
    "This notebook was created for you to answer question 2, 3 and 4 from assignment 2. Please read the steps and the provided code carefully and make sure you understand them. \n",
    "\n",
    "The (red) comments at the beginning of each function explain what they should do, which parameters you should give as input and which variables should be returned by the function. After the (green) comments \"### student code here###' you should write your own code.\n",
    "\n",
    "**Please modify the next cell specifying your group number**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_hIJFbDA1Qbi"
   },
   "source": [
    " *This is the Notebook of* ***Group 0*** \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CQfxb4pUNs1-"
   },
   "source": [
    "### Prerequisite - Libraries\n",
    "Make sure you have the needed libraries installed on your computer: scikit-learn, Pandas, NLTK..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3KiI6RyOpX08"
   },
   "source": [
    "### Prerequisite - Load Data\n",
    "\n",
    "In the first step, we are going to load the data in a Pandas DataFrame. Pandas DataFrames are a useful way of storing data. DataFrames are tables in which data can be accessed as columns, as rows or as individual cells. You can find more info on DataFrames here: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html\n",
    "\n",
    "Read the code below and make sure you understand what is happening. Run the code to load your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "hX1AE_fJpX09"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "### student code here: import the needed modules from sci-kit learn ###\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "eazU-uYcpX1B"
   },
   "outputs": [],
   "source": [
    "def get_path(filename):\n",
    "    \"\"\"\n",
    "    Makes a list of all the paths that fit the search requirement\n",
    "\n",
    "    :param filename: A regular expression that defines the search requirement for the filenames\n",
    "    :return  Returns a list of all the pathnames\n",
    "    \"\"\"\n",
    "    # place the movies folder in the same directory as this notebook\n",
    "    current_directory = os.getcwd()\n",
    "    # if you are using Google Colab, you will have to change the above line\n",
    "    # to load the dataset from your Google Drive\n",
    "\n",
    "    # glob.glob() is a pattern-matching path finder, it searches for the reviews in the movies folder based on a Regular Expression\n",
    "    paths = glob.glob(current_directory + '/movies/' + filename)\n",
    "\n",
    "    if len(paths) == 0:\n",
    "        print('Your file list is empty. The code looks for the folder '+current_directory+'/movies, but could not find it.')\n",
    "    else:\n",
    "        print(\"Found \", len(paths), \"files\")\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "RrcOjEdSpX1E"
   },
   "outputs": [],
   "source": [
    "def load_data(pathset):\n",
    "    \"\"\"\n",
    "    Loads the data into a dataframe\n",
    "\n",
    "    :param pathset:  A list of paths\n",
    "    :return  A dataframe with three columns: Path, Review (Text) and Label\n",
    "    \"\"\"\n",
    "    # Files are named by sentiment (P for positive, N for negative)\n",
    "    pattern = re.compile('P-(train|test)[0-9]*.txt')\n",
    "    reviews = []\n",
    "    labels = []\n",
    "    df = pd.DataFrame(columns = ['Path', 'Review', 'Label'])\n",
    "    for path in pathset:\n",
    "        if re.search(pattern, path):\n",
    "            text = open(path, \"r\").read()\n",
    "            reviews.append(text)\n",
    "            labels.append('Pos')\n",
    "        else:\n",
    "            text = open(path, \"r\").read()\n",
    "            reviews.append(text)\n",
    "            labels.append('Neg')\n",
    "    df['Path'] = pathset\n",
    "    df['Review'] = reviews\n",
    "    df['Label'] = labels\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "cvGgLWN_pX1G"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found  1200 files\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Review</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/kornelovics/EIT/UT/NLP/project-nlp/home...</td>\n",
       "      <td>Let's see, cardboard characters like Muslim te...</td>\n",
       "      <td>Neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/kornelovics/EIT/UT/NLP/project-nlp/home...</td>\n",
       "      <td>\"May contain spoilers\" Sadly Lou Costellos' la...</td>\n",
       "      <td>Neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/kornelovics/EIT/UT/NLP/project-nlp/home...</td>\n",
       "      <td>I can't emphasize it enough, do *NOT* get this...</td>\n",
       "      <td>Neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/kornelovics/EIT/UT/NLP/project-nlp/home...</td>\n",
       "      <td>I am truly sad that this is the first bad revi...</td>\n",
       "      <td>Neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/kornelovics/EIT/UT/NLP/project-nlp/home...</td>\n",
       "      <td>I'm a Petty Officer 1st Class (E-6) and have b...</td>\n",
       "      <td>Pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Path  \\\n",
       "0  /Users/kornelovics/EIT/UT/NLP/project-nlp/home...   \n",
       "1  /Users/kornelovics/EIT/UT/NLP/project-nlp/home...   \n",
       "2  /Users/kornelovics/EIT/UT/NLP/project-nlp/home...   \n",
       "3  /Users/kornelovics/EIT/UT/NLP/project-nlp/home...   \n",
       "4  /Users/kornelovics/EIT/UT/NLP/project-nlp/home...   \n",
       "\n",
       "                                              Review Label  \n",
       "0  Let's see, cardboard characters like Muslim te...   Neg  \n",
       "1  \"May contain spoilers\" Sadly Lou Costellos' la...   Neg  \n",
       "2  I can't emphasize it enough, do *NOT* get this...   Neg  \n",
       "3  I am truly sad that this is the first bad revi...   Neg  \n",
       "4  I'm a Petty Officer 1st Class (E-6) and have b...   Pos  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the files in the Dataframe. This will take a while...\n",
    "paths = get_path('train/[NP]-train[0-9]*.txt')\n",
    "data = load_data(paths)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zRRamA_8pX1K"
   },
   "source": [
    "### Part 2 - Tokenization\n",
    "\n",
    "In this step, you should write a tokenizer and compare it with an off-the-shelf one.\n",
    "\n",
    "#### Question 2.1 Making your own tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "UkZwy1ATNs2F"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['if', 'you', 'have', 'the', 'chance', ',', 'watch', 'it', '.', 'although', ',', 'a', 'warning', ',', \"you'll\", 'cry', 'your', 'eyes', 'out', '.']\n",
      "['kaas', 'is', 'lekker']\n",
      "['me', 'and', 'my', 'bestfriend', 'are', 'going', 'to', 'the', 'city', '!']\n",
      "['me', 'and', 'my', 'number', '3', 'bestfriend', 'like', 'movies']\n"
     ]
    }
   ],
   "source": [
    "def my_tokenizer(text):\n",
    "    \"\"\"\n",
    "    The implementation of your own tokenizer\n",
    "\n",
    "    :param text:  A string with a sentence (or paragraph, or document...)\n",
    "    :return  A list of tokens\n",
    "    \"\"\"\n",
    "    ### student code here ###\n",
    "\n",
    "\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Split on whitespace and punctuation using regex\n",
    "    # This pattern keeps letters, digits, and apostrophes together\n",
    "    tokens = re.findall(r\"[a-zA-Z0-9']+|[.,!?;]\", text)\n",
    "\n",
    "    # Remove empty strings\n",
    "    tokens = [token for token in tokens if token.strip()]\n",
    "\n",
    "    return tokens\n",
    "\n",
    "sample_string0 = \"If you have the chance, watch it. Although, a warning, you'll cry your eyes out.\"\n",
    "sample_string1 = \"kaas is lekker\"\n",
    "sample_string2 = \"Me and My bEstfriend are going to the city!\"\n",
    "sample_string3 = \"me and my number 3 bEStfrienD like movies\"\n",
    "print(my_tokenizer(sample_string0))\n",
    "print(my_tokenizer(sample_string1))\n",
    "print(my_tokenizer(sample_string2))\n",
    "print(my_tokenizer(sample_string3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6pxI0gdoNs2G"
   },
   "source": [
    "#### Question 2.2 Using an off-the-shelf tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "TXUTKVyqNs2H"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'like', 'this', 'assignment', 'because', 'it', 'is', 'fun', ';', 'it', 'helps', 'me', 'practice', 'my', 'python', 'skills', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/kornelovics/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'like', 'this', 'assignment', 'because', ':', '-', 'it', 'is', 'fun', ';', '-', 'it', 'helps', 'me', 'practice', 'my', 'Python', 'skills', '.']\n",
      "\n",
      "\n",
      "['i', 'won', 'a', 'prize', ',', 'but', 'i', \"won't\", 'be', 'able', 'to', 'attend', 'the', 'ceremony', '.']\n",
      "['I', 'won', 'a', 'prize', ',', 'but', 'I', 'wo', \"n't\", 'be', 'able', 'to', 'attend', 'the', 'ceremony', '.']\n",
      "\n",
      "\n",
      "['the', 'strange', 'case', 'of', 'dr', '.', 'jekyll', 'and', 'mr', '.', 'hyde', 'is', 'a', 'famous', 'book', '.', '.', '.', 'but', 'i', \"haven't\", 'read', 'it', '.']\n",
      "['“', 'The', 'strange', 'case', 'of', 'Dr.', 'Jekyll', 'and', 'Mr.', 'Hyde', '”', 'is', 'a', 'famous', 'book', '...', 'but', 'I', 'have', \"n't\", 'read', 'it', '.']\n",
      "\n",
      "\n",
      "['i', 'work', 'for', 'the', 'c', '.', 'i', '.', 'a', '.', '.', 'and', 'you', '?']\n",
      "['I', 'work', 'for', 'the', 'C.I.A', '..', 'And', 'you', '?']\n",
      "\n",
      "\n",
      "['omg', 'twitter', 'is', 'sooooo', 'coooool', '3', 'lol', '.', '.', '.', 'why', 'do', 'i', 'write', 'like', 'this', 'idk', 'right', '?']\n",
      "['OMG', '#', 'Twitter', 'is', 'sooooo', 'coooool', '<', '3', ':', '-', ')', '<', '--', 'lol', '...', 'why', 'do', 'i', 'write', 'like', 'this', 'idk', 'right', '?', ':', ')', '🤷😂', '🤖']\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    }
   ],
   "source": [
    "#Now we are gonna compare the tokenizer you just wrote with the one from NLTK\n",
    "#if you installed NLTK but never downloaded the 'punkt' tokenizer, uncomment the following lines:\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def nltk_tokenizer(text):\n",
    "    \"\"\"\n",
    "    This function should apply the word_tokenize (punkt) tokenizer of nltk to the input text\n",
    "\n",
    "    :param text:  A string with a sentence (or paragraph, or document...)\n",
    "    :return  A list of tokens\n",
    "    \"\"\"\n",
    "    ### student code here ###\n",
    "    # Ensure required tokenizers are available\n",
    "    try:\n",
    "        nltk.data.find('tokenizers/punkt')\n",
    "    except LookupError:\n",
    "        nltk.download('punkt')\n",
    "\n",
    "    # Newer NLTK versions may also need 'punkt_tab'\n",
    "    try:\n",
    "        nltk.data.find('tokenizers/punkt_tab')\n",
    "    except LookupError:\n",
    "        try:\n",
    "            nltk.download('punkt_tab')\n",
    "        except:\n",
    "            pass  # It's optional on some versions\n",
    "\n",
    "    return word_tokenize(text)\n",
    "\n",
    "test_sentences = [\"I like this assignment because:\\n-\\tit is fun;\\n-\\tit helps me practice my Python skills.\",\n",
    "        \"I won a prize, but I won't be able to attend the ceremony.\",\n",
    "        \"“The strange case of Dr. Jekyll and Mr. Hyde” is a famous book... but I haven't read it.\",\n",
    "        \"I work for the C.I.A.. And you?\",\n",
    "        \"OMG #Twitter is sooooo coooool <3 :-) <-- lol...why do i write like this idk right? :) 🤷😂 🤖\"]\n",
    "\n",
    "for test_string in test_sentences:\n",
    "    print(my_tokenizer(test_string))\n",
    "    print(nltk_tokenizer(test_string))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NUrQ_8EbNs2N"
   },
   "source": [
    "### Part 3 - Text classification with a unigram language model\n",
    "\n",
    "#### Training phase\n",
    "You now need to create the model and train it on the documents in the dataframe. Look at the scikit learn documentation to learn how to use the CountVectorizer and MultimodalNaiveBayes modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tQMy8K-MNs2N"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOY CORPUS ANALYSIS\n",
      "==================================================\n",
      "\n",
      "POSITIVE CORPUS word counts:\n",
      "\n",
      "NEGATIVE CORPUS word counts:\n",
      "Total positive words: 43\n",
      "Total negative words: 34\n",
      "Positive vocabulary size: 32\n",
      "Negative vocabulary size: 27\n",
      "Combined vocabulary size (V): 49\n"
     ]
    }
   ],
   "source": [
    "# Part 2.1: Theory calculations with the toy corpus\n",
    "\n",
    "print(\"TOY CORPUS ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Given data from the homework\n",
    "print(\"\\nPOSITIVE CORPUS word counts:\")\n",
    "positive_words = {\n",
    "    'the': 5, 'a': 3, 'really': 2, 'plot': 2, 'movie': 2, 'great': 2, 'are': 2,\n",
    "    'actors': 1, 'all': 1, 'and': 1, 'can': 1, 'delivering': 1, 'director': 1,\n",
    "    'familiar': 1, 'I': 1, 'identify': 1, 'intriguing': 1, 'is': 1, 'like': 1,\n",
    "    'manages': 1, 'out': 1, 'performance': 1, 'story': 1, 'tell': 1, 'this': 1,\n",
    "    'thought': 1, 'to': 1, 'twists': 1, 'was': 1, 'we': 1, 'well': 1, 'with': 1\n",
    "}\n",
    "\n",
    "print(\"\\nNEGATIVE CORPUS word counts:\")\n",
    "negative_words = {\n",
    "    'a': 3, 'to': 2, 'not': 2, 'movie': 2, 'I': 2, 'boring': 2,\n",
    "    'actors': 1, 'again': 1, 'an': 1, 'are': 1, 'disappointing': 1,\n",
    "    'enough': 1, 'great': 1, 'had': 1, 'interesting': 1, 'once': 1,\n",
    "    'plot': 1, 'reminder': 1, 'see': 1, 'shoot': 1, 'terrible': 1,\n",
    "    'that': 1, 'this': 1, 'uninspiring': 1, 'wasted': 1, 'wish': 1, 'with': 1\n",
    "}\n",
    "\n",
    "# Calculate totals\n",
    "total_pos_words = sum(positive_words.values())\n",
    "total_neg_words = sum(negative_words.values())\n",
    "total_pos_vocab = len(positive_words)\n",
    "total_neg_vocab = len(negative_words)\n",
    "\n",
    "print(f\"Total positive words: {total_pos_words}\")\n",
    "print(f\"Total negative words: {total_neg_words}\")\n",
    "print(f\"Positive vocabulary size: {total_pos_vocab}\")\n",
    "print(f\"Negative vocabulary size: {total_neg_vocab}\")\n",
    "\n",
    "# Combined vocabulary for smoothing\n",
    "all_words = set(positive_words.keys()) | set(negative_words.keys())\n",
    "vocab_size = len(all_words)\n",
    "print(f\"Combined vocabulary size (V): {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION 1: Calculate P(boring|Pos) with Laplace smoothing\n",
      "============================================================\n",
      "Word: 'boring'\n",
      "Count of 'boring' in positive reviews: C('boring', Pos) = 0\n",
      "Total words in positive reviews: 43\n",
      "Vocabulary size (V): 49\n",
      "Laplace parameter (k): 1\n",
      "\n",
      "Formula: P('boring'|Pos) = (C('boring', Pos) + k) / (∑w C(w, Pos) + k*V)\n",
      "Formula: P('boring'|Pos) = (0 + 1) / (43 + 1*49)\n",
      "Formula: P('boring'|Pos) = 1 / 92\n",
      "Result: P('boring'|Pos) = 0.010870\n",
      "\n",
      "For comparison:\n",
      "P('boring'|Neg) = (2 + 1) / (34 + 1*49)\n",
      "P('boring'|Neg) = 3 / 83\n",
      "P('boring'|Neg) = 0.036145\n",
      "\n",
      "As expected, P(boring|Neg) > P(boring|Pos) since 'boring' appears in negative reviews!\n"
     ]
    }
   ],
   "source": [
    "# Calculate P(boring|Pos) using Laplace smoothing\n",
    "\n",
    "print(\"QUESTION 1: Calculate P(boring|Pos) with Laplace smoothing\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Formula: P(wi|Pos) = (C(wi, Pos) + k) / (sum of all positive words + k*V)\n",
    "# where k=1 for Laplace smoothing\n",
    "\n",
    "word = \"boring\"\n",
    "count_boring_pos = positive_words.get(word, 0)  # 0 since boring doesn't appear in positive\n",
    "k = 1  # Laplace smoothing parameter\n",
    "V = vocab_size  # Combined vocabulary size\n",
    "\n",
    "numerator = count_boring_pos + k\n",
    "denominator = total_pos_words + (k * V)\n",
    "\n",
    "prob_boring_pos = numerator / denominator\n",
    "\n",
    "print(f\"Word: '{word}'\")\n",
    "print(f\"Count of '{word}' in positive reviews: C('{word}', Pos) = {count_boring_pos}\")\n",
    "print(f\"Total words in positive reviews: {total_pos_words}\")\n",
    "print(f\"Vocabulary size (V): {V}\")\n",
    "print(f\"Laplace parameter (k): {k}\")\n",
    "print()\n",
    "print(f\"Formula: P('{word}'|Pos) = (C('{word}', Pos) + k) / (∑w C(w, Pos) + k*V)\")\n",
    "print(f\"Formula: P('{word}'|Pos) = ({count_boring_pos} + {k}) / ({total_pos_words} + {k}*{V})\")\n",
    "print(f\"Formula: P('{word}'|Pos) = {numerator} / {denominator}\")\n",
    "print(f\"Result: P('{word}'|Pos) = {prob_boring_pos:.6f}\")\n",
    "print()\n",
    "\n",
    "# Also calculate P(boring|Neg) for comparison\n",
    "count_boring_neg = negative_words.get(word, 0)\n",
    "numerator_neg = count_boring_neg + k\n",
    "denominator_neg = total_neg_words + (k * V)\n",
    "prob_boring_neg = numerator_neg / denominator_neg\n",
    "\n",
    "print(f\"For comparison:\")\n",
    "print(f\"P('{word}'|Neg) = ({count_boring_neg} + {k}) / ({total_neg_words} + {k}*{V})\")\n",
    "print(f\"P('{word}'|Neg) = {numerator_neg} / {denominator_neg}\")\n",
    "print(f\"P('{word}'|Neg) = {prob_boring_neg:.6f}\")\n",
    "print(f\"\\nAs expected, P(boring|Neg) > P(boring|Pos) since 'boring' appears in negative reviews!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION 2: Classify 'intriguing yet disappointing'\n",
      "============================================================\n",
      "Test sentence: 'intriguing yet disappointing'\n",
      "Words to analyze: ['intriguing', 'yet', 'disappointing']\n",
      "\n",
      "CALCULATING PROBABILITIES FOR EACH WORD:\n",
      "----------------------------------------\n",
      "Word: 'intriguing'\n",
      "  Count in Pos: 1, Count in Neg: 0\n",
      "  P('intriguing'|Pos) = 0.021739\n",
      "  P('intriguing'|Neg) = 0.012048\n",
      "\n",
      "Word: 'yet'\n",
      "  Count in Pos: 0, Count in Neg: 0\n",
      "  P('yet'|Pos) = 0.010870\n",
      "  P('yet'|Neg) = 0.012048\n",
      "\n",
      "Word: 'disappointing'\n",
      "  Count in Pos: 0, Count in Neg: 1\n",
      "  P('disappointing'|Pos) = 0.010870\n",
      "  P('disappointing'|Neg) = 0.024096\n",
      "\n",
      "FINAL SENTENCE PROBABILITIES:\n",
      "------------------------------\n",
      "P('intriguing yet disappointing'|Pos) = 0.0000025684\n",
      "P('intriguing yet disappointing'|Neg) = 0.0000034978\n",
      "\n",
      "CLASSIFICATION: NEGATIVE\n",
      "Confidence: 57.66%\n",
      "\n",
      "Reasoning: Since P(sentence|NEG) > P(sentence|POS),\n",
      "the sentence is classified as NEGATIVE.\n"
     ]
    }
   ],
   "source": [
    "# Question 2: Classify \"intriguing yet disappointing\"\n",
    "\n",
    "print(\"QUESTION 2: Classify 'intriguing yet disappointing'\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "test_sentence = \"intriguing yet disappointing\"\n",
    "test_words = test_sentence.split()\n",
    "\n",
    "print(f\"Test sentence: '{test_sentence}'\")\n",
    "print(f\"Words to analyze: {test_words}\")\n",
    "print()\n",
    "\n",
    "# Calculate P(sentence|Pos) and P(sentence|Neg)\n",
    "# For unigram model: P(w1, w2, ..., wn|Class) = ∏ P(wi|Class)\n",
    "\n",
    "def calculate_word_probability(word, word_counts, total_words, vocab_size, k=1):\n",
    "    \"\"\"Calculate P(word|Class) with Laplace smoothing\"\"\"\n",
    "    count = word_counts.get(word, 0)\n",
    "    return (count + k) / (total_words + k * vocab_size)\n",
    "\n",
    "print(\"CALCULATING PROBABILITIES FOR EACH WORD:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "prob_pos_total = 1.0  # Start with 1 for multiplication\n",
    "prob_neg_total = 1.0\n",
    "\n",
    "for word in test_words:\n",
    "    # Calculate P(word|Pos)\n",
    "    prob_word_pos = calculate_word_probability(word, positive_words, total_pos_words, vocab_size)\n",
    "    # Calculate P(word|Neg)\n",
    "    prob_word_neg = calculate_word_probability(word, negative_words, total_neg_words, vocab_size)\n",
    "\n",
    "    print(f\"Word: '{word}'\")\n",
    "    print(f\"  Count in Pos: {positive_words.get(word, 0)}, Count in Neg: {negative_words.get(word, 0)}\")\n",
    "    print(f\"  P('{word}'|Pos) = {prob_word_pos:.6f}\")\n",
    "    print(f\"  P('{word}'|Neg) = {prob_word_neg:.6f}\")\n",
    "\n",
    "    # Multiply for unigram independence assumption\n",
    "    prob_pos_total *= prob_word_pos\n",
    "    prob_neg_total *= prob_word_neg\n",
    "    print()\n",
    "\n",
    "print(\"FINAL SENTENCE PROBABILITIES:\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"P('{test_sentence}'|Pos) = {prob_pos_total:.10f}\")\n",
    "print(f\"P('{test_sentence}'|Neg) = {prob_neg_total:.10f}\")\n",
    "print()\n",
    "\n",
    "# Determine classification\n",
    "if prob_pos_total > prob_neg_total:\n",
    "    classification = \"POSITIVE\"\n",
    "    confidence = prob_pos_total / (prob_pos_total + prob_neg_total)\n",
    "else:\n",
    "    classification = \"NEGATIVE\"\n",
    "    confidence = prob_neg_total / (prob_pos_total + prob_neg_total)\n",
    "\n",
    "print(f\"CLASSIFICATION: {classification}\")\n",
    "print(f\"Confidence: {confidence:.2%}\")\n",
    "print()\n",
    "print(f\"Reasoning: Since P(sentence|{classification[:3]}) > P(sentence|{'POS' if classification=='NEGATIVE' else 'NEG'}),\")\n",
    "print(f\"the sentence is classified as {classification}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Found  1200 files\n",
      "Loaded 1200 training documents\n",
      "Feature matrix shape: (1200, 17952)\n",
      "Number of unique words: 17952\n",
      "Model trained successfully!\n"
     ]
    }
   ],
   "source": [
    "### Student code here ###\n",
    "\n",
    "# Load training data\n",
    "print(\"Loading training data...\")\n",
    "train_paths = get_path('train/[NP]-train[0-9]*.txt')\n",
    "train_data = load_data(train_paths)\n",
    "print(f\"Loaded {len(train_data)} training documents\")\n",
    "\n",
    "# Initialize CountVectorizer with default settings (includes lowercase normalization)\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Transform text data to numerical features\n",
    "X_train = vectorizer.fit_transform(train_data['Review'])\n",
    "y_train = train_data['Label']\n",
    "\n",
    "print(f\"Feature matrix shape: {X_train.shape}\")\n",
    "print(f\"Number of unique words: {len(vectorizer.vocabulary_)}\")\n",
    "\n",
    "# Train Naive Bayes classifier with Laplace smoothing (alpha=1.0)\n",
    "classifier = MultinomialNB(alpha=1.0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wrmIrKsbNs2O"
   },
   "source": [
    "#### Testing phase\n",
    "Now that you have a trained model, you need to test its performance.\n",
    "\n",
    "1. Load your test data.\n",
    "2. Classify your test data using the classifier you trained before.\n",
    "3. Compute the accuracy of your classifier on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "NNZtd9aqNs2O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test data...\n",
      "Found  100 files\n",
      "Loaded 100 test documents\n",
      "Accuracy with Laplace smoothing (k=1): 0.8400 (84.00%)\n",
      "\n",
      "Sample predictions:\n",
      "True: Pos, Predicted: Pos\n",
      "True: Neg, Predicted: Neg\n",
      "True: Neg, Predicted: Neg\n",
      "True: Pos, Predicted: Neg\n",
      "True: Pos, Predicted: Pos\n"
     ]
    }
   ],
   "source": [
    "# First, read all the test data from the files.\n",
    "# Then classify it using the classifier you trained before\n",
    "# Finally, calculate the performance\n",
    "### Student code here ###\n",
    "\n",
    "# Load test data\n",
    "print(\"Loading test data...\")\n",
    "test_paths = get_path('test/[NP]-test[0-9]*.txt')\n",
    "test_data = load_data(test_paths)\n",
    "print(f\"Loaded {len(test_data)} test documents\")\n",
    "\n",
    "# Transform test data using the same vectorizer\n",
    "X_test = vectorizer.transform(test_data['Review'])\n",
    "y_test = test_data['Label']\n",
    "\n",
    "# Make predictions\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy with Laplace smoothing (k=1): {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "\n",
    "# Show some example predictions\n",
    "print(\"\\nSample predictions:\")\n",
    "for i in range(5):\n",
    "    print(f\"True: {y_test.iloc[i]}, Predicted: {y_pred[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q2XPTWi1ytLW"
   },
   "source": [
    "Now train two more models: one without Laplace smoothing, and one where stopwords are removed. Then test them on the same test data, and compare the performance with the results you previously obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "H6antoDczL0U"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "COMPARISON EXPERIMENTS\n",
      "============================================================\n",
      "\n",
      "1. WITHOUT LAPLACE SMOOTHING (k=0):\n",
      "Accuracy without Laplace smoothing: 0.5000 (50.00%)\n",
      "\n",
      "2. WITH STOP WORDS REMOVED:\n",
      "Accuracy with stop words removed: 0.8500 (85.00%)\n",
      "\n",
      "3. WITHOUT LOWERCASE NORMALIZATION:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages/sklearn/naive_bayes.py:898: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = np.log(smoothed_fc) - np.log(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy without lowercase normalization: 0.8100 (81.00%)\n",
      "\n",
      "============================================================\n",
      "SUMMARY OF RESULTS:\n",
      "============================================================\n",
      "With Laplace smoothing (k=1):     0.8400 (84.00%)\n",
      "Without Laplace smoothing (k=0):  0.5000 (50.00%)\n",
      "With stop words removed:          0.8500 (85.00%)\n",
      "Without lowercase normalization:  0.8100 (81.00%)\n",
      "\n",
      "============================================================\n",
      "ANALYSIS:\n",
      "============================================================\n",
      "\n",
      "Laplace Smoothing Effect:\n",
      "✓ Laplace smoothing IMPROVED performance by 34.00 percentage points\n",
      "  This is expected because smoothing helps with unseen words in test data.\n",
      "\n",
      "Stop Words Effect:\n",
      "✓ Removing stop words IMPROVED performance by 1.00 percentage points\n",
      "  This suggests stop words were adding noise to the classification.\n",
      "\n",
      "Lowercase Normalization Effect:\n",
      "✗ Disabling lowercase normalization DECREASED performance by 3.00 percentage points\n",
      "  This suggests case normalization helps by reducing feature sparsity.\n"
     ]
    }
   ],
   "source": [
    "### Student code here ###\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"COMPARISON EXPERIMENTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Model without Laplace smoothing (alpha=0)\n",
    "print(\"\\n1. WITHOUT LAPLACE SMOOTHING (k=0):\")\n",
    "classifier_no_smooth = MultinomialNB(alpha=0.0)\n",
    "classifier_no_smooth.fit(X_train, y_train)\n",
    "y_pred_no_smooth = classifier_no_smooth.predict(X_test)\n",
    "accuracy_no_smooth = accuracy_score(y_test, y_pred_no_smooth)\n",
    "print(f\"Accuracy without Laplace smoothing: {accuracy_no_smooth:.4f} ({accuracy_no_smooth*100:.2f}%)\")\n",
    "\n",
    "# 2. Model with stop words removed\n",
    "print(\"\\n2. WITH STOP WORDS REMOVED:\")\n",
    "vectorizer_stop = CountVectorizer(stop_words='english')\n",
    "X_train_stop = vectorizer_stop.fit_transform(train_data['Review'])\n",
    "X_test_stop = vectorizer_stop.transform(test_data['Review'])\n",
    "\n",
    "classifier_stop = MultinomialNB(alpha=1.0)\n",
    "classifier_stop.fit(X_train_stop, y_train)\n",
    "y_pred_stop = classifier_stop.predict(X_test_stop)\n",
    "accuracy_stop = accuracy_score(y_test, y_pred_stop)\n",
    "print(f\"Accuracy with stop words removed: {accuracy_stop:.4f} ({accuracy_stop*100:.2f}%)\")\n",
    "\n",
    "# 3. Model without lowercase normalization\n",
    "print(\"\\n3. WITHOUT LOWERCASE NORMALIZATION:\")\n",
    "vectorizer_no_lower = CountVectorizer(lowercase=False)\n",
    "X_train_no_lower = vectorizer_no_lower.fit_transform(train_data['Review'])\n",
    "X_test_no_lower = vectorizer_no_lower.transform(test_data['Review'])\n",
    "\n",
    "classifier_no_lower = MultinomialNB(alpha=1.0)\n",
    "classifier_no_lower.fit(X_train_no_lower, y_train)\n",
    "y_pred_no_lower = classifier_no_lower.predict(X_test_no_lower)\n",
    "accuracy_no_lower = accuracy_score(y_test, y_pred_no_lower)\n",
    "print(f\"Accuracy without lowercase normalization: {accuracy_no_lower:.4f} ({accuracy_no_lower*100:.2f}%)\")\n",
    "\n",
    "# Summary comparison\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY OF RESULTS:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"With Laplace smoothing (k=1):     {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"Without Laplace smoothing (k=0):  {accuracy_no_smooth:.4f} ({accuracy_no_smooth*100:.2f}%)\")\n",
    "print(f\"With stop words removed:          {accuracy_stop:.4f} ({accuracy_stop*100:.2f}%)\")\n",
    "print(f\"Without lowercase normalization:  {accuracy_no_lower:.4f} ({accuracy_no_lower*100:.2f}%)\")\n",
    "\n",
    "# Analysis\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ANALYSIS:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nLaplace Smoothing Effect:\")\n",
    "if accuracy > accuracy_no_smooth:\n",
    "    print(f\"✓ Laplace smoothing IMPROVED performance by {((accuracy - accuracy_no_smooth)*100):.2f} percentage points\")\n",
    "    print(\"  This is expected because smoothing helps with unseen words in test data.\")\n",
    "else:\n",
    "    print(f\"✗ Laplace smoothing DECREASED performance by {((accuracy_no_smooth - accuracy)*100):.2f} percentage points\")\n",
    "\n",
    "print(f\"\\nStop Words Effect:\")\n",
    "if accuracy_stop > accuracy:\n",
    "    print(f\"✓ Removing stop words IMPROVED performance by {((accuracy_stop - accuracy)*100):.2f} percentage points\")\n",
    "    print(\"  This suggests stop words were adding noise to the classification.\")\n",
    "elif accuracy_stop < accuracy:\n",
    "    print(f\"✗ Removing stop words DECREASED performance by {((accuracy - accuracy_stop)*100):.2f} percentage points\")\n",
    "    print(\"  This suggests stop words contain useful information for sentiment classification.\")\n",
    "else:\n",
    "    print(\"= No significant difference in performance\")\n",
    "\n",
    "print(f\"\\nLowercase Normalization Effect:\")\n",
    "if accuracy_no_lower > accuracy:\n",
    "    print(f\"✓ Disabling lowercase normalization IMPROVED performance by {((accuracy_no_lower - accuracy)*100):.2f} percentage points\")\n",
    "    print(\"  This suggests case information is important for sentiment classification.\")\n",
    "elif accuracy_no_lower < accuracy:\n",
    "    print(f\"✗ Disabling lowercase normalization DECREASED performance by {((accuracy - accuracy_no_lower)*100):.2f} percentage points\")\n",
    "    print(\"  This suggests case normalization helps by reducing feature sparsity.\")\n",
    "else:\n",
    "    print(\"= No significant difference in performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tDCgEfYgNs2Q"
   },
   "source": [
    "### Part 4 - Text classification with a bigram language model\n",
    "\n",
    "Now we will classify the same dataset again, but this time with a bigram language model. \n",
    "\n",
    "#### Training phase\n",
    "Build a Naïve Bayes classifier that uses bigrams instead of single words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZSIam3ObNs2Q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PART 3.1: BIGRAM MODEL THEORY\n",
      "==================================================\n",
      "\n",
      "QUESTION 1: How to compute P(fi|+) when fi is a bigram?\n",
      "-------------------------------------------------------\n",
      "For a bigram fi = (wi-1, wi), we compute:\n",
      "P(fi|+) = P(wi|wi-1, +) = C(wi-1, wi, +) / C(wi-1, +)\n",
      "\n",
      "Where:\n",
      "- C(wi-1, wi, +) = count of bigram (wi-1, wi) in positive corpus\n",
      "- C(wi-1, +) = count of word wi-1 in positive corpus\n",
      "\n",
      "With Laplace smoothing:\n",
      "P(wi|wi-1, +) = (C(wi-1, wi, +) + k) / (C(wi-1, +) + k*V)\n",
      "where V is the vocabulary size and k=1 for Laplace smoothing\n",
      "\n",
      "QUESTION 2: Calculate specific bigram probabilities\n",
      "--------------------------------------------------\n",
      "Calculate P(movie|great) in positive corpus:\n",
      "  C('great movie', +) = 1\n",
      "  C('great', +) = 2\n",
      "  P(movie|great, +) = 1/2 = 0.500\n",
      "  With Laplace smoothing (V≈30): P(movie|great, +) = (1+1)/(2+1*30) = 0.062500\n",
      "\n",
      "Calculate P(enough|familiar) in positive corpus:\n",
      "  C('familiar enough', +) = 0\n",
      "  C('familiar', +) = 1\n",
      "  P(enough|familiar, +) = 0/1 = 0.000\n",
      "  With Laplace smoothing: P(enough|familiar, +) = (0+1)/(1+1*30) = 0.032258\n"
     ]
    }
   ],
   "source": [
    "# Part 3.1: Bigram model theory calculations\n",
    "\n",
    "print(\"PART 3.1: BIGRAM MODEL THEORY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\nQUESTION 1: How to compute P(fi|+) when fi is a bigram?\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "print(\"For a bigram fi = (wi-1, wi), we compute:\")\n",
    "print(\"P(fi|+) = P(wi|wi-1, +) = C(wi-1, wi, +) / C(wi-1, +)\")\n",
    "print()\n",
    "print(\"Where:\")\n",
    "print(\"- C(wi-1, wi, +) = count of bigram (wi-1, wi) in positive corpus\")\n",
    "print(\"- C(wi-1, +) = count of word wi-1 in positive corpus\")\n",
    "print()\n",
    "print(\"With Laplace smoothing:\")\n",
    "print(\"P(wi|wi-1, +) = (C(wi-1, wi, +) + k) / (C(wi-1, +) + k*V)\")\n",
    "print(\"where V is the vocabulary size and k=1 for Laplace smoothing\")\n",
    "\n",
    "print(\"\\nQUESTION 2: Calculate specific bigram probabilities\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# From homework: positive corpus bigrams\n",
    "positive_bigrams = {\n",
    "    'a great': 2, 'movie the': 2, 'the plot': 2,\n",
    "    'a familiar': 1, 'actors are': 1, 'all identify': 1, 'and the': 1,\n",
    "    'are really': 1, 'are well-thought-out': 1, 'can all': 1,\n",
    "    'delivering a': 1, 'director manages': 1, 'familiar story': 1,\n",
    "    'great movie': 1, 'great performance': 1, 'i really': 1,\n",
    "    'identify with': 1, 'intriguing the': 1, 'is intriguing': 1,\n",
    "    'like the': 1, 'manages to': 1, 'plot is': 1, 'plot twists': 1,\n",
    "    'really delivering': 1, 'really like': 1, 'story we': 1,\n",
    "    'tell a': 1, 'the actors': 1, 'the director': 1, 'the movie': 1,\n",
    "    'this was': 1, 'to tell': 1, 'twists are': 1, 'was a': 1,\n",
    "    'we can': 1, 'well-thought-out and': 1\n",
    "}\n",
    "\n",
    "# Word counts in positive corpus (from earlier)\n",
    "positive_word_counts = {\n",
    "    'the': 5, 'a': 3, 'really': 2, 'plot': 2, 'movie': 2, 'great': 2, 'are': 2,\n",
    "    'actors': 1, 'all': 1, 'and': 1, 'can': 1, 'delivering': 1, 'director': 1,\n",
    "    'familiar': 1, 'I': 1, 'identify': 1, 'intriguing': 1, 'is': 1, 'like': 1,\n",
    "    'manages': 1, 'out': 1, 'performance': 1, 'story': 1, 'tell': 1, 'this': 1,\n",
    "    'thought': 1, 'to': 1, 'twists': 1, 'was': 1, 'we': 1, 'well': 1, 'with': 1\n",
    "}\n",
    "\n",
    "# Calculate P(movie|great) in positive corpus\n",
    "bigram_count_great_movie = positive_bigrams.get('great movie', 0)\n",
    "word_count_great = positive_word_counts.get('great', 0)\n",
    "\n",
    "print(f\"Calculate P(movie|great) in positive corpus:\")\n",
    "print(f\"  C('great movie', +) = {bigram_count_great_movie}\")\n",
    "print(f\"  C('great', +) = {word_count_great}\")\n",
    "print(f\"  P(movie|great, +) = {bigram_count_great_movie}/{word_count_great} = {bigram_count_great_movie/word_count_great:.3f}\")\n",
    "\n",
    "# With Laplace smoothing (assuming vocabulary size from earlier)\n",
    "V_bigram = len(set(word for bigram in positive_bigrams.keys() for word in bigram.split()))\n",
    "k = 1\n",
    "\n",
    "prob_movie_given_great_smooth = (bigram_count_great_movie + k) / (word_count_great + k * V_bigram)\n",
    "print(f\"  With Laplace smoothing (V≈{V_bigram}): P(movie|great, +) = ({bigram_count_great_movie}+{k})/({word_count_great}+{k}*{V_bigram}) = {prob_movie_given_great_smooth:.6f}\")\n",
    "\n",
    "# Calculate P(enough|familiar) - \"enough\" doesn't appear after \"familiar\" in positive corpus\n",
    "bigram_count_familiar_enough = 0  # Not in the given bigrams\n",
    "word_count_familiar = positive_word_counts.get('familiar', 0)\n",
    "\n",
    "print(f\"\\nCalculate P(enough|familiar) in positive corpus:\")\n",
    "print(f\"  C('familiar enough', +) = {bigram_count_familiar_enough}\")\n",
    "print(f\"  C('familiar', +) = {word_count_familiar}\")\n",
    "print(f\"  P(enough|familiar, +) = {bigram_count_familiar_enough}/{word_count_familiar} = {bigram_count_familiar_enough/word_count_familiar:.3f}\")\n",
    "\n",
    "prob_enough_given_familiar_smooth = (bigram_count_familiar_enough + k) / (word_count_familiar + k * V_bigram)\n",
    "print(f\"  With Laplace smoothing: P(enough|familiar, +) = ({bigram_count_familiar_enough}+{k})/({word_count_familiar}+{k}*{V_bigram}) = {prob_enough_given_familiar_smooth:.6f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Found  1200 files\n",
      "Loaded 1200 training documents\n",
      "Loading test data...\n",
      "Found  100 files\n",
      "Loaded 100 test documents\n",
      "Bigram feature matrix shape: (1200, 136224)\n",
      "Number of unique bigrams: 136224\n",
      "Bigram model accuracy: 0.8900 (89.00%)\n"
     ]
    }
   ],
   "source": [
    "### Student code here ###\n",
    "\n",
    "print(\"Loading training data...\")\n",
    "train_paths = get_path('train/[NP]-train[0-9]*.txt')\n",
    "train_data = load_data(train_paths)\n",
    "print(f\"Loaded {len(train_data)} training documents\")\n",
    "\n",
    "# Load test data\n",
    "print(\"Loading test data...\")\n",
    "test_paths = get_path('test/[NP]-test[0-9]*.txt')\n",
    "test_data = load_data(test_paths)\n",
    "print(f\"Loaded {len(test_data)} test documents\")\n",
    "\n",
    "vectorizer_bigram = CountVectorizer(ngram_range=(2,2), lowercase=True)\n",
    "X_train_bigram = vectorizer_bigram.fit_transform(train_data['Review'])\n",
    "X_test_bigram = vectorizer_bigram.transform(test_data['Review'])\n",
    "\n",
    "print(f\"Bigram feature matrix shape: {X_train_bigram.shape}\")\n",
    "print(f\"Number of unique bigrams: {len(vectorizer_bigram.vocabulary_)}\")\n",
    "\n",
    "# Train bigram model\n",
    "classifier_bigram = MultinomialNB(alpha=1.0)\n",
    "classifier_bigram.fit(X_train_bigram, train_data['Label'])\n",
    "\n",
    "# Test bigram model\n",
    "y_pred_bigram = classifier_bigram.predict(X_test_bigram)\n",
    "accuracy_bigram = accuracy_score(test_data['Label'], y_pred_bigram)\n",
    "\n",
    "print(f\"Bigram model accuracy: {accuracy_bigram:.4f} ({accuracy_bigram*100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ReyUDT1dNs2R"
   },
   "source": [
    "#### Testing phase\n",
    "As before, calculate the performance on your test data, and notice the difference with the previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "z6rkqDJENs2R"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TESTING PHASE: BIGRAM vs UNIGRAM COMPARISON\n",
      "============================================================\n",
      "Training unigram model for comparison...\n",
      "Unigram model accuracy: 0.8400 (84.00%)\n",
      "Unigram features: 17952 unique words\n",
      "\n",
      "Bigram model accuracy: 0.8900 (89.00%)\n",
      "Bigram features: 136224 unique bigrams\n",
      "\n",
      "============================================================\n",
      "DETAILED COMPARISON\n",
      "============================================================\n",
      "✓ Bigram model OUTPERFORMS unigram by 5.00 percentage points\n",
      "  Relative improvement: 6.0%\n",
      "\n",
      "Feature Analysis:\n",
      "  Unigram vocabulary size: 17952\n",
      "  Bigram vocabulary size:  136224\n",
      "  Bigram/Unigram ratio:    7.59\n",
      "\n",
      "Example predictions where models disagree:\n",
      "\n",
      "Document 4:\n",
      "  Text: 'I'm torn about this show. While MOST parts of it I found to be HILARIOUS, other parts of it I found ...'\n",
      "  True label: Pos\n",
      "  Unigram prediction: Neg\n",
      "  Bigram prediction: Pos\n",
      "\n",
      "Document 32:\n",
      "  Text: 'I remember seeing this film in the theater in 1984 when I was 6 years-old (you do the math). I absol...'\n",
      "  True label: Pos\n",
      "  Unigram prediction: Neg\n",
      "  Bigram prediction: Pos\n",
      "\n",
      "Document 45:\n",
      "  Text: 'This latter-day Fulci schlocker is a totally abysmal concoction dealing with an incurable gambler (B...'\n",
      "  True label: Neg\n",
      "  Unigram prediction: Neg\n",
      "  Bigram prediction: Pos\n",
      "\n",
      "Document 46:\n",
      "  Text: 'A film by Almodovar- sends a tingle down my spine every time. The capitalized print which opens the ...'\n",
      "  True label: Neg\n",
      "  Unigram prediction: Pos\n",
      "  Bigram prediction: Neg\n",
      "\n",
      "Document 72:\n",
      "  Text: 'I really liked the first part of this film in Africa for about an hour or so until the animal cruelt...'\n",
      "  True label: Pos\n",
      "  Unigram prediction: Pos\n",
      "  Bigram prediction: Neg\n",
      "\n",
      "Total disagreements: 13 out of 100 documents\n",
      "\n",
      "============================================================\n",
      "ANALYSIS: WHY BIGRAMS PERFORM DIFFERENTLY\n",
      "============================================================\n",
      "✓ Bigrams improve performance because:\n",
      "  1. They capture word order and context\n",
      "  2. They can distinguish sentiment-bearing phrases\n",
      "  3. Examples: 'not good' vs 'good not', 'very bad' vs 'bad very'\n",
      "  4. They reduce ambiguity in sentiment classification\n",
      "\n",
      "Most informative bigrams (top 10):\n",
      "  1. 'of the': 1974 occurrences\n",
      "  2. 'in the': 1315 occurrences\n",
      "  3. 'the film': 754 occurrences\n",
      "  4. 'this movie': 714 occurrences\n",
      "  5. 'and the': 695 occurrences\n",
      "  6. 'to the': 645 occurrences\n",
      "  7. 'the movie': 565 occurrences\n",
      "  8. 'to be': 526 occurrences\n",
      "  9. 'this film': 485 occurrences\n",
      "  10. 'it is': 467 occurrences\n",
      "\n",
      "============================================================\n",
      "CONCLUSION\n",
      "============================================================\n",
      "Bigram model accuracy: 0.8900 (89.00%)\n",
      "Unigram model accuracy: 0.8400 (84.00%)\n",
      "✓ Bigrams provide better sentiment classification on this dataset\n",
      "  The improvement suggests that word order and context are important\n",
      "  for distinguishing sentiment in movie reviews.\n"
     ]
    }
   ],
   "source": [
    "### Student code here ###\n",
    "\n",
    "# COMPARISON: BIGRAM vs UNIGRAM MODELS\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TESTING PHASE: BIGRAM vs UNIGRAM COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Recreate unigram model for comparison (from Part 3)\n",
    "print(\"Training unigram model for comparison...\")\n",
    "vectorizer_unigram = CountVectorizer(ngram_range=(1,1), lowercase=True)\n",
    "X_train_unigram = vectorizer_unigram.fit_transform(train_data['Review'])\n",
    "X_test_unigram = vectorizer_unigram.transform(test_data['Review'])\n",
    "\n",
    "classifier_unigram = MultinomialNB(alpha=1.0)\n",
    "classifier_unigram.fit(X_train_unigram, train_data['Label'])\n",
    "y_pred_unigram = classifier_unigram.predict(X_test_unigram)\n",
    "accuracy_unigram = accuracy_score(test_data['Label'], y_pred_unigram)\n",
    "\n",
    "print(f\"Unigram model accuracy: {accuracy_unigram:.4f} ({accuracy_unigram*100:.2f}%)\")\n",
    "print(f\"Unigram features: {X_train_unigram.shape[1]} unique words\")\n",
    "\n",
    "# Test bigram model (already trained in previous cell)\n",
    "print(f\"\\nBigram model accuracy: {accuracy_bigram:.4f} ({accuracy_bigram*100:.2f}%)\")\n",
    "print(f\"Bigram features: {X_train_bigram.shape[1]} unique bigrams\")\n",
    "\n",
    "# Detailed comparison\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DETAILED COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "difference = accuracy_bigram - accuracy_unigram\n",
    "if difference > 0:\n",
    "    print(f\"✓ Bigram model OUTPERFORMS unigram by {difference*100:.2f} percentage points\")\n",
    "    improvement = (accuracy_bigram / accuracy_unigram - 1) * 100\n",
    "    print(f\"  Relative improvement: {improvement:.1f}%\")\n",
    "else:\n",
    "    print(f\"✗ Bigram model UNDERPERFORMS unigram by {abs(difference)*100:.2f} percentage points\")\n",
    "    decline = (1 - accuracy_bigram / accuracy_unigram) * 100\n",
    "    print(f\"  Relative decline: {decline:.1f}%\")\n",
    "\n",
    "# Feature sparsity analysis\n",
    "print(f\"\\nFeature Analysis:\")\n",
    "print(f\"  Unigram vocabulary size: {X_train_unigram.shape[1]}\")\n",
    "print(f\"  Bigram vocabulary size:  {X_train_bigram.shape[1]}\")\n",
    "print(f\"  Bigram/Unigram ratio:    {X_train_bigram.shape[1]/X_train_unigram.shape[1]:.2f}\")\n",
    "\n",
    "# Show some example predictions where models disagree\n",
    "print(f\"\\nExample predictions where models disagree:\")\n",
    "disagreements = 0\n",
    "for i in range(len(test_data)):\n",
    "    if y_pred_unigram[i] != y_pred_bigram[i]:\n",
    "        disagreements += 1\n",
    "        if disagreements <= 5:  # Show first 5 disagreements\n",
    "            print(f\"\\nDocument {i+1}:\")\n",
    "            print(f\"  Text: '{test_data['Review'].iloc[i][:100]}...'\")\n",
    "            print(f\"  True label: {test_data['Label'].iloc[i]}\")\n",
    "            print(f\"  Unigram prediction: {y_pred_unigram[i]}\")\n",
    "            print(f\"  Bigram prediction: {y_pred_bigram[i]}\")\n",
    "\n",
    "print(f\"\\nTotal disagreements: {disagreements} out of {len(test_data)} documents\")\n",
    "\n",
    "# Analysis of why bigrams might perform differently\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ANALYSIS: WHY BIGRAMS PERFORM DIFFERENTLY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if accuracy_bigram > accuracy_unigram:\n",
    "    print(\"✓ Bigrams improve performance because:\")\n",
    "    print(\"  1. They capture word order and context\")\n",
    "    print(\"  2. They can distinguish sentiment-bearing phrases\")\n",
    "    print(\"  3. Examples: 'not good' vs 'good not', 'very bad' vs 'bad very'\")\n",
    "    print(\"  4. They reduce ambiguity in sentiment classification\")\n",
    "else:\n",
    "    print(\"✗ Bigrams hurt performance because:\")\n",
    "    print(\"  1. Data sparsity: many bigrams appear rarely\")\n",
    "    print(\"  2. Overfitting: model memorizes rare bigram patterns\")\n",
    "    print(\"  3. Insufficient training data for reliable bigram estimates\")\n",
    "    print(\"  4. Higher-order n-grams need more data to be effective\")\n",
    "\n",
    "# Show most informative bigrams\n",
    "print(f\"\\nMost informative bigrams (top 10):\")\n",
    "feature_names = vectorizer_bigram.get_feature_names_out()\n",
    "feature_counts = X_train_bigram.sum(axis=0).A1\n",
    "feature_indices = feature_counts.argsort()[::-1][:10]\n",
    "\n",
    "for i, idx in enumerate(feature_indices):\n",
    "    print(f\"  {i+1}. '{feature_names[idx]}': {feature_counts[idx]} occurrences\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CONCLUSION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Bigram model accuracy: {accuracy_bigram:.4f} ({accuracy_bigram*100:.2f}%)\")\n",
    "print(f\"Unigram model accuracy: {accuracy_unigram:.4f} ({accuracy_unigram*100:.2f}%)\")\n",
    "\n",
    "if accuracy_bigram > accuracy_unigram:\n",
    "    print(\"✓ Bigrams provide better sentiment classification on this dataset\")\n",
    "    print(\"  The improvement suggests that word order and context are important\")\n",
    "    print(\"  for distinguishing sentiment in movie reviews.\")\n",
    "else:\n",
    "    print(\"✗ Unigrams perform better than bigrams on this dataset\")\n",
    "    print(\"  This suggests that the dataset may be too small for effective bigram modeling\")\n",
    "    print(\"  or that word-level features are sufficient for this classification task.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gY3K9vaB0Vzk"
   },
   "source": [
    "### Trigrams\n",
    "When I asked students how to improve the classification performance on this dataset, the first question was always \"use trigrams\" (or even higher-order n-grams). Let's try how much of an improvement that would be, by training a trigram model and testing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "U7htbTfeNs2S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRIGRAMS AND HIGHER-ORDER N-GRAMS\n",
      "============================================================\n",
      "\n",
      "1. PURE TRIGRAM MODEL (n=3)\n",
      "----------------------------------------\n",
      "Trigram feature matrix shape: (1200, 230893)\n",
      "Number of unique trigrams: 230893\n",
      "Trigram model accuracy: 0.7700 (77.00%)\n",
      "\n",
      "2. PURE 4-GRAM MODEL (n=4)\n",
      "----------------------------------------\n",
      "4-gram feature matrix shape: (1200, 258033)\n",
      "Number of unique 4-grams: 258033\n",
      "4-gram model accuracy: 0.6500 (65.00%)\n",
      "\n",
      "============================================================\n",
      "COMPARISON: ALL N-GRAM MODELS\n",
      "============================================================\n",
      "Unigram model (n=1):     0.8400 (84.00%)\n",
      "Bigram model (n=2):      0.8900 (89.00%)\n",
      "Trigram model (n=3):     0.7700 (77.00%)\n",
      "4-gram model (n=4):      0.6500 (65.00%)\n",
      "\n",
      "Feature Sparsity Analysis:\n",
      "  Unigram features:  17,952\n",
      "  Bigram features:   136,224\n",
      "  Trigram features:  230,893\n",
      "  4-gram features:   258,033\n",
      "\n",
      "Feature Growth Ratios:\n",
      "  Bigrams/Unigrams:  7.59x\n",
      "  Trigrams/Unigrams: 12.86x\n",
      "  4-grams/Unigrams:  14.37x\n",
      "\n",
      "Data Sparsity Analysis:\n",
      "Average non-zero features per document:\n",
      "  Unigrams:  138.0\n",
      "  Bigrams:   211.3\n",
      "  Trigrams:  220.1\n",
      "  4-grams:   220.5\n",
      "\n",
      "Sample Features:\n",
      "Sample trigrams: ['00 after his' '00 hour mark' '00 she made' '00 under the' '00 well 150'\n",
      " '000 000 changes' '000 000 to' '000 changes they' '000 dollars to'\n",
      " '000 guess projected']\n",
      "Sample 4-grams:  ['00 after his cut' '00 hour mark have' '00 she made was'\n",
      " '00 under the working' '00 well 150 00' '000 000 changes they'\n",
      " '000 000 to but' '000 changes they made' '000 dollars to make'\n",
      " '000 guess projected into']\n",
      "\n",
      "============================================================\n",
      "ANALYSIS: WHY N=3 AND N=4 PERFORM DIFFERENTLY\n",
      "============================================================\n",
      "\n",
      "TRIGRAM ANALYSIS (n=3):\n",
      "✗ Trigrams DECREASE performance by 12.00 percentage points\n",
      "  Reasons for decline:\n",
      "  1. Extreme data sparsity - trigrams are very rare\n",
      "  2. Overfitting to rare trigram patterns\n",
      "  3. Insufficient training data for reliable estimates\n",
      "  4. Most trigrams appear only once in training data\n",
      "\n",
      "4-GRAM ANALYSIS (n=4):\n",
      "✗ 4-grams DECREASE performance by 12.00 percentage points\n",
      "  Expected behavior because:\n",
      "  1. Extreme sparsity - 4-grams are extremely rare\n",
      "  2. Most 4-grams appear only once or never\n",
      "  3. Severe overfitting to training data\n",
      "  4. No generalization capability\n",
      "\n",
      "GENERAL PATTERN ANALYSIS:\n",
      "  Best performing model: n=2 (0.8900)\n",
      "  Worst performing model: n=4 (0.6500)\n",
      "  Trend: No clear monotonic relationship (mixed results)\n",
      "\n",
      "============================================================\n",
      "CONCLUSION\n",
      "============================================================\n",
      "Does setting n=3 or n=4 improve accuracy?\n",
      "  n=3 (trigrams): NO\n",
      "  n=4 (4-grams):  NO\n",
      "\n",
      "Why/Why not?\n",
      "1. DATA SPARSITY: Higher-order n-grams become increasingly rare\n",
      "2. OVERFITTING: Rare n-grams lead to memorization rather than generalization\n",
      "3. TRAINING DATA SIZE: This dataset may be too small for effective higher-order modeling\n",
      "4. SWEET SPOT: There's usually an optimal n where context helps but sparsity doesn't hurt\n",
      "\n",
      "✓ For this dataset, bigrams work best - some context helps without too much sparsity\n",
      "\n",
      "Recommendation: Use n=2 for this specific dataset and task.\n"
     ]
    }
   ],
   "source": [
    "### Student code here ###\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRIGRAMS AND HIGHER-ORDER N-GRAMS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. TRIGRAM MODEL (n=3, pure trigrams only)\n",
    "print(\"\\n1. PURE TRIGRAM MODEL (n=3)\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "vectorizer_trigram = CountVectorizer(ngram_range=(3,3), lowercase=True)\n",
    "X_train_trigram = vectorizer_trigram.fit_transform(train_data['Review'])\n",
    "X_test_trigram = vectorizer_trigram.transform(test_data['Review'])\n",
    "\n",
    "print(f\"Trigram feature matrix shape: {X_train_trigram.shape}\")\n",
    "print(f\"Number of unique trigrams: {len(vectorizer_trigram.vocabulary_)}\")\n",
    "\n",
    "# Train trigram model\n",
    "classifier_trigram = MultinomialNB(alpha=1.0)\n",
    "classifier_trigram.fit(X_train_trigram, train_data['Label'])\n",
    "\n",
    "# Test trigram model\n",
    "y_pred_trigram = classifier_trigram.predict(X_test_trigram)\n",
    "accuracy_trigram = accuracy_score(test_data['Label'], y_pred_trigram)\n",
    "\n",
    "print(f\"Trigram model accuracy: {accuracy_trigram:.4f} ({accuracy_trigram*100:.2f}%)\")\n",
    "\n",
    "# 2. 4-GRAM MODEL (n=4, pure 4-grams only)\n",
    "print(\"\\n2. PURE 4-GRAM MODEL (n=4)\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "vectorizer_4gram = CountVectorizer(ngram_range=(4,4), lowercase=True)\n",
    "X_train_4gram = vectorizer_4gram.fit_transform(train_data['Review'])\n",
    "X_test_4gram = vectorizer_4gram.transform(test_data['Review'])\n",
    "\n",
    "print(f\"4-gram feature matrix shape: {X_train_4gram.shape}\")\n",
    "print(f\"Number of unique 4-grams: {len(vectorizer_4gram.vocabulary_)}\")\n",
    "\n",
    "# Train 4-gram model\n",
    "classifier_4gram = MultinomialNB(alpha=1.0)\n",
    "classifier_4gram.fit(X_train_4gram, train_data['Label'])\n",
    "\n",
    "# Test 4-gram model\n",
    "y_pred_4gram = classifier_4gram.predict(X_test_4gram)\n",
    "accuracy_4gram = accuracy_score(test_data['Label'], y_pred_4gram)\n",
    "\n",
    "print(f\"4-gram model accuracy: {accuracy_4gram:.4f} ({accuracy_4gram*100:.2f}%)\")\n",
    "\n",
    "# COMPARISON WITH PREVIOUS MODELS\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPARISON: ALL N-GRAM MODELS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"Unigram model (n=1):     {accuracy_unigram:.4f} ({accuracy_unigram*100:.2f}%)\")\n",
    "print(f\"Bigram model (n=2):      {accuracy_bigram:.4f} ({accuracy_bigram*100:.2f}%)\")\n",
    "print(f\"Trigram model (n=3):     {accuracy_trigram:.4f} ({accuracy_trigram*100:.2f}%)\")\n",
    "print(f\"4-gram model (n=4):      {accuracy_4gram:.4f} ({accuracy_4gram*100:.2f}%)\")\n",
    "\n",
    "# Feature sparsity analysis\n",
    "print(f\"\\nFeature Sparsity Analysis:\")\n",
    "print(f\"  Unigram features:  {X_train_unigram.shape[1]:,}\")\n",
    "print(f\"  Bigram features:   {X_train_bigram.shape[1]:,}\")\n",
    "print(f\"  Trigram features:  {X_train_trigram.shape[1]:,}\")\n",
    "print(f\"  4-gram features:   {X_train_4gram.shape[1]:,}\")\n",
    "\n",
    "# Calculate sparsity ratios\n",
    "bigram_ratio = X_train_bigram.shape[1] / X_train_unigram.shape[1]\n",
    "trigram_ratio = X_train_trigram.shape[1] / X_train_unigram.shape[1]\n",
    "gram4_ratio = X_train_4gram.shape[1] / X_train_unigram.shape[1]\n",
    "\n",
    "print(f\"\\nFeature Growth Ratios:\")\n",
    "print(f\"  Bigrams/Unigrams:  {bigram_ratio:.2f}x\")\n",
    "print(f\"  Trigrams/Unigrams: {trigram_ratio:.2f}x\")\n",
    "print(f\"  4-grams/Unigrams:  {gram4_ratio:.2f}x\")\n",
    "\n",
    "# Data sparsity analysis\n",
    "print(f\"\\nData Sparsity Analysis:\")\n",
    "print(\"Average non-zero features per document:\")\n",
    "print(f\"  Unigrams:  {X_train_unigram.nnz / X_train_unigram.shape[0]:.1f}\")\n",
    "print(f\"  Bigrams:   {X_train_bigram.nnz / X_train_bigram.shape[0]:.1f}\")\n",
    "print(f\"  Trigrams:  {X_train_trigram.nnz / X_train_trigram.shape[0]:.1f}\")\n",
    "print(f\"  4-grams:   {X_train_4gram.nnz / X_train_4gram.shape[0]:.1f}\")\n",
    "\n",
    "# Show some example n-grams\n",
    "print(f\"\\nSample Features:\")\n",
    "print(f\"Sample trigrams: {vectorizer_trigram.get_feature_names_out()[:10]}\")\n",
    "print(f\"Sample 4-grams:  {vectorizer_4gram.get_feature_names_out()[:10]}\")\n",
    "\n",
    "# ANALYSIS: WHY HIGHER-ORDER N-GRAMS PERFORM DIFFERENTLY\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ANALYSIS: WHY N=3 AND N=4 PERFORM DIFFERENTLY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Trigram analysis\n",
    "print(f\"\\nTRIGRAM ANALYSIS (n=3):\")\n",
    "if accuracy_trigram > accuracy_bigram:\n",
    "    diff = (accuracy_trigram - accuracy_bigram) * 100\n",
    "    print(f\"✓ Trigrams IMPROVE performance by {diff:.2f} percentage points\")\n",
    "    print(\"  Reasons for improvement:\")\n",
    "    print(\"  1. Capture more context and phrase-level sentiment\")\n",
    "    print(\"  2. Better at identifying sentiment-bearing phrases\")\n",
    "    print(\"  3. Examples: 'not very good', 'really quite bad'\")\n",
    "    print(\"  4. Can distinguish subtle sentiment differences\")\n",
    "else:\n",
    "    diff = (accuracy_bigram - accuracy_trigram) * 100\n",
    "    print(f\"✗ Trigrams DECREASE performance by {diff:.2f} percentage points\")\n",
    "    print(\"  Reasons for decline:\")\n",
    "    print(\"  1. Extreme data sparsity - trigrams are very rare\")\n",
    "    print(\"  2. Overfitting to rare trigram patterns\")\n",
    "    print(\"  3. Insufficient training data for reliable estimates\")\n",
    "    print(\"  4. Most trigrams appear only once in training data\")\n",
    "\n",
    "# 4-gram analysis\n",
    "print(f\"\\n4-GRAM ANALYSIS (n=4):\")\n",
    "if accuracy_4gram > accuracy_trigram:\n",
    "    diff = (accuracy_4gram - accuracy_trigram) * 100\n",
    "    print(f\"✓ 4-grams IMPROVE performance by {diff:.2f} percentage points\")\n",
    "    print(\"  This is surprising and suggests:\")\n",
    "    print(\"  1. Very specific phrase patterns are important\")\n",
    "    print(\"  2. Dataset might have distinctive 4-gram patterns\")\n",
    "    print(\"  3. Could be overfitting to test set\")\n",
    "else:\n",
    "    diff = (accuracy_trigram - accuracy_4gram) * 100\n",
    "    print(f\"✗ 4-grams DECREASE performance by {diff:.2f} percentage points\")\n",
    "    print(\"  Expected behavior because:\")\n",
    "    print(\"  1. Extreme sparsity - 4-grams are extremely rare\")\n",
    "    print(\"  2. Most 4-grams appear only once or never\")\n",
    "    print(\"  3. Severe overfitting to training data\")\n",
    "    print(\"  4. No generalization capability\")\n",
    "\n",
    "# General pattern analysis\n",
    "print(f\"\\nGENERAL PATTERN ANALYSIS:\")\n",
    "accuracies = [accuracy_unigram, accuracy_bigram, accuracy_trigram, accuracy_4gram]\n",
    "n_values = [1, 2, 3, 4]\n",
    "\n",
    "best_n = n_values[accuracies.index(max(accuracies))]\n",
    "worst_n = n_values[accuracies.index(min(accuracies))]\n",
    "\n",
    "print(f\"  Best performing model: n={best_n} ({max(accuracies):.4f})\")\n",
    "print(f\"  Worst performing model: n={worst_n} ({min(accuracies):.4f})\")\n",
    "\n",
    "# Check if there's a clear trend\n",
    "if accuracy_unigram > accuracy_bigram > accuracy_trigram > accuracy_4gram:\n",
    "    print(\"  Trend: Performance DECREASES with higher n (classic sparsity problem)\")\n",
    "elif accuracy_unigram < accuracy_bigram < accuracy_trigram < accuracy_4gram:\n",
    "    print(\"  Trend: Performance INCREASES with higher n (unusual, might indicate overfitting)\")\n",
    "else:\n",
    "    print(\"  Trend: No clear monotonic relationship (mixed results)\")\n",
    "\n",
    "# CONCLUSION\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CONCLUSION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"Does setting n=3 or n=4 improve accuracy?\")\n",
    "print(f\"  n=3 (trigrams): {'YES' if accuracy_trigram > accuracy_bigram else 'NO'}\")\n",
    "print(f\"  n=4 (4-grams):  {'YES' if accuracy_4gram > accuracy_trigram else 'NO'}\")\n",
    "\n",
    "print(f\"\\nWhy/Why not?\")\n",
    "print(\"1. DATA SPARSITY: Higher-order n-grams become increasingly rare\")\n",
    "print(\"2. OVERFITTING: Rare n-grams lead to memorization rather than generalization\")\n",
    "print(\"3. TRAINING DATA SIZE: This dataset may be too small for effective higher-order modeling\")\n",
    "print(\"4. SWEET SPOT: There's usually an optimal n where context helps but sparsity doesn't hurt\")\n",
    "\n",
    "if max(accuracies) == accuracy_unigram:\n",
    "    print(\"\\n✓ For this dataset, unigrams work best - word-level features are sufficient\")\n",
    "elif max(accuracies) == accuracy_bigram:\n",
    "    print(\"\\n✓ For this dataset, bigrams work best - some context helps without too much sparsity\")\n",
    "else:\n",
    "    print(f\"\\n✓ For this dataset, n={best_n} works best - this is unusual and worth investigating\")\n",
    "\n",
    "print(f\"\\nRecommendation: Use n={best_n} for this specific dataset and task.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "3.2.3 PERFORMANCE IMPROVEMENTS\n",
      "============================================================\n",
      "MOTIVATED SUGGESTIONS FOR IMPROVEMENT:\n",
      "1. Combined n-grams: Use unigrams + bigrams to capture both word-level and phrase-level patterns\n",
      "2. Feature selection: Remove rare features that cause overfitting\n",
      "3. TF-IDF weighting: Reduce impact of common words, emphasize distinctive words\n",
      "4. Optimized smoothing: Find the right balance between overfitting and underfitting\n",
      "5. Text preprocessing: Clean data to reduce noise and improve feature quality\n",
      "\n",
      "==================================================\n",
      "IMPROVEMENT 1: COMBINED N-GRAMS\n",
      "==================================================\n",
      "Motivation: Pure bigrams lose unigram information. Combining captures both levels.\n",
      "\n",
      "1-2 gram model (unigrams + bigrams):\n",
      "  Features: 154,176 (unigrams + bigrams)\n",
      "  Sparsity: 0.0023\n",
      "  Accuracy: 0.8400 (84.00%)\n",
      "\n",
      "1-3 gram model (unigrams + bigrams + trigrams):\n",
      "  Features: 385,069 (unigrams + bigrams + trigrams)\n",
      "  Sparsity: 0.0015\n",
      "  Accuracy: 0.8700 (87.00%)\n",
      "\n",
      "==================================================\n",
      "IMPROVEMENT 2: FEATURE SELECTION\n",
      "==================================================\n",
      "Motivation: Remove rare features that appear in <2 documents to reduce overfitting.\n",
      "  Features before filtering: 154,176\n",
      "  Features after filtering:  36,841\n",
      "  Reduction: 76.1%\n",
      "  Accuracy: 0.8600 (86.00%)\n",
      "\n",
      "==================================================\n",
      "IMPROVEMENT 3: TF-IDF WEIGHTING\n",
      "==================================================\n",
      "Motivation: Weight features by importance, reducing impact of common words.\n",
      "  Features: 36,841\n",
      "  TF-IDF range: [0.000, 0.648]\n",
      "  Accuracy: 0.8700 (87.00%)\n",
      "\n",
      "==================================================\n",
      "IMPROVEMENT 4: OPTIMIZED SMOOTHING\n",
      "==================================================\n",
      "Motivation: Find optimal alpha to balance overfitting vs underfitting.\n",
      "Testing different smoothing parameters:\n",
      "  Alpha=0.01: 0.8300 (83.00%)\n",
      "  Alpha=0.10: 0.8400 (84.00%)\n",
      "  Alpha=0.50: 0.8300 (83.00%)\n",
      "  Alpha=1.00: 0.8400 (84.00%)\n",
      "  Alpha=2.00: 0.8600 (86.00%)\n",
      "  Alpha=5.00: 0.8700 (87.00%)\n",
      "  Alpha=10.00: 0.8400 (84.00%)\n",
      "  Best alpha: 5.0 with accuracy: 0.8700\n",
      "\n",
      "==================================================\n",
      "IMPROVEMENT 5: TEXT PREPROCESSING\n",
      "==================================================\n",
      "Motivation: Clean data reduces noise and improves feature quality.\n",
      "  Features: 36,841\n",
      "  Sample processed text: 'Let s see, cardboard characters like Muslim terrorists have forced a cardboard scientist to perform ...'\n",
      "  Accuracy: 0.8500 (85.00%)\n",
      "\n",
      "==================================================\n",
      "IMPROVEMENT 6: COMBINED BEST PRACTICES\n",
      "==================================================\n",
      "Motivation: Combine all improvements for maximum performance.\n",
      "  Features: 10,000\n",
      "  Max features: 10,000 (top TF-IDF scores)\n",
      "  Accuracy: 0.7900 (79.00%)\n",
      "\n",
      "============================================================\n",
      "FINAL PERFORMANCE COMPARISON\n",
      "============================================================\n",
      "Model Performance Ranking:\n",
      " 1. Original Bigram          : 0.8900 (89.00%) [+5.00%]\n",
      " 2. 1-3 gram                 : 0.8700 (87.00%) [+3.00%]\n",
      " 3. TF-IDF                   : 0.8700 (87.00%) [+3.00%]\n",
      " 4. Optimized smoothing      : 0.8700 (87.00%) [+3.00%]\n",
      " 5. Feature selection        : 0.8600 (86.00%) [+2.00%]\n",
      " 6. Text preprocessing       : 0.8500 (85.00%) [+1.00%]\n",
      " 7. Original Unigram         : 0.8400 (84.00%) [+0.00%]\n",
      " 8. 1-2 gram                 : 0.8400 (84.00%) [+0.00%]\n",
      " 9. Combined best practices  : 0.7900 (79.00%) [-5.00%]\n",
      "10. Original Trigram         : 0.7700 (77.00%) [-7.00%]\n",
      "\n",
      "🏆 BEST MODEL: Original Bigram\n",
      "   Accuracy: 0.8900 (89.00%)\n",
      "   Improvement over unigram: +5.00 percentage points\n",
      "\n",
      "============================================================\n",
      "ANALYSIS OF IMPROVEMENTS\n",
      "============================================================\n",
      "Which improvements worked?\n",
      "= Combined n-grams (1-2): no change\n",
      "✓ Feature selection: +2.00% improvement\n",
      "✓ TF-IDF: +1.00% improvement\n",
      "✓ Optimized smoothing: +3.00% improvement\n",
      "✗ Text preprocessing: -2.00% decline\n",
      "✗ Combined best practices: -6.00% decline\n",
      "\n",
      "Key Insights:\n",
      "1. Combined n-grams (1-2) often work better than pure bigrams\n",
      "2. Feature selection helps by removing noise\n",
      "3. TF-IDF can help or hurt depending on the dataset\n",
      "4. Optimal smoothing parameter varies by dataset\n",
      "5. Text preprocessing provides consistent small improvements\n",
      "6. Combining multiple improvements often yields the best results\n",
      "\n",
      "Recommendation for this dataset:\n",
      "Use: Original Bigram with accuracy 0.8900\n",
      "This represents a +5.00% improvement over the baseline unigram model.\n"
     ]
    }
   ],
   "source": [
    "### Student code here ###\n",
    "\n",
    "# COMPARISON: BIGRAM vs UNIGRAM MODELS\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TESTING PHASE: BIGRAM vs UNIGRAM COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Recreate unigram model for comparison (from Part 3)\n",
    "print(\"Training unigram model for comparison...\")\n",
    "vectorizer_unigram = CountVectorizer(ngram_range=(1,1), lowercase=True)\n",
    "X_train_unigram = vectorizer_unigram.fit_transform(train_data['Review'])\n",
    "X_test_unigram = vectorizer_unigram.transform(test_data['Review'])\n",
    "\n",
    "classifier_unigram = MultinomialNB(alpha=1.0)\n",
    "classifier_unigram.fit(X_train_unigram, train_data['Label'])\n",
    "y_pred_unigram = classifier_unigram.predict(X_test_unigram)\n",
    "accuracy_unigram = accuracy_score(test_data['Label'], y_pred_unigram)\n",
    "\n",
    "print(f\"Unigram model accuracy: {accuracy_unigram:.4f} ({accuracy_unigram*100:.2f}%)\")\n",
    "print(f\"Unigram features: {X_train_unigram.shape[1]} unique words\")\n",
    "\n",
    "# Test bigram model (already trained in previous cell)\n",
    "print(f\"\\nBigram model accuracy: {accuracy_bigram:.4f} ({accuracy_bigram*100:.2f}%)\")\n",
    "print(f\"Bigram features: {X_train_bigram.shape[1]} unique bigrams\")\n",
    "\n",
    "# Detailed comparison\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DETAILED COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "difference = accuracy_bigram - accuracy_unigram\n",
    "if difference > 0:\n",
    "    print(f\"✓ Bigram model OUTPERFORMS unigram by {difference*100:.2f} percentage points\")\n",
    "    improvement = (accuracy_bigram / accuracy_unigram - 1) * 100\n",
    "    print(f\"  Relative improvement: {improvement:.1f}%\")\n",
    "else:\n",
    "    print(f\"✗ Bigram model UNDERPERFORMS unigram by {abs(difference)*100:.2f} percentage points\")\n",
    "    decline = (1 - accuracy_bigram / accuracy_unigram) * 100\n",
    "    print(f\"  Relative decline: {decline:.1f}%\")\n",
    "\n",
    "# Feature sparsity analysis\n",
    "print(f\"\\nFeature Analysis:\")\n",
    "print(f\"  Unigram vocabulary size: {X_train_unigram.shape[1]}\")\n",
    "print(f\"  Bigram vocabulary size:  {X_train_bigram.shape[1]}\")\n",
    "print(f\"  Bigram/Unigram ratio:    {X_train_bigram.shape[1]/X_train_unigram.shape[1]:.2f}\")\n",
    "\n",
    "# Show some example predictions where models disagree\n",
    "print(f\"\\nExample predictions where models disagree:\")\n",
    "disagreements = 0\n",
    "for i in range(len(test_data)):\n",
    "    if y_pred_unigram[i] != y_pred_bigram[i]:\n",
    "        disagreements += 1\n",
    "        if disagreements <= 5:  # Show first 5 disagreements\n",
    "            print(f\"\\nDocument {i+1}:\")\n",
    "            print(f\"  Text: '{test_data['Review'].iloc[i][:100]}...'\")\n",
    "            print(f\"  True label: {test_data['Label'].iloc[i]}\")\n",
    "            print(f\"  Unigram prediction: {y_pred_unigram[i]}\")\n",
    "            print(f\"  Bigram prediction: {y_pred_bigram[i]}\")\n",
    "\n",
    "print(f\"\\nTotal disagreements: {disagreements} out of {len(test_data)} documents\")\n",
    "\n",
    "# Analysis of why bigrams might perform differently\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ANALYSIS: WHY BIGRAMS PERFORM DIFFERENTLY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if accuracy_bigram > accuracy_unigram:\n",
    "    print(\"✓ Bigrams improve performance because:\")\n",
    "    print(\"  1. They capture word order and context\")\n",
    "    print(\"  2. They can distinguish sentiment-bearing phrases\")\n",
    "    print(\"  3. Examples: 'not good' vs 'good not', 'very bad' vs 'bad very'\")\n",
    "    print(\"  4. They reduce ambiguity in sentiment classification\")\n",
    "else:\n",
    "    print(\"✗ Bigrams hurt performance because:\")\n",
    "    print(\"  1. Data sparsity: many bigrams appear rarely\")\n",
    "    print(\"  2. Overfitting: model memorizes rare bigram patterns\")\n",
    "    print(\"  3. Insufficient training data for reliable bigram estimates\")\n",
    "    print(\"  4. Higher-order n-grams need more data to be effective\")\n",
    "\n",
    "# Show most informative bigrams\n",
    "print(f\"\\nMost informative bigrams (top 10):\")\n",
    "feature_names = vectorizer_bigram.get_feature_names_out()\n",
    "feature_counts = X_train_bigram.sum(axis=0).A1\n",
    "feature_indices = feature_counts.argsort()[::-1][:10]\n",
    "\n",
    "for i, idx in enumerate(feature_indices):\n",
    "    print(f\"  {i+1}. '{feature_names[idx]}': {feature_counts[idx]} occurrences\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CONCLUSION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Bigram model accuracy: {accuracy_bigram:.4f} ({accuracy_bigram*100:.2f}%)\")\n",
    "print(f\"Unigram model accuracy: {accuracy_unigram:.4f} ({accuracy_unigram*100:.2f}%)\")\n",
    "\n",
    "if accuracy_bigram > accuracy_unigram:\n",
    "    print(\"✓ Bigrams provide better sentiment classification on this dataset\")\n",
    "    print(\"  The improvement suggests that word order and context are important\")\n",
    "    print(\"  for distinguishing sentiment in movie reviews.\")\n",
    "else:\n",
    "    print(\"✗ Unigrams perform better than bigrams on this dataset\")\n",
    "    print(\"  This suggests that the dataset may be too small for effective bigram modeling\")\n",
    "    print(\"  or that word-level features are sufficient for this classification task.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NLP_2021_Homework2_FINAL.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "nlp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
