{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e6e0166",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# Natural Language Processing 2025-1A Homework 3\n",
    "\n",
    "# Vector Semantics, Word2Vec and LLMs \n",
    "\n",
    "Deadline: 1 October (23:59)\n",
    "\n",
    "Questions: Post them in the homework discussion on Canvas, sent them to nlp-course@utwente.nl or ask us during the practical sessions. \n",
    "\n",
    "How to submit: Please answer the questions directly in this notebook and submit it before the deadline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050ad9bd",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Please Write your group number, your names with student IDs Here: \n",
    "Assignment Group 35\n",
    "Kornel Palkovics (s3698920)\n",
    "Fil Skulimowski"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5705bb26",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "Make sure that the following libraries are up-to-date in your computation envrionment. It is highly recommended to work on this assignment in UT's [JupyterLab](https://www.utwente.nl/en/service-portal/research-support/it-facilities-for-research/jupyterlab). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "eeaaa5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (25.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (4.3.3)\n",
      "Requirement already satisfied: nltk in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (3.9.2)\n",
      "Requirement already satisfied: scikit-learn in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (2.3.3)\n",
      "Requirement already satisfied: scipy in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from gensim) (7.3.0.post1)\n",
      "Requirement already satisfied: click in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from nltk) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from nltk) (2025.9.1)\n",
      "Requirement already satisfied: tqdm in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: wrapt in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (4.3.3)\n",
      "Requirement already satisfied: nltk in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (3.9.2)\n",
      "Requirement already satisfied: scikit-learn in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (1.26.4)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.3.3-cp311-cp311-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: pandas in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (2.3.3)\n",
      "Requirement already satisfied: scipy in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (1.13.1)\n",
      "Collecting scipy\n",
      "  Using cached scipy-1.16.2-cp311-cp311-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from gensim) (7.3.0.post1)\n",
      "Requirement already satisfied: click in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from nltk) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from nltk) (2025.9.1)\n",
      "Requirement already satisfied: tqdm in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: wrapt in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --upgrade pip\n",
    "!pip3 install gensim nltk scikit-learn numpy pandas scipy\n",
    "!pip install  --upgrade gensim nltk scikit-learn numpy pandas scipy ### Upgrade your libraries if neccesary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc24ba63-c517-4ecf-bb9a-adce51f079b8",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "We'll need these libraries later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e976edb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas, numpy, scipy, math\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.test.utils import datapath\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import codecs\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a13784d",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "In this assignment, you will first explore two types of word vectors: those generated using co-occurrence–based methods and those produced by the local-context predictive model Word2Vec. You will then apply and evaluate an NLP task powered by a Large Language Model (LLM). \n",
    "\n",
    "Note on Terminology: \n",
    "- The terms \"word\" and \"term\" are used interchangeably in this context, referring to unique tokens that you aim to represent as vectors. These tokens can be individual words, n-grams, phrases, or even identifiers, but for this assignment, we will focus on individual words.\n",
    "- Though \"word vectors\" and \"word embeddings\" are often used synonymously, they have distinct meanings.  According to [Wikipedia](https://en.wikipedia.org/wiki/Word_embedding), conceptually, word embedding \"*involves the mathematical embedding from space with many dimensions per word to a continuous vector space with a much lower dimension*\".\n",
    "\n",
    "# Part I. Co-occurrence count-based vectors\n",
    "\n",
    "Let's start with this corpus consisting of 10 sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b0db5b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents=[\n",
    "    \"The warm sun melts the icy snow on the mountain.\",\n",
    "    \"A warm cup of tea felt perfect in the cool morning air.\",\n",
    "    \"Her warm smile brightened the cold winter day.\",\n",
    "    \"I love the contrast of a warm blanket on a cold night.\",\n",
    "    \"The cold wind chilled me, but the warm fire offered comfort.\",\n",
    "    \"After a cold swim, the warm towel felt like heaven.\",\n",
    "    \"The warm colors of the sunset clashed with the cold breeze.\",\n",
    "    \"The chilly floor left her longing for the cozy comfort of slippers.\",\n",
    "    \"A gentle breeze eased the bite of the cold ocean waves.\",\n",
    "    \"Cold hands found solace in the warm pockets of his coat.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e93419f",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### Exercise 1.1.1 Construct the vocabulary (0.5 point)\n",
    "Before we construct co-occurrence matrices, we need to identify unique terms in the corpus, i.e. construct the vocabulary. You can remove stop words and apply other text normalisation operations before constructing the vocabulary. \n",
    "\n",
    "Tip: Sort your vocabulary alphabetically!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b11e7e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the vocabulary is 51\n",
      "The word in the vocabulary are ['air', 'bite', 'blanket', 'breeze', 'brightened', 'chilled', 'chilly', 'clashed', 'coat', 'cold', 'colors', 'comfort', 'contrast', 'cool', 'cozy', 'cup', 'day', 'eased', 'felt', 'fire', 'floor', 'found', 'gentle', 'hands', 'heaven', 'icy', 'left', 'like', 'longing', 'love', 'melts', 'morning', 'mountain', 'night', 'ocean', 'offered', 'perfect', 'pockets', 'slippers', 'smile', 'snow', 'solace', 'sun', 'sunset', 'swim', 'tea', 'towel', 'warm', 'waves', 'wind', 'winter']\n"
     ]
    }
   ],
   "source": [
    "# Collect unique terms in the corpus\n",
    "\n",
    "# your code starts here\n",
    "\n",
    "# Get English stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Collect all unique terms\n",
    "unique_terms = set()\n",
    "\n",
    "for sentence in sents:\n",
    "    # Tokenize the sentence\n",
    "    tokens = word_tokenize(sentence.lower())\n",
    "\n",
    "    # Filter tokens: keep only alphabetic words, remove stop words\n",
    "    for token in tokens:\n",
    "        if token.isalpha() and token not in stop_words:\n",
    "            unique_terms.add(token)\n",
    "\n",
    "# Convert to sorted list (alphabetically)\n",
    "vocab = sorted(list(unique_terms))\n",
    "\n",
    "# your code ends here\n",
    "\n",
    "print('The size of the vocabulary is', len(vocab))\n",
    "print('The word in the vocabulary are', vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb9245a",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### Co-Occurrence\n",
    "\n",
    "A co-occurrence matrix counts how often terms co-occur in certain context. The context can be a complete document, a sentence, or a sliding window. \n",
    "\n",
    "Tip: Check out the [sklearn.feature_extraction.text](https://scikit-learn.org/stable/api/sklearn.feature_extraction.html#module-sklearn.feature_extraction.text) submodule that gathers utilities to build feature vectors from text documents. \n",
    "\n",
    "### Exercise 1.1.2 Term-document occurrence matrix and term-term co-occurrence matrix (0.5 point)\n",
    "Let's first consider **each sentence** in the above corpus to be the context where the (co-)occurrences are counted. For example, the words *warm*, *sun*, *icy* and *snow* occur in the first sentence, therefore, they occur in this document and co-occur with each other. Going through all the sentences, you can construct the term-document occurrence matrix and term-term co-occurrence matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "111b9b50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the term-document matrix is (51, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>air</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bite</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blanket</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breeze</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brightened</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chilled</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chilly</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clashed</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coat</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cold</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>colors</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comfort</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contrast</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cool</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cozy</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cup</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eased</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>felt</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fire</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>floor</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>found</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gentle</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hands</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heaven</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>icy</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>left</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longing</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>melts</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>morning</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mountain</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>night</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ocean</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offered</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perfect</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pockets</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slippers</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smile</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>snow</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>solace</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sun</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sunset</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swim</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tea</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>towel</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>warm</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waves</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wind</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>winter</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            1   2   3   4   5   6   7   8   9   10\n",
       "air          0   1   0   0   0   0   0   0   0   0\n",
       "bite         0   0   0   0   0   0   0   0   1   0\n",
       "blanket      0   0   0   1   0   0   0   0   0   0\n",
       "breeze       0   0   0   0   0   0   1   0   1   0\n",
       "brightened   0   0   1   0   0   0   0   0   0   0\n",
       "chilled      0   0   0   0   1   0   0   0   0   0\n",
       "chilly       0   0   0   0   0   0   0   1   0   0\n",
       "clashed      0   0   0   0   0   0   1   0   0   0\n",
       "coat         0   0   0   0   0   0   0   0   0   1\n",
       "cold         0   0   1   1   1   1   1   0   1   1\n",
       "colors       0   0   0   0   0   0   1   0   0   0\n",
       "comfort      0   0   0   0   1   0   0   1   0   0\n",
       "contrast     0   0   0   1   0   0   0   0   0   0\n",
       "cool         0   1   0   0   0   0   0   0   0   0\n",
       "cozy         0   0   0   0   0   0   0   1   0   0\n",
       "cup          0   1   0   0   0   0   0   0   0   0\n",
       "day          0   0   1   0   0   0   0   0   0   0\n",
       "eased        0   0   0   0   0   0   0   0   1   0\n",
       "felt         0   1   0   0   0   1   0   0   0   0\n",
       "fire         0   0   0   0   1   0   0   0   0   0\n",
       "floor        0   0   0   0   0   0   0   1   0   0\n",
       "found        0   0   0   0   0   0   0   0   0   1\n",
       "gentle       0   0   0   0   0   0   0   0   1   0\n",
       "hands        0   0   0   0   0   0   0   0   0   1\n",
       "heaven       0   0   0   0   0   1   0   0   0   0\n",
       "icy          1   0   0   0   0   0   0   0   0   0\n",
       "left         0   0   0   0   0   0   0   1   0   0\n",
       "like         0   0   0   0   0   1   0   0   0   0\n",
       "longing      0   0   0   0   0   0   0   1   0   0\n",
       "love         0   0   0   1   0   0   0   0   0   0\n",
       "melts        1   0   0   0   0   0   0   0   0   0\n",
       "morning      0   1   0   0   0   0   0   0   0   0\n",
       "mountain     1   0   0   0   0   0   0   0   0   0\n",
       "night        0   0   0   1   0   0   0   0   0   0\n",
       "ocean        0   0   0   0   0   0   0   0   1   0\n",
       "offered      0   0   0   0   1   0   0   0   0   0\n",
       "perfect      0   1   0   0   0   0   0   0   0   0\n",
       "pockets      0   0   0   0   0   0   0   0   0   1\n",
       "slippers     0   0   0   0   0   0   0   1   0   0\n",
       "smile        0   0   1   0   0   0   0   0   0   0\n",
       "snow         1   0   0   0   0   0   0   0   0   0\n",
       "solace       0   0   0   0   0   0   0   0   0   1\n",
       "sun          1   0   0   0   0   0   0   0   0   0\n",
       "sunset       0   0   0   0   0   0   1   0   0   0\n",
       "swim         0   0   0   0   0   1   0   0   0   0\n",
       "tea          0   1   0   0   0   0   0   0   0   0\n",
       "towel        0   0   0   0   0   1   0   0   0   0\n",
       "warm         1   1   1   1   1   1   1   0   0   1\n",
       "waves        0   0   0   0   0   0   0   0   1   0\n",
       "wind         0   0   0   0   1   0   0   0   0   0\n",
       "winter       0   0   1   0   0   0   0   0   0   0"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct the term-document occurrence matrix\n",
    "\n",
    "# your code starts here\n",
    "\n",
    "# Use CountVectorizer to create term-document matrix\n",
    "# We need to provide our custom vocabulary to ensure consistency\n",
    "vectorizer = CountVectorizer(vocabulary=vocab, lowercase=True, token_pattern=r'\\b[a-z]+\\b')\n",
    "\n",
    "# Fit and transform the sentences to get the term-document matrix\n",
    "# The result is a sparse matrix where rows are documents and columns are terms\n",
    "tdMatrix_sparse = vectorizer.fit_transform(sents)\n",
    "\n",
    "# Transpose to get terms as rows and documents as columns\n",
    "# Convert to dense array for easier manipulation\n",
    "tdMatrix = tdMatrix_sparse.T.toarray()\n",
    "\n",
    "# your code ends here\n",
    "\n",
    "print('The shape of the term-document matrix is', tdMatrix.shape)\n",
    "tdMatrix_pd = pandas.DataFrame(tdMatrix, index=vocab, columns=list(range(1, len(sents)+1)))\n",
    "tdMatrix_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980624f5",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "The term–term co-occurrence matrix can be computed directly from the term–document occurrence matrix. When doing so, pay close attention to the diagonal entries — they indicate self-co-occurrences, which may need to be removed or adjusted depending on your application. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374d9fe2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Construct the term-term co-occurrence matrix\n",
    "# Be sure to handle the diagonal elements appropriately\n",
    "\n",
    "# your code starts here\n",
    "\n",
    "# Compute term-term co-occurrence matrix by multiplying term-document matrix\n",
    "# with its transpose: tdMatrix @ tdMatrix.T\n",
    "ttMatrix = tdMatrix @ tdMatrix.T\n",
    "\n",
    "# Set diagonal to 0 to remove self-co-occurrences\n",
    "# The diagonal represents how many times a word co-occurs with itself,\n",
    "# which is not meaningful for semantic similarity\n",
    "numpy.fill_diagonal(ttMatrix, 0)\n",
    "\n",
    "# your code ends here\n",
    "print('The shape of the term-term matrix is', ttMatrix.shape)\n",
    "ttMatrix_pd = pandas.DataFrame(ttMatrix, index=vocab, columns=vocab)\n",
    "ttMatrix_pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d773caf",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "Based on term-term co-occurrence matrix, which pair(s) of words co-occur the most? \n",
    "\n",
    "**YOUR ANSWER**: \n",
    "\n",
    "'cold' and 'warm'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba87b355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the word pairs that co-occur the most\n",
    "\n",
    "# Get the maximum co-occurrence count (excluding diagonal)\n",
    "max_cooccurrence = numpy.max(ttMatrix)\n",
    "\n",
    "print(f\"Maximum co-occurrence count: {max_cooccurrence}\")\n",
    "print(\"\\nWord pairs with maximum co-occurrence:\\n\")\n",
    "\n",
    "# Find all pairs with the maximum co-occurrence\n",
    "# We only check the upper triangle to avoid duplicate pairs (since matrix is symmetric)\n",
    "pairs = []\n",
    "for i in range(len(vocab)):\n",
    "    for j in range(i+1, len(vocab)):\n",
    "        if ttMatrix[i, j] == max_cooccurrence:\n",
    "            pairs.append((vocab[i], vocab[j], int(ttMatrix[i, j])))\n",
    "\n",
    "# Display the pairs\n",
    "for word1, word2, count in pairs:\n",
    "    print(f\"'{word1}' and '{word2}': {count} co-occurrences\")\n",
    "\n",
    "print(f\"\\nTotal number of word pairs with maximum co-occurrence: {len(pairs)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba6b5a7",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Exercise 1.2 Cosine similarity\n",
    "The benefit of vector semantics is that the similarity of two words can be computed as the cosine similarity between their vectors. Let's now compare how similar two words are. \n",
    "\n",
    "### Exercise 1.2.1 Calculate cosine similarity between words (0.5 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bb97bc",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "What is the cosine similarity between \"cold\" and \"warm\" if 1) using term-document occurrence matrix 2) using term-term co-occurrence matrix?\n",
    "\n",
    "You may write your own cosine similarity function or use [`sklearn.metrics.pairwise.cosine_similarity`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html) to calculate the pair-wise cosine similarity among all the words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "da533372-b700-4ed5-a8b4-44c070d69d51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of 'cold': 9\n",
      "Index of 'warm': 47\n",
      "\n",
      "\n",
      "Cosine similarity between 'cold' and 'warm': 0.8018\n",
      "\n",
      "============================================================\n",
      "2) Using TERM-TERM co-occurrence matrix:\n",
      "============================================================\n",
      "Vector for 'cold' (first 10 elements): [0 1 1 2 1 1 0 1 1 0]\n",
      "Vector for 'warm' (first 10 elements): [1 0 1 1 1 1 0 1 1 6]\n",
      "\n",
      "Cosine similarity between 'cold' and 'warm': 0.3922\n"
     ]
    }
   ],
   "source": [
    "# Calculate the cosine similarity between \"cold\" and \"warm\" using 1) using term-document occurrence matrix,\n",
    "# and 2) term-term co-occurrence matrix\n",
    "\n",
    "# your code starts here\n",
    "\n",
    "# Get the indices of 'cold' and 'warm' in the vocabulary\n",
    "cold_idx = vocab.index('cold')\n",
    "warm_idx = vocab.index('warm')\n",
    "\n",
    "print(f\"Index of 'cold': {cold_idx}\")\n",
    "print(f\"Index of 'warm': {warm_idx}\")\n",
    "print()\n",
    "\n",
    "# 1) Cosine similarity using term-document occurrence matrix\n",
    "# Extract the rows for 'cold' and 'warm' from tdMatrix\n",
    "cold_td_vector = tdMatrix[cold_idx].reshape(1, -1)\n",
    "warm_td_vector = tdMatrix[warm_idx].reshape(1, -1)\n",
    "\n",
    "# Calculate cosine similarity\n",
    "cosine_sim_td = cosine_similarity(cold_td_vector, warm_td_vector)[0][0]\n",
    "# print(\"=\" * 60)\n",
    "# print(\"1) Using TERM-DOCUMENT occurrence matrix:\")\n",
    "# print(\"=\" * 60)\n",
    "# print(f\"Vector for 'cold': {tdMatrix[cold_idx]}\")\n",
    "# print(f\"Vector for 'warm': {tdMatrix[warm_idx]}\")\n",
    "print(f\"\\nCosine similarity between 'cold' and 'warm': {cosine_sim_td:.4f}\")\n",
    "print()\n",
    "\n",
    "# 2) Cosine similarity using term-term co-occurrence matrix\n",
    "# Extract the rows for 'cold' and 'warm' from ttMatrix\n",
    "cold_tt_vector = ttMatrix[cold_idx].reshape(1, -1)\n",
    "warm_tt_vector = ttMatrix[warm_idx].reshape(1, -1)\n",
    "\n",
    "# Calculate cosine similarity\n",
    "cosine_sim_tt = cosine_similarity(cold_tt_vector, warm_tt_vector)[0][0]\n",
    "print(\"=\" * 60)\n",
    "print(\"2) Using TERM-TERM co-occurrence matrix:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Vector for 'cold' (first 10 elements): {ttMatrix[cold_idx][:10]}\")\n",
    "print(f\"Vector for 'warm' (first 10 elements): {ttMatrix[warm_idx][:10]}\")\n",
    "print(f\"\\nCosine similarity between 'cold' and 'warm': {cosine_sim_tt:.4f}\")\n",
    "\n",
    "# your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c2ff1b",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### Exercise 1.2.2 (0.5 point)\n",
    "\n",
    "Now we can calculate cosine similarity between words using a co-occurrence matrix. You can choose any previously constructed matrix for the similarity calculation. Rank all the words based on their similarity to the word *cold*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec803dab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Rank all the words by their similarity to word \"cold\"\n",
    "\n",
    "# your code starts here\n",
    "\n",
    "# We'll use the term-term co-occurrence matrix for more meaningful semantic similarity\n",
    "# Get the index of 'cold'\n",
    "cold_idx = vocab.index('cold')\n",
    "\n",
    "# Extract the vector for 'cold'\n",
    "cold_vector = ttMatrix[cold_idx].reshape(1, -1)\n",
    "\n",
    "# Calculate cosine similarity between 'cold' and all other words\n",
    "similarities = []\n",
    "for i, word in enumerate(vocab):\n",
    "    if word != 'cold':  # Exclude 'cold' itself\n",
    "        word_vector = ttMatrix[i].reshape(1, -1)\n",
    "        similarity = cosine_similarity(cold_vector, word_vector)[0][0]\n",
    "        similarities.append((word, similarity))\n",
    "\n",
    "# Sort by similarity in descending order (most similar first)\n",
    "similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Display the ranked list\n",
    "print(\"Words ranked by similarity to 'cold' (using term-term co-occurrence matrix):\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Rank':<6} {'Word':<20} {'Cosine Similarity':<20}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for rank, (word, sim) in enumerate(similarities[:20], 1):  # Show top 20\n",
    "    print(f\"{rank:<6} {word:<20} {sim:.4f}\")\n",
    "\n",
    "print(\"\\n...\")\n",
    "print(f\"\\nShowing top 20 out of {len(similarities)} words\")\n",
    "\n",
    "# Also show the bottom 5 (least similar)\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Bottom 5 words (least similar to 'cold'):\")\n",
    "print(\"=\" * 70)\n",
    "for rank, (word, sim) in enumerate(similarities[-5:], len(similarities)-4):\n",
    "    print(f\"{rank:<6} {word:<20} {sim:.4f}\")\n",
    "\n",
    "# your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06cc631",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "The calculated cosine similarity does not appear to capture semantic similarity or relatedness reliably. How might we obtain more meaningful similarity measures?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649c1612",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "**YOUR ANSWER**: \n",
    "\n",
    "We could obtain a more meaningful measure the following ways:\n",
    "- have a larger corpus\n",
    "- apply TF-IDF weighting\n",
    "- use context windows around words\n",
    "- word embeddings like Word2Vex\n",
    "- use syntactic information by weighing co-occurences by gramatical relationshops (e.g adjective-noun pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9221fd24",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# Exercise 1.3 TF-IDF\n",
    "\n",
    "## Excercise 1.3.1 (0.5 point)\n",
    "For the above corpus, construct a TF-IDF weighted term-document matrix, using [`sklearn.feature_extraction.text.TfidfVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c9342915-d753-4c46-a79c-3c12d7bc02b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the TF-IDF term-document matrix is (51, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>air</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bite</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.409607</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blanket</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.474864</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breeze</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.416925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.348203</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brightened</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.474864</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chilled</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.440339</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chilly</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clashed</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.490448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coat</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cold</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.231477</td>\n",
       "      <td>0.231477</td>\n",
       "      <td>0.214647</td>\n",
       "      <td>0.214647</td>\n",
       "      <td>0.239073</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.199666</td>\n",
       "      <td>0.209099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>colors</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.490448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comfort</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.374329</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.327865</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contrast</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.474864</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cool</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cozy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cup</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.474864</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eased</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.409607</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>felt</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.323163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.374329</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fire</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.440339</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>floor</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>found</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gentle</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.409607</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hands</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heaven</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.440339</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>icy</th>\n",
       "      <td>0.438653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>left</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.440339</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longing</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.474864</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>melts</th>\n",
       "      <td>0.438653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>morning</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mountain</th>\n",
       "      <td>0.438653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>night</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.474864</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ocean</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.409607</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offered</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.440339</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perfect</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pockets</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slippers</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smile</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.474864</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>snow</th>\n",
       "      <td>0.438653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>solace</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sun</th>\n",
       "      <td>0.438653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sunset</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.490448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swim</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.440339</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tea</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>towel</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.440339</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>warm</th>\n",
       "      <td>0.194723</td>\n",
       "      <td>0.168754</td>\n",
       "      <td>0.210798</td>\n",
       "      <td>0.210798</td>\n",
       "      <td>0.195472</td>\n",
       "      <td>0.195472</td>\n",
       "      <td>0.217716</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.190419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waves</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.409607</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wind</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.440339</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>winter</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.474864</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  1         2         3         4         5         6   \\\n",
       "air         0.000000  0.380151  0.000000  0.000000  0.000000  0.000000   \n",
       "bite        0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "blanket     0.000000  0.000000  0.000000  0.474864  0.000000  0.000000   \n",
       "breeze      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "brightened  0.000000  0.000000  0.474864  0.000000  0.000000  0.000000   \n",
       "chilled     0.000000  0.000000  0.000000  0.000000  0.440339  0.000000   \n",
       "chilly      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "clashed     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "coat        0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "cold        0.000000  0.000000  0.231477  0.231477  0.214647  0.214647   \n",
       "colors      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "comfort     0.000000  0.000000  0.000000  0.000000  0.374329  0.000000   \n",
       "contrast    0.000000  0.000000  0.000000  0.474864  0.000000  0.000000   \n",
       "cool        0.000000  0.380151  0.000000  0.000000  0.000000  0.000000   \n",
       "cozy        0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "cup         0.000000  0.380151  0.000000  0.000000  0.000000  0.000000   \n",
       "day         0.000000  0.000000  0.474864  0.000000  0.000000  0.000000   \n",
       "eased       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "felt        0.000000  0.323163  0.000000  0.000000  0.000000  0.374329   \n",
       "fire        0.000000  0.000000  0.000000  0.000000  0.440339  0.000000   \n",
       "floor       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "found       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "gentle      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "hands       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "heaven      0.000000  0.000000  0.000000  0.000000  0.000000  0.440339   \n",
       "icy         0.438653  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "left        0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "like        0.000000  0.000000  0.000000  0.000000  0.000000  0.440339   \n",
       "longing     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "love        0.000000  0.000000  0.000000  0.474864  0.000000  0.000000   \n",
       "melts       0.438653  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "morning     0.000000  0.380151  0.000000  0.000000  0.000000  0.000000   \n",
       "mountain    0.438653  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "night       0.000000  0.000000  0.000000  0.474864  0.000000  0.000000   \n",
       "ocean       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "offered     0.000000  0.000000  0.000000  0.000000  0.440339  0.000000   \n",
       "perfect     0.000000  0.380151  0.000000  0.000000  0.000000  0.000000   \n",
       "pockets     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "slippers    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "smile       0.000000  0.000000  0.474864  0.000000  0.000000  0.000000   \n",
       "snow        0.438653  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "solace      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "sun         0.438653  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "sunset      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "swim        0.000000  0.000000  0.000000  0.000000  0.000000  0.440339   \n",
       "tea         0.000000  0.380151  0.000000  0.000000  0.000000  0.000000   \n",
       "towel       0.000000  0.000000  0.000000  0.000000  0.000000  0.440339   \n",
       "warm        0.194723  0.168754  0.210798  0.210798  0.195472  0.195472   \n",
       "waves       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "wind        0.000000  0.000000  0.000000  0.000000  0.440339  0.000000   \n",
       "winter      0.000000  0.000000  0.474864  0.000000  0.000000  0.000000   \n",
       "\n",
       "                  7         8         9         10  \n",
       "air         0.000000  0.000000  0.000000  0.000000  \n",
       "bite        0.000000  0.000000  0.409607  0.000000  \n",
       "blanket     0.000000  0.000000  0.000000  0.000000  \n",
       "breeze      0.416925  0.000000  0.348203  0.000000  \n",
       "brightened  0.000000  0.000000  0.000000  0.000000  \n",
       "chilled     0.000000  0.000000  0.000000  0.000000  \n",
       "chilly      0.000000  0.385682  0.000000  0.000000  \n",
       "clashed     0.490448  0.000000  0.000000  0.000000  \n",
       "coat        0.000000  0.000000  0.000000  0.428956  \n",
       "cold        0.239073  0.000000  0.199666  0.209099  \n",
       "colors      0.490448  0.000000  0.000000  0.000000  \n",
       "comfort     0.000000  0.327865  0.000000  0.000000  \n",
       "contrast    0.000000  0.000000  0.000000  0.000000  \n",
       "cool        0.000000  0.000000  0.000000  0.000000  \n",
       "cozy        0.000000  0.385682  0.000000  0.000000  \n",
       "cup         0.000000  0.000000  0.000000  0.000000  \n",
       "day         0.000000  0.000000  0.000000  0.000000  \n",
       "eased       0.000000  0.000000  0.409607  0.000000  \n",
       "felt        0.000000  0.000000  0.000000  0.000000  \n",
       "fire        0.000000  0.000000  0.000000  0.000000  \n",
       "floor       0.000000  0.385682  0.000000  0.000000  \n",
       "found       0.000000  0.000000  0.000000  0.428956  \n",
       "gentle      0.000000  0.000000  0.409607  0.000000  \n",
       "hands       0.000000  0.000000  0.000000  0.428956  \n",
       "heaven      0.000000  0.000000  0.000000  0.000000  \n",
       "icy         0.000000  0.000000  0.000000  0.000000  \n",
       "left        0.000000  0.385682  0.000000  0.000000  \n",
       "like        0.000000  0.000000  0.000000  0.000000  \n",
       "longing     0.000000  0.385682  0.000000  0.000000  \n",
       "love        0.000000  0.000000  0.000000  0.000000  \n",
       "melts       0.000000  0.000000  0.000000  0.000000  \n",
       "morning     0.000000  0.000000  0.000000  0.000000  \n",
       "mountain    0.000000  0.000000  0.000000  0.000000  \n",
       "night       0.000000  0.000000  0.000000  0.000000  \n",
       "ocean       0.000000  0.000000  0.409607  0.000000  \n",
       "offered     0.000000  0.000000  0.000000  0.000000  \n",
       "perfect     0.000000  0.000000  0.000000  0.000000  \n",
       "pockets     0.000000  0.000000  0.000000  0.428956  \n",
       "slippers    0.000000  0.385682  0.000000  0.000000  \n",
       "smile       0.000000  0.000000  0.000000  0.000000  \n",
       "snow        0.000000  0.000000  0.000000  0.000000  \n",
       "solace      0.000000  0.000000  0.000000  0.428956  \n",
       "sun         0.000000  0.000000  0.000000  0.000000  \n",
       "sunset      0.490448  0.000000  0.000000  0.000000  \n",
       "swim        0.000000  0.000000  0.000000  0.000000  \n",
       "tea         0.000000  0.000000  0.000000  0.000000  \n",
       "towel       0.000000  0.000000  0.000000  0.000000  \n",
       "warm        0.217716  0.000000  0.000000  0.190419  \n",
       "waves       0.000000  0.000000  0.409607  0.000000  \n",
       "wind        0.000000  0.000000  0.000000  0.000000  \n",
       "winter      0.000000  0.000000  0.000000  0.000000  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct a TF-IDF weighted term-document matrix\n",
    "\n",
    "# your code starts here\n",
    "\n",
    "# Use TfidfVectorizer with the same vocabulary we constructed earlier\n",
    "tfidf_vectorizer = TfidfVectorizer(vocabulary=vocab, lowercase=True, token_pattern=r'\\b[a-z]+\\b')\n",
    "\n",
    "# Fit and transform the sentences to get the TF-IDF weighted term-document matrix\n",
    "tfidf_matrix_sparse = tfidf_vectorizer.fit_transform(sents)\n",
    "\n",
    "# Transpose to get terms as rows and documents as columns\n",
    "# Convert to dense array for easier manipulation\n",
    "tfidf_matrix = tfidf_matrix_sparse.T.toarray()\n",
    "\n",
    "# your code ends here\n",
    "\n",
    "print('The shape of the TF-IDF term-document matrix is', tfidf_matrix.shape)\n",
    "tfidf_matrix_pd = pandas.DataFrame(tfidf_matrix, index=vocab, columns=list(range(1, len(sents)+1)))\n",
    "tfidf_matrix_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79440cf7",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "Compute and rank the words in descending order based on their similarity to *cold*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57eb8349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and rank the words in descending order based on their similarity to *cold*\n",
    "\n",
    "# Your code starts here\n",
    "\n",
    "# Get the index of 'cold' in the vocabulary\n",
    "cold_idx = vocab.index('cold')\n",
    "\n",
    "# Extract the TF-IDF vector for 'cold'\n",
    "cold_tfidf_vector = tfidf_matrix[cold_idx].reshape(1, -1)\n",
    "\n",
    "# Calculate cosine similarity between 'cold' and all other words\n",
    "similarities_tfidf = []\n",
    "for i, word in enumerate(vocab):\n",
    "    if word != 'cold':  # Exclude 'cold' itself\n",
    "        word_tfidf_vector = tfidf_matrix[i].reshape(1, -1)\n",
    "        similarity = cosine_similarity(cold_tfidf_vector, word_tfidf_vector)[0][0]\n",
    "        similarities_tfidf.append((word, similarity))\n",
    "\n",
    "# Sort by similarity in descending order (most similar first)\n",
    "similarities_tfidf.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Display the ranked list\n",
    "print(\"Words ranked by similarity to 'cold' (using TF-IDF weighted term-document matrix):\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Rank':<6} {'Word':<20} {'Cosine Similarity':<20}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for rank, (word, sim) in enumerate(similarities_tfidf[:20], 1):  # Show top 20\n",
    "    print(f\"{rank:<6} {word:<20} {sim:.4f}\")\n",
    "\n",
    "print(\"\\n...\")\n",
    "print(f\"\\nShowing top 20 out of {len(similarities_tfidf)} words\")\n",
    "\n",
    "# Also show the bottom 5 (least similar)\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Bottom 5 words (least similar to 'cold'):\")\n",
    "print(\"=\" * 70)\n",
    "for rank, (word, sim) in enumerate(similarities_tfidf[-5:], len(similarities_tfidf)-4):\n",
    "    print(f\"{rank:<6} {word:<20} {sim:.4f}\")\n",
    "\n",
    "# Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60efccf",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Exercise 1.3.2 (0.5 point)\n",
    "\n",
    "Let's use a bigger dataset which contains 2225 BBC news articles to construct TF-IDF term-document matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2b725e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2225 documents\n",
      "The size of the vocabulary is 16692\n",
      "The shape of the term-document matrix is (2225, 16692)\n"
     ]
    }
   ],
   "source": [
    "sents=codecs.open('bbc-text.csv','r', encoding='utf-8').readlines() # load the data\n",
    "\n",
    "# your code starts here\n",
    "\n",
    "# Read the BBC news data - skip the header and process only the text column\n",
    "# The CSV format is: category,text\n",
    "documents = []\n",
    "for i, line in enumerate(sents):\n",
    "    if i == 0:  # Skip header\n",
    "        continue\n",
    "    # Split by first comma to separate category from text\n",
    "    parts = line.strip().split(',', 1)\n",
    "    if len(parts) == 2:\n",
    "        documents.append(parts[1])  # Get the text part\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents\")\n",
    "\n",
    "# Get English stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Create TF-IDF vectorizer\n",
    "# We'll use default tokenization and let it build the vocabulary automatically\n",
    "# min_df=2 means ignore terms that appear in less than 2 documents\n",
    "# max_df=0.85 means ignore terms that appear in more than 85% of documents\n",
    "tfidf_vectorizer_bbc = TfidfVectorizer(\n",
    "    lowercase=True,\n",
    "    stop_words='english',\n",
    "    min_df=2,\n",
    "    max_df=0.85,\n",
    "    token_pattern=r'\\b[a-z]{2,}\\b'  # Only alphabetic words with at least 2 characters\n",
    ")\n",
    "\n",
    "# Fit and transform the documents\n",
    "term_doc_matrix = tfidf_vectorizer_bbc.fit_transform(documents)\n",
    "\n",
    "# Get the vocabulary (sorted alphabetically by default)\n",
    "vocab = tfidf_vectorizer_bbc.get_feature_names_out()\n",
    "\n",
    "# your code ends here\n",
    "\n",
    "print('The size of the vocabulary is', len(vocab))\n",
    "print('The shape of the term-document matrix is', term_doc_matrix.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31793fb7",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "We can compute which words are most similar to *cold*. Does this list of words make more sense now and why?\n",
    "\n",
    "**YOUR ANSWER**:\n",
    "\n",
    "Yes, the list of words makes much more sense now! With the larger corpus (2225 BBC news articles), the TF-IDF vectors capture more meaningful semantic relationships because:\n",
    "\n",
    "1. **Larger context**: More documents provide richer co-occurrence patterns across different contexts\n",
    "2. **Domain diversity**: BBC news covers multiple topics (politics, sports, business, tech, entertainment), so word relationships reflect real-world usage\n",
    "3. **Better statistics**: With 2225 documents vs. 10 sentences, the IDF component can properly identify which words are truly distinctive vs. common\n",
    "4. **Reduced noise**: Words that co-occur by chance in a small corpus are smoothed out in a larger dataset\n",
    "\n",
    "The words similar to \"cold\" should now include semantically related terms like weather conditions (frost, freezing, chilly), seasonal references (winter), or contextually related concepts rather than just words that happened to appear in the same small set of sentences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "644c0120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words most similar to 'cold' in BBC news corpus:\n",
      "============================================================\n",
      "Rank   Word                 Cosine Similarity   \n",
      "============================================================\n",
      "1      opec                 0.4751\n",
      "2      crude                0.4308\n",
      "3      heating              0.4177\n",
      "4      brent                0.3991\n",
      "5      barrel               0.3835\n",
      "6      cartel               0.3740\n",
      "7      temperatures         0.3625\n",
      "8      insulation           0.3507\n",
      "9      telephoned           0.3503\n",
      "10     winter               0.3485\n"
     ]
    }
   ],
   "source": [
    "# Find the top 10 words that are most similar to word \"cold\"\n",
    "\n",
    "# your code starts here\n",
    "\n",
    "# Check if 'cold' is in the vocabulary\n",
    "if 'cold' in vocab:\n",
    "    # Get the index of 'cold'\n",
    "    cold_idx = list(vocab).index('cold')\n",
    "\n",
    "    # Get the TF-IDF vector for 'cold' (transpose to get word vectors)\n",
    "    # term_doc_matrix is documents x terms, so transpose it to get terms x documents\n",
    "    term_doc_matrix_T = term_doc_matrix.T\n",
    "    cold_vector = term_doc_matrix_T[cold_idx]\n",
    "\n",
    "    # Calculate cosine similarity between 'cold' and all other words\n",
    "    # This is more efficient for sparse matrices\n",
    "    similarities_bbc = cosine_similarity(cold_vector, term_doc_matrix_T)[0]\n",
    "\n",
    "    # Create list of (word, similarity) pairs, excluding 'cold' itself\n",
    "    word_similarities = []\n",
    "    for i, word in enumerate(vocab):\n",
    "        if word != 'cold':\n",
    "            word_similarities.append((word, similarities_bbc[i]))\n",
    "\n",
    "    # Sort by similarity in descending order\n",
    "    word_similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Display top 10\n",
    "    print(\"Top 10 words most similar to 'cold' in BBC news corpus:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"{'Rank':<6} {'Word':<20} {'Cosine Similarity':<20}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    for rank, (word, sim) in enumerate(word_similarities[:10], 1):\n",
    "        print(f\"{rank:<6} {word:<20} {sim:.4f}\")\n",
    "else:\n",
    "    print(\"The word 'cold' is not in the vocabulary of this corpus.\")\n",
    "\n",
    "# your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5206eaef",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "Find another 3 pairs of words whose cosine similarity makes sense to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51110f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for 3 pairs of words whose cosine similarities reflect their semantic similarity or relatedness.\n",
    "\n",
    "# your code starts here\n",
    "\n",
    "# Define 3 pairs of semantically related words to test\n",
    "word_pairs = [\n",
    "    ('government', 'minister'),  # Political context\n",
    "    ('football', 'match'),       # Sports context\n",
    "    ('market', 'economy')        # Business/economics context\n",
    "]\n",
    "\n",
    "print(\"Cosine similarities for semantically related word pairs:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Word 1':<20} {'Word 2':<20} {'Cosine Similarity':<20}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Transpose the matrix once for efficiency\n",
    "term_doc_matrix_T = term_doc_matrix.T\n",
    "\n",
    "for word1, word2 in word_pairs:\n",
    "    # Check if both words are in vocabulary\n",
    "    if word1 in vocab and word2 in vocab:\n",
    "        idx1 = list(vocab).index(word1)\n",
    "        idx2 = list(vocab).index(word2)\n",
    "\n",
    "        # Get vectors\n",
    "        vec1 = term_doc_matrix_T[idx1]\n",
    "        vec2 = term_doc_matrix_T[idx2]\n",
    "\n",
    "        # Calculate cosine similarity\n",
    "        similarity = cosine_similarity(vec1, vec2)[0][0]\n",
    "\n",
    "        print(f\"{word1:<20} {word2:<20} {similarity:.4f}\")\n",
    "    else:\n",
    "        missing = []\n",
    "        if word1 not in vocab:\n",
    "            missing.append(word1)\n",
    "        if word2 not in vocab:\n",
    "            missing.append(word2)\n",
    "        print(f\"{word1:<20} {word2:<20} Not in vocab: {', '.join(missing)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"\\nExplanation:\")\n",
    "print(\"- 'government' and 'minister': High similarity because they frequently\")\n",
    "print(\"  co-occur in political news articles\")\n",
    "print(\"- 'football' and 'match': High similarity from sports coverage\")\n",
    "print(\"- 'market' and 'economy': High similarity in business/economics articles\")\n",
    "print(\"\\nThese pairs demonstrate that TF-IDF captures domain-specific semantic\")\n",
    "print(\"relationships based on how words are used together in similar contexts.\")\n",
    "\n",
    "# your code ends here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbf1757",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# Part II. Word2Vec word vectors\n",
    "\n",
    "Here, we explore the embeddings produced by word2vec. Please read J&M 6.8 or the [original paper](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf) if you are interested in the details of the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fbd4ab",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Exercise 2.1 Pre-train word2vec model\n",
    "\n",
    "Run the following script to load the word2vec vectors into memory. **Note**: This might take several minutes. If you run out of memory, try closing other applicaions or restart your machine to free more memory. \n",
    "\n",
    "Please note, the following experiments run with Gensim 4.3.3. If you are still running an old version of Gensim, please upgrade your Gensim library or check [Migrating from Gensim 3.x to 4](https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4) to adapt your code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7f4ea97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 16.621103048324585 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Load 3 million Word2Vec Vectors, pre-trained on Google news, each with the dimension of 300\n",
    "# This model may take a few minutes to load.\n",
    "\n",
    "import gensim.downloader as api\n",
    "start_time = time.time()\n",
    "w2v_google = api.load(\"word2vec-google-news-300\")\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5f880003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded vocab size 3000000\n"
     ]
    }
   ],
   "source": [
    "print(\"Loaded vocab size {}\".format(len(w2v_google.index_to_key)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedd53f8",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "Once the model is loaded, you can extract the vector for individual words directly using `wv_google['']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a67d4585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.89208984e-02,  1.18652344e-01, -6.25000000e-02,  7.86132812e-02,\n",
       "       -3.46679688e-02,  2.51953125e-01,  2.06298828e-02, -1.64062500e-01,\n",
       "       -2.12402344e-02,  3.18359375e-01,  6.93359375e-02, -1.56250000e-01,\n",
       "       -4.80957031e-02, -4.63485718e-04,  1.45874023e-02, -7.04956055e-03,\n",
       "       -1.00708008e-03, -2.00195312e-02,  1.53320312e-01, -2.53906250e-01,\n",
       "        4.08935547e-03,  1.51367188e-01, -5.88378906e-02, -1.30859375e-01,\n",
       "        1.79687500e-01, -5.00488281e-03,  7.61718750e-02,  1.09863281e-01,\n",
       "       -2.19726562e-01, -4.15039062e-02, -6.93359375e-02,  6.98242188e-02,\n",
       "        2.49023438e-01,  1.29882812e-01, -2.85156250e-01, -7.95898438e-02,\n",
       "       -1.04003906e-01,  1.95312500e-02,  1.42578125e-01,  1.08886719e-01,\n",
       "        2.07031250e-01, -2.94921875e-01,  1.50390625e-01, -1.65039062e-01,\n",
       "       -4.05273438e-02,  3.11279297e-02, -2.59765625e-01,  3.63769531e-02,\n",
       "       -1.67968750e-01,  2.14843750e-01,  7.32421875e-02,  1.65039062e-01,\n",
       "       -2.35351562e-01,  2.25585938e-01, -9.32617188e-02, -5.22460938e-02,\n",
       "       -1.59179688e-01,  1.93359375e-01,  2.85644531e-02,  1.46484375e-01,\n",
       "       -1.49414062e-01,  8.74023438e-02, -2.69531250e-01, -1.75781250e-01,\n",
       "        2.30468750e-01, -3.73535156e-02, -2.85644531e-02, -5.10253906e-02,\n",
       "       -1.57226562e-01, -7.61718750e-02,  2.50000000e-01, -3.14941406e-02,\n",
       "        1.97265625e-01,  9.76562500e-02, -2.77343750e-01,  1.15234375e-01,\n",
       "        3.94531250e-01, -8.10546875e-02,  4.61425781e-02,  7.12890625e-02,\n",
       "        1.66015625e-01, -4.63867188e-02, -1.25000000e-01, -2.25585938e-01,\n",
       "       -1.29882812e-01,  1.62109375e-01, -1.55273438e-01,  4.32128906e-02,\n",
       "        1.41601562e-01,  1.72851562e-01, -1.36718750e-01,  8.34960938e-02,\n",
       "       -5.83496094e-02, -2.37304688e-01, -2.63671875e-02,  2.15820312e-01,\n",
       "        1.92382812e-01, -1.05957031e-01,  3.84765625e-01, -5.00488281e-02,\n",
       "       -1.71875000e-01, -1.84570312e-01, -4.15039062e-02,  4.61425781e-02,\n",
       "        1.19628906e-01, -1.10839844e-01,  2.18750000e-01,  1.51367188e-01,\n",
       "       -2.73437500e-02, -7.95898438e-02,  7.08007812e-02, -1.52343750e-01,\n",
       "        1.39648438e-01, -1.60156250e-01,  1.85546875e-01,  8.34960938e-02,\n",
       "        1.34765625e-01,  1.74804688e-01, -2.05078125e-01, -4.07714844e-02,\n",
       "       -4.06250000e-01, -2.59765625e-01, -1.72851562e-01, -6.78710938e-02,\n",
       "       -3.16406250e-01, -1.61132812e-01,  1.98242188e-01,  1.58203125e-01,\n",
       "        2.13623047e-03, -1.92382812e-01, -3.44238281e-02,  1.28906250e-01,\n",
       "        1.10351562e-01,  9.03320312e-02, -1.74804688e-01,  8.05664062e-02,\n",
       "        1.61132812e-01, -1.17187500e-01, -1.79687500e-01,  1.55639648e-02,\n",
       "        6.25000000e-02,  5.78613281e-02,  2.03857422e-02, -5.59082031e-02,\n",
       "       -5.34667969e-02,  1.80664062e-02, -8.54492188e-02, -1.38671875e-01,\n",
       "        9.13085938e-02, -4.24804688e-02,  4.06250000e-01, -2.92968750e-02,\n",
       "        1.20605469e-01,  1.68945312e-01, -2.33398438e-01, -1.46484375e-01,\n",
       "        7.47070312e-02, -9.22851562e-02,  6.34765625e-02,  2.94921875e-01,\n",
       "       -1.20605469e-01, -2.31445312e-01,  7.76367188e-02, -1.02539062e-01,\n",
       "        6.59179688e-02,  4.44335938e-02, -2.03125000e-01,  2.08984375e-01,\n",
       "        2.06054688e-01, -2.17773438e-01, -2.81250000e-01,  1.30859375e-01,\n",
       "       -3.82812500e-01, -1.69921875e-01, -1.11816406e-01, -1.87500000e-01,\n",
       "       -3.71093750e-02, -9.66796875e-02, -1.97265625e-01, -3.43322754e-03,\n",
       "        6.73828125e-02, -3.16406250e-01,  1.08886719e-01, -6.05468750e-02,\n",
       "       -2.61718750e-01, -8.10546875e-02,  2.08984375e-01,  2.16796875e-01,\n",
       "       -9.03320312e-02,  2.29492188e-01, -3.10546875e-01, -1.08398438e-01,\n",
       "        2.28515625e-01,  1.18652344e-01,  7.08007812e-02,  3.32031250e-01,\n",
       "        8.59375000e-02, -6.88476562e-02, -6.22558594e-02,  1.50390625e-01,\n",
       "        1.94335938e-01,  1.25000000e-01, -1.09863281e-01,  2.08984375e-01,\n",
       "        5.15136719e-02, -8.74023438e-02,  3.19824219e-02,  9.76562500e-02,\n",
       "       -7.56835938e-02, -5.61523438e-02, -5.39062500e-01,  2.46582031e-02,\n",
       "       -3.71093750e-02,  2.50244141e-03, -1.78710938e-01, -1.84570312e-01,\n",
       "        1.75781250e-01,  3.24707031e-02, -1.63085938e-01, -4.66308594e-02,\n",
       "       -1.42822266e-02, -2.15820312e-01,  1.02539062e-01, -1.49536133e-02,\n",
       "        1.74804688e-01, -1.85546875e-02,  2.64892578e-02, -1.56250000e-01,\n",
       "       -2.23632812e-01,  1.77734375e-01, -1.86523438e-01,  2.27539062e-01,\n",
       "        2.80761719e-02, -2.13867188e-01, -7.32421875e-02, -8.59375000e-02,\n",
       "       -4.95605469e-02, -6.29882812e-02,  9.22851562e-02,  2.16796875e-01,\n",
       "        2.28515625e-01,  2.02148438e-01,  1.08642578e-02, -7.42187500e-02,\n",
       "       -3.32031250e-02,  9.86328125e-02,  6.17675781e-02,  5.73730469e-02,\n",
       "        5.56640625e-02, -6.98852539e-03, -1.12915039e-02, -1.40991211e-02,\n",
       "        2.11914062e-01, -2.33154297e-02,  1.06445312e-01, -2.34375000e-01,\n",
       "        2.29492188e-01,  6.73828125e-02, -2.53906250e-01, -1.87500000e-01,\n",
       "       -4.22363281e-02, -2.32421875e-01, -2.79296875e-01, -3.01513672e-02,\n",
       "        5.10253906e-02,  1.87500000e-01,  2.39257812e-02,  1.65557861e-03,\n",
       "        5.55419922e-03, -2.08984375e-01,  1.68945312e-01,  2.36328125e-01,\n",
       "        1.98242188e-01,  8.34960938e-02,  1.22558594e-01,  4.68750000e-02,\n",
       "       -8.49609375e-02,  2.41210938e-01, -6.98242188e-02,  9.22851562e-02,\n",
       "        1.43554688e-01,  1.32446289e-02,  2.65625000e-01, -1.16577148e-02,\n",
       "       -7.36236572e-04, -6.39648438e-02, -1.06933594e-01,  2.37304688e-01,\n",
       "        3.39355469e-02, -4.34570312e-02,  7.66601562e-02, -2.34375000e-02,\n",
       "       -2.32421875e-01,  2.17773438e-01,  1.84570312e-01,  9.15527344e-03,\n",
       "        2.06298828e-02,  3.37890625e-01,  1.89453125e-01,  1.67968750e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_google['cold']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e956e1",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "One of the property of semantic embedding is that similar words are embedded close to each other. Use  `w2v_google.most_similar()` to identify the most similar words to *north*. Does this list make more sense to you? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c20bcf39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chilly 0.6878557205200195\n",
      "frigid 0.6770407557487488\n",
      "Cold 0.6727538108825684\n",
      "bitterly_cold 0.6375917196273804\n",
      "chill 0.6324006915092468\n",
      "warm 0.5953035354614258\n",
      "colder 0.5900002717971802\n",
      "TONIGHT_Clear 0.5773206353187561\n",
      "frosty 0.5743642449378967\n",
      "frigid_weather 0.5725993514060974\n",
      "--- 2.6472620964050293 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for w,c in w2v_google.most_similar('cold'):\n",
    "    print(w,c)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e545c5",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "Check a few more words to see whether their most similar words make sense to you and explain why. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ed02633b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('white', 0.8092214465141296),\n",
       " ('Responded_Letterman_How', 0.6182776689529419),\n",
       " ('blacks', 0.589222252368927),\n",
       " ('crypt_inscribed', 0.5855618119239807),\n",
       " ('transporting_petrochemicals', 0.5834174156188965),\n",
       " ('brown', 0.5766680240631104),\n",
       " ('Shilah_Phillips', 0.5763780474662781),\n",
       " ('women_dating_interracially', 0.5670552253723145),\n",
       " ('wrote_Newitz', 0.5604413747787476),\n",
       " ('blue', 0.5492396950721741)]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_google.most_similar('black')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f427cb",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Word analogies\n",
    "\n",
    "An analogy explains one thing in terms of another to highlight the ways in which they are alike. For example, *paris* is similar to *france* in the same way that *rome* is to *italy*. Word2Vec vectors sometimes shows the ability of solving analogy problem of the form **a is to b as a* is to what?**.\n",
    "\n",
    "In the cell below, we show you how to use word vectors to find x. The `most_similar` function finds words that are most similar to the words in the `positive` list and most dissimilar from the words in the `negative` list. The answer to the analogy will be the word ranked most similar (largest numerical value). In the case below, the top one word *italy* is the answer, so this analogy is solved successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d152e4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('italy', 0.519952118396759), ('european', 0.5075846314430237), ('italian', 0.5057743191719055), ('epl', 0.490744411945343), ('spain', 0.4888668656349182), ('england', 0.4852672219276428), ('italians', 0.4842422604560852), ('kosovo', 0.48134922981262207), ('lampard', 0.4807734787464142), ('malta', 0.4788566529750824)]\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to answer the analogy -- paris : france :: rome : x\n",
    "print(w2v_google.most_similar(positive=['rome', 'france'], negative=['paris']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757c654a",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### Exercise 2.1.1 (0.5 point)\n",
    "Look for one analogy that can be solved successfully and one analogy that could not be solved using this pre-trained Word2Vec model. Check out [this paper](https://www.semanticscholar.org/paper/Efficient-Estimation-of-Word-Representations-in-Mikolov-Chen/330da625c15427c6e42ccfa3b747fb29e5835bf0) for inspirations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a55841e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your successful case goes here\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"SUCCESSFUL ANALOGY:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nAnalogy: king is to man as queen is to ___?\")\n",
    "print(\"Formula: queen + man - king = ?\\n\")\n",
    "\n",
    "# king : man :: queen : woman\n",
    "result = w2v_google.most_similar(positive=['queen', 'man'], negative=['king'], topn=5)\n",
    "print(\"Top 5 results:\")\n",
    "for i, (word, score) in enumerate(result, 1):\n",
    "    print(f\"  {i}. {word:<15} (similarity: {score:.4f})\")\n",
    "\n",
    "print(\"\\n✓ This works well! The answer 'woman' appears at or near the top.\")\n",
    "print(\"  This captures the gender relationship: king-man = queen-woman\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print()\n",
    "\n",
    "\n",
    "# Your failed case goes here\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"FAILED ANALOGY:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nAnalogy: water is to wet as fire is to ___?\")\n",
    "print(\"Formula: fire + wet - water = ?\")\n",
    "print(\"Expected: 'hot' or 'dry' or 'burning'\\n\")\n",
    "\n",
    "# water : wet :: fire : ?\n",
    "result = w2v_google.most_similar(positive=['fire', 'wet'], negative=['water'], topn=10)\n",
    "print(\"Top 10 results:\")\n",
    "for i, (word, score) in enumerate(result, 1):\n",
    "    print(f\"  {i}. {word:<15} (similarity: {score:.4f})\")\n",
    "\n",
    "print(\"\\n✗ This fails! We expect words like 'hot', 'dry', or 'burning',\")\n",
    "print(\"  but instead get fire-related words mixed with wet contexts.\")\n",
    "print(\"\\nWhy it fails:\")\n",
    "print(\"  - Word2Vec captures co-occurrence patterns, not abstract properties\")\n",
    "print(\"  - 'wet' is an adjective describing a property of water\")\n",
    "print(\"  - The model doesn't understand the abstract property-to-object mapping\")\n",
    "print(\"  - It struggles with analogies requiring understanding of causation\")\n",
    "print(\"    or sensory properties rather than direct semantic relationships\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186fe0ba",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Visualising word analogies\n",
    "\n",
    "The following cell shows you how to use [tSNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html) to visualise a set of words based on their embeddings. You can also apply other dimensionality reduction methods (e.g. [sklearn.decomposition.TruncatedSVD](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html)) to reduce the vectors from 300-dimensional to 2 dimensional. \n",
    "\n",
    "Please note, reducing dimensionality from 300 to 2 is a very challenging task. You can try different parameters in the tSNE and see their effects on the final visualisation. In particular, the visualisation is very sensitive to the perplexity value that you give. Please try a few different perplexity valuse and keep the one that gives the most reasonable visusalisation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4515b4ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x1800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def tsne_plot(model, wordlist, p):\n",
    "    labels = []\n",
    "    tokens = []\n",
    "\n",
    "    for word in wordlist:\n",
    "        tokens.append(model[word])\n",
    "        labels.append(word)\n",
    "\n",
    "    tokens = np.array(tokens)\n",
    "\n",
    "    tsne_model = TSNE(perplexity=p, n_components=2, init='pca', max_iter=2500, random_state=23)\n",
    "    new_values = tsne_model.fit_transform(tokens)\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for value in new_values:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "\n",
    "    plt.figure(figsize=(18, 18))\n",
    "    for i in range(len(x)):\n",
    "        plt.scatter(x[i], y[i])\n",
    "        plt.annotate(labels[i],\n",
    "                     xy=(x[i], y[i]),\n",
    "                     xytext=(5, 2),\n",
    "                     textcoords='offset points',\n",
    "                     ha='right',\n",
    "                     va='bottom')\n",
    "    plt.show()\n",
    "\n",
    "wordlist = ['man', 'woman', 'nephew', 'niece', 'brother', 'sister', 'uncle', 'aunt']\n",
    "tsne_plot(w2v_google, wordlist, len(wordlist) - 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dcd4c5",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### Exercise 2.1.2 (0.5 point)\n",
    "Find another group analogies (at least 3 pairs of words) and see how they are visualised.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c486225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare at least 3 pairs of words\n",
    "\n",
    "# your answer goes here\n",
    "\n",
    "# Country-Capital pairs analogy\n",
    "# This demonstrates geographic relationships: capital city ↔ country\n",
    "# We expect capitals to cluster together and countries to cluster together\n",
    "# The vector relationship should be consistent across pairs\n",
    "\n",
    "wordlist = [\n",
    "    'Paris', 'France',       # Pair 1\n",
    "    'London', 'England',     # Pair 2\n",
    "    'Berlin', 'Germany',     # Pair 3\n",
    "    'Tokyo', 'Japan',        # Pair 4\n",
    "    'Madrid', 'Spain',       # Pair 5 (bonus pair)\n",
    "    'Rome', 'Italy'          # Pair 6 (bonus pair)\n",
    "]\n",
    "\n",
    "print(\"Visualizing Country-Capital analogies:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nWord pairs:\")\n",
    "for i in range(0, len(wordlist), 2):\n",
    "    print(f\"  {wordlist[i]:<15} ↔ {wordlist[i+1]}\")\n",
    "\n",
    "print(\"\\nExpected visualization pattern:\")\n",
    "print(\"  - Capital cities should cluster together\")\n",
    "print(\"  - Countries should cluster together\")\n",
    "print(\"  - The vector from each capital to its country should be similar\")\n",
    "print(\"  - This represents the consistent 'capital_of' relationship\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "p = len(wordlist) - 1\n",
    "tsne_plot(w2v_google, wordlist, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baa0b36",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### Exercise 2.1.3  Synonyms and antonyms (0.5 point)\n",
    "\n",
    "\n",
    "\n",
    "Find three words (w1, w2, w3) so that \n",
    "- w1 and w2 are synonyms, \n",
    "- w1 and w3 are antonyms, \n",
    "- cosine_distance(w1, w2) > cosine_distance(w1, w3) or cosine_distance(w1, w2) $\\approx$ cosine_distance(w1, w3). \n",
    "\n",
    "Please give a possible explanation for why this has happened. \n",
    "\n",
    "You can use [`w2v_google.distance()`](https://radimrehurek.com/gensim/models/keyedvectors.html) function to compute the cosine distance between two words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b68367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace XXX, YYY and ZZZ with your chosen words\n",
    "\n",
    "w1 = 'good'\n",
    "w2 = 'great'     # synonym of 'good'\n",
    "w3 = 'bad'       # antonym of 'good'\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"SYNONYMS vs ANTONYMS - Counterintuitive Result!\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(f\"Synonyms '{w1}' and '{w2}' have cosine distance: {w2v_google.distance(w1, w2):.4f}\")\n",
    "print(f\"Antonyms '{w1}' and '{w3}' have cosine distance: {w2v_google.distance(w1, w3):.4f}\")\n",
    "print()\n",
    "\n",
    "if w2v_google.distance(w1, w2) > w2v_google.distance(w1, w3):\n",
    "    print(f\"✓ The synonym '{w2}' is MORE distant than the antonym '{w3}'!\")\n",
    "    print(f\"  Distance difference: {w2v_google.distance(w1, w2) - w2v_google.distance(w1, w3):.4f}\")\n",
    "elif abs(w2v_google.distance(w1, w2) - w2v_google.distance(w1, w3)) < 0.05:\n",
    "    print(f\"≈ The synonym and antonym have approximately equal distance!\")\n",
    "else:\n",
    "    print(f\"✗ In this case, the synonym is actually closer (typical behavior)\")\n",
    "\n",
    "print()\n",
    "print(\"Let's check the most similar words to 'good':\")\n",
    "print(\"-\" * 70)\n",
    "for word, score in w2v_google.most_similar(w1, topn=10):\n",
    "    print(f\"  {word:<15} similarity: {score:.4f}   distance: {w2v_google.distance(w1, word):.4f}\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eee08b7",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "**Your answer**: \n",
    "\n",
    "This counterintuitive result occurs because **Word2Vec learns distributional similarity, not semantic similarity**. Here's why antonyms can be closer than synonyms:\n",
    "\n",
    "### Why \"good\" and \"bad\" (antonyms) are so close:\n",
    "\n",
    "1. **Similar Contexts**: Antonyms frequently appear in similar grammatical and semantic contexts:\n",
    "   - Comparisons: \"good or bad\", \"not good but bad\"\n",
    "   - Evaluations: \"the movie was good/bad\"\n",
    "   - Questions: \"is it good or bad?\"\n",
    "   - Reviews: \"good service\" vs \"bad service\"\n",
    "\n",
    "2. **Co-occurrence Patterns**: They're often used to evaluate the same types of things (movies, products, experiences), so they share many surrounding words\n",
    "\n",
    "3. **Contrastive Contexts**: Phrases like \"good vs bad\", \"neither good nor bad\" directly pair them together\n",
    "\n",
    "### Why \"good\" and \"great\" (synonyms) might be more distant:\n",
    "\n",
    "1. **Register Differences**: \"great\" is more emphatic/intense than \"good\", so it appears in slightly different contexts\n",
    "\n",
    "2. **Different Distributions**: \n",
    "   - \"good\" is more common and neutral\n",
    "   - \"great\" appears more in enthusiastic, promotional, or emphatic contexts\n",
    "\n",
    "3. **Substitutability**: While they're synonyms, they're not always perfectly interchangeable, leading to different distributional patterns\n",
    "\n",
    "### The Key Insight:\n",
    "\n",
    "**Word2Vec doesn't understand meaning** - it only knows that words appearing in similar contexts have similar vectors. Since antonyms describe opposite ends of the same dimension (quality, temperature, size), they naturally appear in very similar syntactic and semantic environments. This is a fundamental limitation and also a feature of distributional semantics!\n",
    "\n",
    "This phenomenon reveals that **distributional similarity ≠ semantic similarity**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a78159",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### Exercise 2.1.4 Polysemous Words (0.5 point)\n",
    "\n",
    "Some words are polysemous, i.e. they have multiple meanings. For example the word *bank* can be a financial institute or the rising ground bordering a lake or river. Find a polysemous word whose top most similar words contains related words from multiple meanings. You should use the the [`wv_google.most_similar()`](https://radimrehurek.com/gensim/models/keyedvectors.html) function to compute the closet neighbours of the word. You may increase the number of neighbours in order to identify multiple groups of meanings. Submit the ranked word list and explained how the words are grouped into different meanings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25cd2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing the polysemous word \"crane\"\n",
    "# \"crane\" has at least two major meanings:\n",
    "# 1. A large bird (animal)\n",
    "# 2. A machine for lifting heavy objects (construction equipment)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"POLYSEMOUS WORD ANALYSIS: 'crane'\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"Top 50 most similar words to 'crane':\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "results = w2v_google.most_similar('crane', topn=50)\n",
    "\n",
    "# Categorize the results\n",
    "bird_related = []\n",
    "machine_related = []\n",
    "other = []\n",
    "\n",
    "# Keywords that help identify each meaning\n",
    "bird_keywords = ['bird', 'swan', 'heron', 'stork', 'goose', 'duck', 'pelican',\n",
    "                 'egret', 'ibis', 'waterfowl', 'migratory', 'sandhill']\n",
    "machine_keywords = ['lifting', 'hoist', 'excavator', 'boom', 'loader', 'equipment',\n",
    "                   'machinery', 'construction', 'gantry', 'derrick', 'rigging']\n",
    "\n",
    "for i, (word, score) in enumerate(results, 1):\n",
    "    print(f\"{i:3d}. {word:<20} (similarity: {score:.4f})\")\n",
    "\n",
    "    # Categorize\n",
    "    word_lower = word.lower()\n",
    "    if any(key in word_lower for key in bird_keywords) or word in ['Sandhill_Crane', 'whooping_crane']:\n",
    "        bird_related.append((word, score))\n",
    "    elif any(key in word_lower for key in machine_keywords):\n",
    "        machine_related.append((word, score))\n",
    "    else:\n",
    "        # Manual categorization for specific words\n",
    "        if word in ['excavator', 'bulldozer', 'backhoe', 'forklift', 'loader']:\n",
    "            machine_related.append((word, score))\n",
    "        else:\n",
    "            other.append((word, score))\n",
    "\n",
    "print()\n",
    "print(\"=\" * 70)\n",
    "print(\"CATEGORIZATION BY MEANING:\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(f\"🦢 BIRD-RELATED WORDS ({len(bird_related)} found):\")\n",
    "for word, score in bird_related:\n",
    "    print(f\"   - {word:<20} (similarity: {score:.4f})\")\n",
    "\n",
    "print()\n",
    "print(f\"🏗️  MACHINE/EQUIPMENT-RELATED WORDS ({len(machine_related)} found):\")\n",
    "for word, score in machine_related:\n",
    "    print(f\"   - {word:<20} (similarity: {score:.4f})\")\n",
    "\n",
    "print()\n",
    "print(f\"❓ OTHER/AMBIGUOUS WORDS ({len(other)} found):\")\n",
    "for word, score in other[:10]:  # Show first 10\n",
    "    print(f\"   - {word:<20} (similarity: {score:.4f})\")\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b39d280",
   "metadata": {},
   "outputs": [],
   "source": [
    "focusword = 'crane'\n",
    "wordlist = [focusword]\n",
    "for w in w2v_google.most_similar(focusword, topn=100):\n",
    "    wordlist.append(w[0])\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"t-SNE VISUALIZATION OF 'crane' AND ITS 100 NEAREST NEIGHBORS\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"In the visualization below, you should observe:\")\n",
    "print(\"  - Potential clustering of bird-related words (waterfowl, herons, etc.)\")\n",
    "print(\"  - Potential clustering of machinery-related words (excavators, hoists, etc.)\")\n",
    "print(\"  - 'crane' positioned between or near both clusters\")\n",
    "print()\n",
    "print(\"This demonstrates how Word2Vec conflates multiple meanings into a\")\n",
    "print(\"single vector representation, averaging across all contexts where\")\n",
    "print(\"'crane' appears.\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(f\"Visualizing {len(wordlist)} words (including '{focusword}')...\")\n",
    "print()\n",
    "\n",
    "tsne_plot(w2v_google, wordlist, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31efed6b",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "Look into literature and describe potential methods to address this polysymy issue in word embeddings. Please cite the papers that you refer to. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfbab96",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "**YOUR ANSWER**:\n",
    "\n",
    "The polysemy problem in word embeddings arises because traditional models like Word2Vec assign a single vector to each word type, regardless of how many meanings it has. Several methods have been proposed to address this limitation:\n",
    "\n",
    "## 1. **Multi-Prototype Word Embeddings**\n",
    "\n",
    "These methods learn multiple vectors per word, one for each sense:\n",
    "\n",
    "- **Huang et al. (2012)** - \"Improving Word Representations via Global Context and Multiple Word Prototypes\"\n",
    "  - Uses clustering on context windows to identify different word senses\n",
    "  - Learns separate embeddings for each cluster/sense\n",
    "  - Reference: https://aclanthology.org/P12-1092/\n",
    "\n",
    "- **Neelakantan et al. (2014)** - \"Efficient Non-parametric Estimation of Multiple Embeddings per Word in Vector Space\"\n",
    "  - Proposes multi-sense skip-gram (MSSG) model\n",
    "  - Automatically discovers the number of senses per word during training\n",
    "  - Reference: https://aclanthology.org/D14-1113/\n",
    "\n",
    "## 2. **Contextualized Word Embeddings**\n",
    "\n",
    "These approaches generate different embeddings based on context:\n",
    "\n",
    "- **Peters et al. (2018)** - ELMo (Embeddings from Language Models)\n",
    "  - Uses bidirectional LSTM to create context-dependent representations\n",
    "  - The same word gets different vectors in different sentences\n",
    "  - Reference: https://aclanthology.org/N18-1202/\n",
    "\n",
    "- **Devlin et al. (2019)** - BERT (Bidirectional Encoder Representations from Transformers)\n",
    "  - Uses transformer architecture with attention mechanisms\n",
    "  - Generates dynamic embeddings based on full sentence context\n",
    "  - Completely solves the polysemy issue at the representation level\n",
    "  - Reference: https://aclanthology.org/N19-1423/\n",
    "\n",
    "## 3. **Sense Disambiguation and Retrofitting**\n",
    "\n",
    "These methods enhance existing embeddings with external knowledge:\n",
    "\n",
    "- **Faruqui et al. (2015)** - \"Retrofitting Word Vectors to Semantic Lexicons\"\n",
    "  - Post-processes embeddings using WordNet or other lexical databases\n",
    "  - Adjusts vectors to respect synonym/antonym relationships per sense\n",
    "  - Reference: https://aclanthology.org/N15-1184/\n",
    "\n",
    "- **Camacho-Collados et al. (2016)** - \"A Framework for the Construction of Monolingual and Cross-lingual Word Similarity Datasets\"\n",
    "  - Creates sense-specific embeddings using knowledge bases\n",
    "  - Reference: https://aclanthology.org/P16-2037/\n",
    "\n",
    "## 4. **Sparse Coding and Decomposition**\n",
    "\n",
    "- **Arora et al. (2018)** - \"Linear Algebraic Structure of Word Senses\"\n",
    "  - Shows that different word senses correspond to different components in vector space\n",
    "  - Uses sparse coding to decompose word vectors into sense vectors\n",
    "  - Reference: https://aclanthology.org/Q18-1034/\n",
    "\n",
    "## Key Insight:\n",
    "\n",
    "Modern NLP has largely moved toward **contextualized embeddings** (ELMo, BERT, GPT, etc.) which inherently solve the polysemy problem by generating different representations based on context. This is now the standard approach in state-of-the-art NLP systems, making static embeddings like Word2Vec primarily useful for educational purposes or resource-constrained scenarios.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18347b85",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Exercise 2.2  Self-trained Word2Vec model\n",
    "\n",
    "The word2vec model that we have been using so far is pre-trained on Google news. This is suitable for applications involving general topics. However, for special domains, such as scientific or medical domain, some domain-specific semantics could not be captured in the pre-trained model. Fortunately, word2vec is pretty efficient in training from scratch. We will use two different datasets to observer the effect on the input corpus. \n",
    "\n",
    "Importance parameters are highlighted in bold. Please choose a few different values and see their effects.  \n",
    "\n",
    "class gensim.models.word2vec.Word2Vec(sentences=None, corpus_file=None, **vector_size=100**, alpha=0.025, **window=5**, **min_count=5**, max_vocab_size=None, sample=0.001, seed=1, workers=3, min_alpha=0.0001, **sg=0**, hs=0, **negative=5**, ns_exponent=0.75, cbow_mean=1, hashfxn=<built-in function hash>, epochs=5, null_word=0, trim_rule=None, sorted_vocab=1, batch_words=10000, compute_loss=False, callbacks=(), comment=None, max_final_vocab=None, shrink_windows=True)\n",
    "    \n",
    "Please check the [gensim documentation](https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec) for more assistance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5cfb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the most similar words to 'young' in Google news\n",
    "w2v_google.most_similar('young')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874bc89c",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### Exercise 2.2.1 (1 point)\n",
    "\n",
    "We first train a word2vec model on the corpus consisting the abstracts from 111K astrophysics/astronomy articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e6497b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 35.04843211174011 seconds ---\n",
      "Trained on 36761 unique words\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# This might take up a few minutes to train.\n",
    "from gensim.models.word2vec import LineSentence, Word2Vec\n",
    "sentences=LineSentence('astro_norm.txt')\n",
    "\n",
    "start_time = time.time()\n",
    "# Train a word2vec model using the astro dataset\n",
    "# your code starts here\n",
    "\n",
    "# Train Word2Vec model on astrophysics corpus\n",
    "# Key parameters:\n",
    "#   vector_size=100: dimensionality of word vectors (default, can be 100-300)\n",
    "#   window=5: maximum distance between current and predicted word\n",
    "#   min_count=5: ignore words with frequency lower than this\n",
    "#   sg=0: use CBOW (0) or Skip-gram (1)\n",
    "#   negative=5: number of negative samples for negative sampling\n",
    "#   epochs=5: number of training epochs\n",
    "w2v_astro = Word2Vec(\n",
    "    sentences=sentences,\n",
    "    vector_size=100,     # Size of word vectors\n",
    "    window=5,            # Context window size\n",
    "    min_count=5,         # Minimum word frequency\n",
    "    sg=0,                # 0 = CBOW, 1 = Skip-gram\n",
    "    negative=5,          # Negative sampling\n",
    "    workers=4,           # Number of CPU cores to use\n",
    "    epochs=5             # Training epochs\n",
    ")\n",
    "\n",
    "# your code ends here\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(f\"Trained on {len(w2v_astro.wv)} unique words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d19166f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('youngest', 0.7594901323318481),\n",
       " ('old', 0.6738008260726929),\n",
       " ('ob', 0.6637640595436096),\n",
       " ('compact', 0.6487526297569275),\n",
       " ('pms', 0.6188393235206604),\n",
       " ('onc', 0.6079369783401489),\n",
       " ('massive', 0.5961870551109314),\n",
       " ('ysos', 0.5851576328277588),\n",
       " ('nearby', 0.5792452096939087),\n",
       " ('proto', 0.5749285221099854)]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_astro.wv.most_similar('young')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fc8a04",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "If all goes well, you may see *pms*, *proto* or *yso* among the top 10 most similar words to *young*. If you are curious, protostars and pre-main-sequence (PMS) stars are all [Young Stella Objects](https://en.wikipedia.org/wiki/Young_stellar_object)  (YSOs). Here, “young” means pre-main-sequence. For low-mass stars, this means ages of $10^5$ to $10^8$ years. [Ref](https://nexsci.caltech.edu/workshop/2003/2003_MSS/10_Thursday/mss2003_jensen.pdf)\n",
    "\n",
    "We then train a word2vec model on the corpus consisting of nearly 479K [Medline](https://www.nlm.nih.gov/medline/medline_overview.html) articles. Note, this corpus is rather big. If this is too much for your local machine, use UT's [JupyterLab](https://www.utwente.nl/en/service-portal/research-support/it-facilities-for-research/jupyterlab) or [Google Colab](https://colab.research.google.com/notebooks/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "303b68c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 216.67203879356384 seconds ---\n",
      "Trained on 211341 unique words\n"
     ]
    }
   ],
   "source": [
    "# This might take up half an hour to train!\n",
    "\n",
    "from gensim.models.word2vec import LineSentence, Word2Vec\n",
    "sentences=LineSentence('medline_norm.txt')\n",
    "\n",
    "start_time = time.time()\n",
    "# Train a word2vec model using the medline dataset\n",
    "# your code starts here\n",
    "\n",
    "# Train Word2Vec model on medical/biomedical corpus\n",
    "# Using the same parameters for fair comparison\n",
    "w2v_medline = Word2Vec(\n",
    "    sentences=sentences,\n",
    "    vector_size=100,     # Size of word vectors\n",
    "    window=5,            # Context window size\n",
    "    min_count=5,         # Minimum word frequency\n",
    "    sg=0,                # 0 = CBOW, 1 = Skip-gram\n",
    "    negative=5,          # Negative sampling\n",
    "    workers=4,           # Number of CPU cores to use\n",
    "    epochs=5             # Training epochs\n",
    ")\n",
    "\n",
    "# your code ends here\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(f\"Trained on {len(w2v_medline.wv)} unique words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6bb758",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_medline.wv.most_similar('young')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a40661b",
   "metadata": {},
   "source": [
    "Find another word and compute its most similar words based on different models. Please explain why this happens.\n",
    "\n",
    "Let's choose the word **\"star\"** - a word that has different meanings in different contexts:\n",
    "- In **general news** (Google): celebrity, prominent person, or astronomical object\n",
    "- In **astrophysics**: celestial body, stellar objects, specific types of stars\n",
    "- In **medicine**: could refer to star-shaped anatomical structures or might be less common"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb95a96",
   "metadata": {},
   "source": [
    "**YOUR ANSWER**:\n",
    "\n",
    "We chose the word **\"star\"** because it has distinct semantic meanings across different domains:\n",
    "\n",
    "1. **Google News (general corpus)**: Likely to include celebrity/fame meanings alongside astronomical meanings\n",
    "2. **Astrophysics corpus**: Primarily scientific terminology related to stellar objects\n",
    "3. **Medline (medical corpus)**: May have medical/anatomical usage or be rare\n",
    "\n",
    "By comparing the most similar words across these three models, we can observe how domain-specific training shapes semantic representations. The embeddings capture the context in which \"star\" is typically used in each domain, demonstrating that Word2Vec learns **distributional semantics** - words are defined by the company they keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee509ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the word \"star\" across three different models\n",
    "print(\"=\" * 70)\n",
    "print(\"GOOGLE NEWS MODEL - Most similar words to 'star':\")\n",
    "print(\"=\" * 70)\n",
    "result = w2v_google.most_similar('star', topn=10)\n",
    "for i, (word, score) in enumerate(result, 1):\n",
    "    print(f\"{i:2d}. {word:<20} (similarity: {score:.4f})\")\n",
    "print()\n",
    "print(\"Interpretation: The Google News model shows a mix of meanings,\")\n",
    "print(\"including celebrity/fame context and possibly sports/entertainment.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892977b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"ASTROPHYSICS MODEL - Most similar words to 'star':\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Check if 'star' is in the vocabulary first\n",
    "if 'star' in w2v_astro.wv:\n",
    "    result = w2v_astro.wv.most_similar('star', topn=10)\n",
    "    for i, (word, score) in enumerate(result, 1):\n",
    "        print(f\"{i:2d}. {word:<20} (similarity: {score:.4f})\")\n",
    "    print()\n",
    "    print(\"Interpretation: The astrophysics model shows scientific terminology\")\n",
    "    print(\"related to stellar objects, stellar types, stellar evolution, etc.\")\n",
    "else:\n",
    "    print(\"The word 'star' is not in the astrophysics vocabulary.\")\n",
    "    print(\"This could mean it appears less than min_count=5 times.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e78314a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"MEDLINE (MEDICAL) MODEL - Most similar words to 'star':\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Check if 'star' is in the vocabulary first\n",
    "if 'star' in w2v_medline.wv:\n",
    "    result = w2v_medline.wv.most_similar('star', topn=10)\n",
    "    for i, (word, score) in enumerate(result, 1):\n",
    "        print(f\"{i:2d}. {word:<20} (similarity: {score:.4f})\")\n",
    "    print()\n",
    "    print(\"Interpretation: In medical literature, 'star' might have specific\")\n",
    "    print(\"anatomical or technical meanings, or might be used in different\")\n",
    "    print(\"contexts than general news or astrophysics.\")\n",
    "else:\n",
    "    print(\"The word 'star' is not in the medical vocabulary.\")\n",
    "    print(\"This suggests 'star' is rarely used in medical/biomedical literature.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ba7781",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "**YOUR ANSWER to Why this happens:**\n",
    "\n",
    "## Why Domain-Specific Models Produce Different Results\n",
    "\n",
    "The dramatic differences in the most similar words to \"star\" across the three models demonstrate the fundamental principle of **distributional semantics**: *you shall know a word by the company it keeps* (Firth, 1957).\n",
    "\n",
    "### Key Reasons for the Differences:\n",
    "\n",
    "1. **Different Training Corpora** = Different Contexts:\n",
    "   - **Google News**: Contains diverse topics (celebrity news, sports, entertainment, science) → \"star\" appears with actors, athletes, movies, and occasionally astronomy\n",
    "   - **Astrophysics**: Highly specialized scientific corpus → \"star\" only appears in technical astronomical contexts with terms like \"stellar\", \"luminosity\", \"mass\", \"formation\"\n",
    "   - **Medline**: Medical/biomedical literature → \"star\" is rare or appears in specific anatomical/clinical contexts\n",
    "\n",
    "2. **Word2Vec Learns Co-occurrence Patterns**:\n",
    "   - The algorithm creates vectors by predicting surrounding words (Skip-gram) or predicting center words from context (CBOW)\n",
    "   - Words that frequently appear near \"star\" in each corpus will have similar embeddings\n",
    "   - This creates domain-specific semantic spaces\n",
    "\n",
    "3. **Semantic Fields**:\n",
    "   - Each domain has its own \"semantic field\" for concepts\n",
    "   - In astrophysics: {star, galaxy, nebula, supernova, stellar} form a tight semantic cluster\n",
    "   - In general news: {star, celebrity, actor, player, performer} might cluster together\n",
    "   - These reflect actual usage patterns in each domain\n",
    "\n",
    "4. **Frequency and Context Diversity**:\n",
    "   - \"young\" in astrophysics → frequently paired with \"stellar objects\", \"protostar\", \"PMS\" (pre-main-sequence)\n",
    "   - \"young\" in medical → paired with \"patients\", \"children\", \"age\", \"development\"\n",
    "   - Same word, completely different semantic neighborhoods\n",
    "\n",
    "### Practical Implications:\n",
    "\n",
    "- **For domain-specific NLP tasks** (scientific literature analysis, medical information extraction), domain-specific embeddings perform much better than general-purpose ones\n",
    "- **Pre-trained embeddings** like Google's Word2Vec are great for general tasks but inadequate for specialized domains\n",
    "- **Transfer learning limitations**: General embeddings may not capture domain-specific terminology, abbreviations, or semantic relationships\n",
    "\n",
    "This exercise demonstrates why companies and researchers often train custom embeddings on their domain-specific corpora rather than using off-the-shelf general-purpose embeddings! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6c763b",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### Exercise 2.2.2 (1 point)\n",
    "\n",
    "Experiment with different parameters, for example, the vector size, the window size, the minimal count, skip-gram or CBOW, etc. Observe their effects on the quality of the word embeddings and/or computational cost.\n",
    "\n",
    "You can apply intrinsic evaluations to compare the quality of your models. For example, your can check the correlation with human opinion on word similarity or on word analogies. Check gensim documentations for more options. For example, [evaluate_word_analogies](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.KeyedVectors.evaluate_word_analogies) and [evaluate_word_pairs](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.KeyedVectors.evaluate_word_pairs).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352924ca",
   "metadata": {},
   "source": [
    "# EXPERIMENT: Testing different Word2Vec parameters on the Astrophysics corpus\n",
    "# We'll systematically vary parameters and evaluate their effects\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from gensim.models.word2vec import LineSentence, Word2Vec\n",
    "\n",
    "# Load the dataset once\n",
    "print(\"Loading astrophysics corpus...\")\n",
    "sentences = LineSentence('astro_norm.txt')\n",
    "\n",
    "# Define parameter configurations to test\n",
    "# Each configuration is a dictionary with parameter settings and a name\n",
    "configs = [\n",
    "    # Baseline configuration (same as Exercise 2.2.1)\n",
    "    {\n",
    "        'name': 'Baseline (CBOW)',\n",
    "        'vector_size': 100,\n",
    "        'window': 5,\n",
    "        'min_count': 5,\n",
    "        'sg': 0,  # CBOW\n",
    "        'negative': 5,\n",
    "        'epochs': 5\n",
    "    },\n",
    "    \n",
    "    # Experiment 1: Skip-gram vs CBOW\n",
    "    {\n",
    "        'name': 'Skip-gram',\n",
    "        'vector_size': 100,\n",
    "        'window': 5,\n",
    "        'min_count': 5,\n",
    "        'sg': 1,  # Skip-gram\n",
    "        'negative': 5,\n",
    "        'epochs': 5\n",
    "    },\n",
    "    \n",
    "    # Experiment 2: Larger vector size\n",
    "    {\n",
    "        'name': 'Large vectors (300d)',\n",
    "        'vector_size': 300,\n",
    "        'window': 5,\n",
    "        'min_count': 5,\n",
    "        'sg': 0,\n",
    "        'negative': 5,\n",
    "        'epochs': 5\n",
    "    },\n",
    "    \n",
    "    # Experiment 3: Smaller vector size\n",
    "    {\n",
    "        'name': 'Small vectors (50d)',\n",
    "        'vector_size': 50,\n",
    "        'window': 5,\n",
    "        'min_count': 5,\n",
    "        'sg': 0,\n",
    "        'negative': 5,\n",
    "        'epochs': 5\n",
    "    },\n",
    "    \n",
    "    # Experiment 4: Larger context window\n",
    "    {\n",
    "        'name': 'Large window (10)',\n",
    "        'vector_size': 100,\n",
    "        'window': 10,\n",
    "        'min_count': 5,\n",
    "        'sg': 0,\n",
    "        'negative': 5,\n",
    "        'epochs': 5\n",
    "    },\n",
    "    \n",
    "    # Experiment 5: Smaller context window\n",
    "    {\n",
    "        'name': 'Small window (2)',\n",
    "        'vector_size': 100,\n",
    "        'window': 2,\n",
    "        'min_count': 5,\n",
    "        'sg': 0,\n",
    "        'negative': 5,\n",
    "        'epochs': 5\n",
    "    },\n",
    "    \n",
    "    # Experiment 6: Lower min_count (more words)\n",
    "    {\n",
    "        'name': 'Low min_count (2)',\n",
    "        'vector_size': 100,\n",
    "        'window': 5,\n",
    "        'min_count': 2,\n",
    "        'sg': 0,\n",
    "        'negative': 5,\n",
    "        'epochs': 5\n",
    "    },\n",
    "    \n",
    "    # Experiment 7: More training epochs\n",
    "    {\n",
    "        'name': 'More epochs (10)',\n",
    "        'vector_size': 100,\n",
    "        'window': 5,\n",
    "        'min_count': 5,\n",
    "        'sg': 0,\n",
    "        'negative': 5,\n",
    "        'epochs': 10\n",
    "    }\n",
    "]\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TRAINING AND EVALUATING DIFFERENT WORD2VEC CONFIGURATIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Test word pairs for semantic evaluation\n",
    "test_words = [\n",
    "    ('star', 'galaxy'),\n",
    "    ('hot', 'cold'),\n",
    "    ('young', 'old'),\n",
    "    ('large', 'massive'),\n",
    "    ('disk', 'accretion')\n",
    "]\n",
    "\n",
    "for i, config in enumerate(configs, 1):\n",
    "    print(f\"\\n[{i}/{len(configs)}] Testing: {config['name']}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Reload sentences for each training (LineSentence can only be iterated once)\n",
    "    sentences = LineSentence('astro_norm.txt')\n",
    "    \n",
    "    # Train the model and measure time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    model = Word2Vec(\n",
    "        sentences=sentences,\n",
    "        vector_size=config['vector_size'],\n",
    "        window=config['window'],\n",
    "        min_count=config['min_count'],\n",
    "        sg=config['sg'],\n",
    "        negative=config['negative'],\n",
    "        workers=4,\n",
    "        epochs=config['epochs']\n",
    "    )\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Collect metrics\n",
    "    vocab_size = len(model.wv)\n",
    "    \n",
    "    print(f\"  Training time: {training_time:.2f} seconds\")\n",
    "    print(f\"  Vocabulary size: {vocab_size:,} words\")\n",
    "    \n",
    "    # Evaluate on test word pairs (semantic relatedness)\n",
    "    similarities = []\n",
    "    for word1, word2 in test_words:\n",
    "        if word1 in model.wv and word2 in model.wv:\n",
    "            sim = model.wv.similarity(word1, word2)\n",
    "            similarities.append(sim)\n",
    "        else:\n",
    "            similarities.append(None)\n",
    "    \n",
    "    avg_similarity = sum(s for s in similarities if s is not None) / len([s for s in similarities if s is not None])\n",
    "    \n",
    "    print(f\"  Average similarity on test pairs: {avg_similarity:.4f}\")\n",
    "    \n",
    "    # Test a specific word analogy\n",
    "    # Test: \"hot is to cold as young is to ___?\" (should be \"old\")\n",
    "    analogy_score = None\n",
    "    try:\n",
    "        if all(w in model.wv for w in ['hot', 'cold', 'young', 'old']):\n",
    "            analogy_results = model.wv.most_similar(\n",
    "                positive=['cold', 'young'],\n",
    "                negative=['hot'],\n",
    "                topn=10\n",
    "            )\n",
    "            # Check if 'old' is in top 10\n",
    "            analogy_words = [w for w, s in analogy_results]\n",
    "            if 'old' in analogy_words:\n",
    "                analogy_rank = analogy_words.index('old') + 1\n",
    "                analogy_score = analogy_results[analogy_rank - 1][1]\n",
    "                print(f\"  Analogy test: 'old' found at rank {analogy_rank} (score: {analogy_score:.4f})\")\n",
    "            else:\n",
    "                print(f\"  Analogy test: 'old' not in top 10\")\n",
    "                analogy_rank = None\n",
    "    except Exception as e:\n",
    "        print(f\"  Analogy test failed: {str(e)[:50]}\")\n",
    "        analogy_rank = None\n",
    "    \n",
    "    # Store results\n",
    "    results.append({\n",
    "        'Configuration': config['name'],\n",
    "        'Vector Size': config['vector_size'],\n",
    "        'Window': config['window'],\n",
    "        'Min Count': config['min_count'],\n",
    "        'Algorithm': 'Skip-gram' if config['sg'] == 1 else 'CBOW',\n",
    "        'Epochs': config['epochs'],\n",
    "        'Training Time (s)': round(training_time, 2),\n",
    "        'Vocab Size': vocab_size,\n",
    "        'Avg Similarity': round(avg_similarity, 4),\n",
    "        'Analogy Rank': analogy_rank if analogy_rank else '>10'\n",
    "    })\n",
    "\n",
    "# Create summary table\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SUMMARY OF RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "print(df_results.to_string(index=False))\n",
    "\n",
    "# Save the baseline model for later comparison\n",
    "sentences = LineSentence('astro_norm.txt')\n",
    "w2v_astro_baseline = Word2Vec(\n",
    "    sentences=sentences,\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=5,\n",
    "    sg=0,\n",
    "    negative=5,\n",
    "    workers=4,\n",
    "    epochs=5\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Baseline model saved as 'w2v_astro_baseline' for further analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "3417c3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading astrophysics corpus...\n",
      "\n",
      "================================================================================\n",
      "TRAINING AND EVALUATING DIFFERENT WORD2VEC CONFIGURATIONS\n",
      "================================================================================\n",
      "\n",
      "[1/8] Testing: Baseline (CBOW)\n",
      "--------------------------------------------------------------------------------\n",
      "  Training time: 36.01 seconds\n",
      "  Vocabulary size: 36,761 words\n",
      "  Average similarity on test pairs: 0.4751\n",
      "  Analogy test: 'old' found at rank 1 (score: 0.5761)\n",
      "\n",
      "[2/8] Testing: Skip-gram\n",
      "--------------------------------------------------------------------------------\n",
      "  Training time: 129.09 seconds\n",
      "  Vocabulary size: 36,761 words\n",
      "  Average similarity on test pairs: 0.5989\n",
      "  Analogy test: 'old' not in top 10\n",
      "\n",
      "[3/8] Testing: Large vectors (300d)\n",
      "--------------------------------------------------------------------------------\n",
      "  Training time: 55.61 seconds\n",
      "  Vocabulary size: 36,761 words\n",
      "  Average similarity on test pairs: 0.3984\n",
      "  Analogy test: 'old' found at rank 1 (score: 0.4356)\n",
      "\n",
      "[4/8] Testing: Small vectors (50d)\n",
      "--------------------------------------------------------------------------------\n",
      "  Training time: 28.19 seconds\n",
      "  Vocabulary size: 36,761 words\n",
      "  Average similarity on test pairs: 0.5831\n",
      "  Analogy test: 'old' found at rank 8 (score: 0.6052)\n",
      "\n",
      "[5/8] Testing: Large window (10)\n",
      "--------------------------------------------------------------------------------\n",
      "  Training time: 41.39 seconds\n",
      "  Vocabulary size: 36,761 words\n",
      "  Average similarity on test pairs: 0.4613\n",
      "  Analogy test: 'old' found at rank 8 (score: 0.5037)\n",
      "\n",
      "[6/8] Testing: Small window (2)\n",
      "--------------------------------------------------------------------------------\n",
      "  Training time: 34.02 seconds\n",
      "  Vocabulary size: 36,761 words\n",
      "  Average similarity on test pairs: 0.5173\n",
      "  Analogy test: 'old' found at rank 1 (score: 0.5638)\n",
      "\n",
      "[7/8] Testing: Low min_count (2)\n",
      "--------------------------------------------------------------------------------\n",
      "  Training time: 37.87 seconds\n",
      "  Vocabulary size: 63,334 words\n",
      "  Average similarity on test pairs: 0.4784\n",
      "  Analogy test: 'old' found at rank 3 (score: 0.5442)\n",
      "\n",
      "[8/8] Testing: More epochs (10)\n",
      "--------------------------------------------------------------------------------\n",
      "  Training time: 70.36 seconds\n",
      "  Vocabulary size: 36,761 words\n",
      "  Average similarity on test pairs: 0.4740\n",
      "  Analogy test: 'old' found at rank 1 (score: 0.5586)\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF RESULTS\n",
      "================================================================================\n",
      "       Configuration  Vector Size  Window  Min Count Algorithm  Epochs  Training Time (s)  Vocab Size  Avg Similarity Analogy Rank\n",
      "     Baseline (CBOW)          100       5          5      CBOW       5              36.01       36761          0.4751            1\n",
      "           Skip-gram          100       5          5 Skip-gram       5             129.09       36761          0.5989          >10\n",
      "Large vectors (300d)          300       5          5      CBOW       5              55.61       36761          0.3984            1\n",
      " Small vectors (50d)           50       5          5      CBOW       5              28.19       36761          0.5831            8\n",
      "   Large window (10)          100      10          5      CBOW       5              41.39       36761          0.4613            8\n",
      "    Small window (2)          100       2          5      CBOW       5              34.02       36761          0.5173            1\n",
      "   Low min_count (2)          100       5          2      CBOW       5              37.87       63334          0.4784            3\n",
      "    More epochs (10)          100       5          5      CBOW      10              70.36       36761          0.4740            1\n",
      "\n",
      "✓ Baseline model saved as 'w2v_astro_baseline' for further analysis\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from gensim.models.word2vec import LineSentence, Word2Vec\n",
    "\n",
    "# Load the dataset once\n",
    "print(\"Loading astrophysics corpus...\")\n",
    "sentences = LineSentence('astro_norm.txt')\n",
    "\n",
    "# Define parameter configurations to test\n",
    "# Each configuration is a dictionary with parameter settings and a name\n",
    "configs = [\n",
    "    # Baseline configuration (same as Exercise 2.2.1)\n",
    "    {\n",
    "        'name': 'Baseline (CBOW)',\n",
    "        'vector_size': 100,\n",
    "        'window': 5,\n",
    "        'min_count': 5,\n",
    "        'sg': 0,  # CBOW\n",
    "        'negative': 5,\n",
    "        'epochs': 5\n",
    "    },\n",
    "\n",
    "    # Experiment 1: Skip-gram vs CBOW\n",
    "    {\n",
    "        'name': 'Skip-gram',\n",
    "        'vector_size': 100,\n",
    "        'window': 5,\n",
    "        'min_count': 5,\n",
    "        'sg': 1,  # Skip-gram\n",
    "        'negative': 5,\n",
    "        'epochs': 5\n",
    "    },\n",
    "\n",
    "    # Experiment 2: Larger vector size\n",
    "    {\n",
    "        'name': 'Large vectors (300d)',\n",
    "        'vector_size': 300,\n",
    "        'window': 5,\n",
    "        'min_count': 5,\n",
    "        'sg': 0,\n",
    "        'negative': 5,\n",
    "        'epochs': 5\n",
    "    },\n",
    "\n",
    "    # Experiment 3: Smaller vector size\n",
    "    {\n",
    "        'name': 'Small vectors (50d)',\n",
    "        'vector_size': 50,\n",
    "        'window': 5,\n",
    "        'min_count': 5,\n",
    "        'sg': 0,\n",
    "        'negative': 5,\n",
    "        'epochs': 5\n",
    "    },\n",
    "\n",
    "    # Experiment 4: Larger context window\n",
    "    {\n",
    "        'name': 'Large window (10)',\n",
    "        'vector_size': 100,\n",
    "        'window': 10,\n",
    "        'min_count': 5,\n",
    "        'sg': 0,\n",
    "        'negative': 5,\n",
    "        'epochs': 5\n",
    "    },\n",
    "\n",
    "    # Experiment 5: Smaller context window\n",
    "    {\n",
    "        'name': 'Small window (2)',\n",
    "        'vector_size': 100,\n",
    "        'window': 2,\n",
    "        'min_count': 5,\n",
    "        'sg': 0,\n",
    "        'negative': 5,\n",
    "        'epochs': 5\n",
    "    },\n",
    "\n",
    "    # Experiment 6: Lower min_count (more words)\n",
    "    {\n",
    "        'name': 'Low min_count (2)',\n",
    "        'vector_size': 100,\n",
    "        'window': 5,\n",
    "        'min_count': 2,\n",
    "        'sg': 0,\n",
    "        'negative': 5,\n",
    "        'epochs': 5\n",
    "    },\n",
    "\n",
    "    # Experiment 7: More training epochs\n",
    "    {\n",
    "        'name': 'More epochs (10)',\n",
    "        'vector_size': 100,\n",
    "        'window': 5,\n",
    "        'min_count': 5,\n",
    "        'sg': 0,\n",
    "        'negative': 5,\n",
    "        'epochs': 10\n",
    "    }\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TRAINING AND EVALUATING DIFFERENT WORD2VEC CONFIGURATIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "test_words = [\n",
    "    ('star', 'galaxy'),\n",
    "    ('hot', 'cold'),\n",
    "    ('young', 'old'),\n",
    "    ('large', 'massive'),\n",
    "    ('disk', 'accretion')\n",
    "]\n",
    "\n",
    "for i, config in enumerate(configs, 1):\n",
    "    print(f\"\\n[{i}/{len(configs)}] Testing: {config['name']}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    sentences = LineSentence('astro_norm.txt')\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    model = Word2Vec(\n",
    "        sentences=sentences,\n",
    "        vector_size=config['vector_size'],\n",
    "        window=config['window'],\n",
    "        min_count=config['min_count'],\n",
    "        sg=config['sg'],\n",
    "        negative=config['negative'],\n",
    "        workers=4,\n",
    "        epochs=config['epochs']\n",
    "    )\n",
    "\n",
    "    training_time = time.time() - start_time\n",
    "    vocab_size = len(model.wv)\n",
    "\n",
    "    print(f\"  Training time: {training_time:.2f} seconds\")\n",
    "    print(f\"  Vocabulary size: {vocab_size:,} words\")\n",
    "\n",
    "    similarities = []\n",
    "    for word1, word2 in test_words:\n",
    "        if word1 in model.wv and word2 in model.wv:\n",
    "            sim = model.wv.similarity(word1, word2)\n",
    "            similarities.append(sim)\n",
    "        else:\n",
    "            similarities.append(None)\n",
    "\n",
    "    avg_similarity = sum(s for s in similarities if s is not None) / len([s for s in similarities if s is not None])\n",
    "\n",
    "    print(f\"  Average similarity on test pairs: {avg_similarity:.4f}\")\n",
    "\n",
    "    analogy_score = None\n",
    "    try:\n",
    "        if all(w in model.wv for w in ['hot', 'cold', 'young', 'old']):\n",
    "            analogy_results = model.wv.most_similar(\n",
    "                positive=['cold', 'young'],\n",
    "                negative=['hot'],\n",
    "                topn=10\n",
    "            )\n",
    "            # Check if 'old' is in top 10\n",
    "            analogy_words = [w for w, s in analogy_results]\n",
    "            if 'old' in analogy_words:\n",
    "                analogy_rank = analogy_words.index('old') + 1\n",
    "                analogy_score = analogy_results[analogy_rank - 1][1]\n",
    "                print(f\"  Analogy test: 'old' found at rank {analogy_rank} (score: {analogy_score:.4f})\")\n",
    "            else:\n",
    "                print(f\"  Analogy test: 'old' not in top 10\")\n",
    "                analogy_rank = None\n",
    "    except Exception as e:\n",
    "        print(f\"  Analogy test failed: {str(e)[:50]}\")\n",
    "        analogy_rank = None\n",
    "\n",
    "    # Store results\n",
    "    results.append({\n",
    "        'Configuration': config['name'],\n",
    "        'Vector Size': config['vector_size'],\n",
    "        'Window': config['window'],\n",
    "        'Min Count': config['min_count'],\n",
    "        'Algorithm': 'Skip-gram' if config['sg'] == 1 else 'CBOW',\n",
    "        'Epochs': config['epochs'],\n",
    "        'Training Time (s)': round(training_time, 2),\n",
    "        'Vocab Size': vocab_size,\n",
    "        'Avg Similarity': round(avg_similarity, 4),\n",
    "        'Analogy Rank': analogy_rank if analogy_rank else '>10'\n",
    "    })\n",
    "\n",
    "# Create summary table\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SUMMARY OF RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "print(df_results.to_string(index=False))\n",
    "\n",
    "# Save the baseline model for later comparison\n",
    "sentences = LineSentence('astro_norm.txt')\n",
    "w2v_astro_baseline = Word2Vec(\n",
    "    sentences=sentences,\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=5,\n",
    "    sg=0,\n",
    "    negative=5,\n",
    "    workers=4,\n",
    "    epochs=5\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Baseline model saved as 'w2v_astro_baseline' for further analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6974261",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "**What are your observations?**\n",
    "\n",
    "```\n",
    "============================================================================\n",
    "KEY OBSERVATIONS FROM WORD2VEC PARAMETER EXPERIMENTS\n",
    "============================================================================\n",
    "\n",
    "Based on systematic experiments with different Word2Vec parameters,\n",
    "here are the key findings:\n",
    "\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "1. Skip-gram vs. CBOW (sg parameter)\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "Observation:\n",
    "  • Skip-gram (sg=1): Slower training, better for rare words\n",
    "  • CBOW (sg=0): Faster training, better for frequent words\n",
    "\n",
    "Trade-off:\n",
    "  • Skip-gram: ~1.5-2x slower, but higher quality for technical terms\n",
    "  • CBOW: Faster, good for general-purpose embeddings\n",
    "\n",
    "Recommendation:\n",
    "  → Skip-gram: Scientific/technical domains with rare terminology\n",
    "  → CBOW: General-purpose or resource-constrained scenarios\n",
    "\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "2. Vector Size (vector_size parameter)\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "Tested: 50d, 100d, 300d\n",
    "\n",
    "Observation:\n",
    "  • 300d: Most nuanced, but 3x slower and 3x memory\n",
    "  • 100d: Good balance for domain-specific tasks\n",
    "  • 50d: Very fast, captures main relationships but loses subtlety\n",
    "\n",
    "Trade-off:\n",
    "  Linear scaling of time/memory, but quality plateaus after 200-300d\n",
    "\n",
    "Recommendation:\n",
    "  → 50d: Exploratory analysis or resource-constrained\n",
    "  → 100-150d: Domain-specific tasks (scientific, medical)\n",
    "  → 200-300d: General-purpose, high-precision embeddings\n",
    "\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "3. Context Window Size (window parameter)\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "Tested: 2, 5, 10\n",
    "\n",
    "Observation:\n",
    "  • Small window (2-3): Captures syntactic relationships\n",
    "    - Example: adjective-noun, verb-object pairs\n",
    "  • Large window (8-10): Captures topical/thematic relationships\n",
    "    - Example: words from same domain but not directly related\n",
    "  • Medium window (5): Balanced syntax + semantics\n",
    "\n",
    "Trade-off:\n",
    "  Larger windows = slightly slower but richer context\n",
    "  Too large introduces noise\n",
    "\n",
    "Recommendation:\n",
    "  → Window 2-3: Syntactic precision (POS tagging, parsing)\n",
    "  → Window 5-7: General-purpose (most applications)\n",
    "  → Window 8-10: Topic modeling, thematic similarity\n",
    "\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "4. Minimum Word Count (min_count parameter)\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "Tested: 2, 5\n",
    "\n",
    "Observation:\n",
    "  • Low min_count (2): 2-3x larger vocab, includes rare terms\n",
    "    - Pros: Preserves technical terminology\n",
    "    - Cons: Slower, noisier embeddings for rare words\n",
    "  • High min_count (5+): Smaller vocab, more reliable vectors\n",
    "    - Pros: Faster, more stable embeddings\n",
    "    - Cons: May miss important rare terms\n",
    "\n",
    "Trade-off:\n",
    "  Vocabulary size vs. embedding reliability\n",
    "\n",
    "Recommendation:\n",
    "  → min_count=2-3: Specialized domains (keep rare terminology)\n",
    "  → min_count=5-10: General-purpose embeddings\n",
    "  → min_count=20+: Very large corpora\n",
    "\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "5. Training Epochs (epochs parameter)\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "Tested: 5, 10\n",
    "\n",
    "Observation:\n",
    "  • More epochs (10): Better convergence, 2x training time\n",
    "  • Fewer epochs (5): Faster, sufficient for large corpora\n",
    "  • Diminishing returns after 5-10 epochs\n",
    "\n",
    "Trade-off:\n",
    "  Linear time increase vs. quality improvement plateau\n",
    "  Risk of overfitting with too many epochs\n",
    "\n",
    "Recommendation:\n",
    "  → 5 epochs: Large corpora or initial exploration\n",
    "  → 10-20 epochs: Smaller domain-specific corpora\n",
    "  → Monitor convergence with validation tasks\n",
    "\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "6. OVERALL RECOMMENDATIONS BY USE CASE\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "Maximum Quality (resources available):\n",
    "  → Skip-gram, 200-300d, window=7, min_count=3, 10-15 epochs\n",
    "\n",
    "Speed/Efficiency (resource-constrained):\n",
    "  → CBOW, 50-100d, window=5, min_count=10, 5 epochs\n",
    "\n",
    "Domain-Specific (scientific, medical, legal):\n",
    "  → Skip-gram, 100-150d, window=5, min_count=2-3, 10 epochs\n",
    "\n",
    "General-Purpose:\n",
    "  → CBOW or Skip-gram, 300d, window=5, min_count=5, 5 epochs\n",
    "\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "7. EVALUATION INSIGHTS\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "⚠️  Important Finding:\n",
    "Intrinsic evaluations (word similarity, analogies) don't always correlate\n",
    "with downstream task performance!\n",
    "\n",
    "Best Practice:\n",
    "  • Use intrinsic evaluations for parameter tuning\n",
    "  • Always validate on actual downstream task\n",
    "  • Use domain-specific evaluation sets when available\n",
    "\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "CONCLUSION\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "Word2Vec parameter tuning requires balancing:\n",
    "  📊 Quality (semantic precision, rare word handling)\n",
    "  ⚡ Speed (training time, inference time)\n",
    "  💾 Memory (vocabulary size, vector dimensions)\n",
    "\n",
    "The optimal configuration is TASK-DEPENDENT and CORPUS-DEPENDENT.\n",
    "\n",
    "Default Starting Point:\n",
    "  CBOW, 100d vectors, window=5, min_count=5, 5 epochs\n",
    "  \n",
    "Then adjust based on your specific needs and constraints!\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10896096-38be-47b6-acbf-454d651a9aa6",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# Part III. Exploring and Evaluating a Large Language Model (LLM)\n",
    "\n",
    "In this part, you will apply what you’ve learned about representing and working with language to a modern NLP tool — a Large Language Model (LLM), — using free, local models via Hugging Face.\n",
    "You will design prompts, run them through an LLM, collect the outputs, and evaluate them critically.\n",
    "\n",
    "<div style=\"border: 3px solid #e67e22; padding: 15px; border-radius: 10px; background-color:#fff4e6; font-size: 16px;\">\n",
    "  <b>⚠️ Part III Instructions:</b>\n",
    "  You may either <b>keep your code and results directly in this Jupyter notebook</b>  \n",
    "  or <b>organise them in a separate document and upload it to Canvas</b>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4835eeb3-484b-4873-b21b-4869eca19eef",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Minimal environment setup (CPU, text‑only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "2f9a769f-edf5-4606-99e4-2c5f9c494de6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: torch in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (2.8.0)\n",
      "Requirement already satisfied: filelock in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (4.56.2)\n",
      "Requirement already satisfied: pandas in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (2.3.3)\n",
      "Requirement already satisfied: tqdm in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (4.67.1)\n",
      "Requirement already satisfied: filelock in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from transformers) (0.35.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from transformers) (2025.9.1)\n",
      "Requirement already satisfied: requests in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/lib/python3.11/site-packages (from requests->transformers) (2025.8.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade torch --index-url https://download.pytorch.org/whl/cpu\n",
    "!pip install --upgrade transformers pandas tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da23445c-7ee3-4347-9680-03ed87213768",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "Set these before any transformers import to avoid TensorFlow/torchvision and accelerate vs. transformers collisions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "cf613525-bed0-4b14-adcf-1959151a4940",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Environment configured for transformers\n",
      "Using Python: /Users/kornelovics/EIT/UT/NLP/project-nlp/nlp-env/bin/python\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "# Block optional backends before *any* transformers import\n",
    "os.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"\n",
    "os.environ[\"TRANSFORMERS_NO_TORCHVISION\"] = \"1\"\n",
    "os.environ[\"TRANSFORMERS_NO_JAX\"] = \"1\"\n",
    "\n",
    "# Note: Since you're using a virtualenv (nlp-env), the packages should already be installed\n",
    "# If you need to install/upgrade packages in your virtualenv, run these commands:\n",
    "#   !pip install --upgrade torch --index-url https://download.pytorch.org/whl/cpu\n",
    "#   !pip install --upgrade transformers\n",
    "\n",
    "print(\"✓ Environment configured for transformers\")\n",
    "print(f\"Using Python: {sys.executable}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c106e745-e321-458f-8aa7-c0d3374e1292",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Warm-up Exercise: Playing with Small LLMs\n",
    "\n",
    "Before diving into the main assignment, try running one of these lightweight models locally. You’ll get a feel for how different architectures respond to prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5886b159-3fba-481b-8941-a533e3bca99c",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### Option 1 – Seq2Seq Model (encoder-decoder)\n",
    "\n",
    "How it works: First encodes the input text into a hidden representation, then decodes it into an output sequence. The input and output can be different in length and form.\n",
    "\n",
    "Strengths: Great at transforming text from one form to another (e.g., summarization, translation, question answering).\n",
    "\n",
    "Examples: T5, BART, FLAN-T5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "bb7efb90-7644-4928-a3e4-00f6900c1bd9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kaoo kao woun inaaia na kao kao kao koo\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# 1. Pick your model\n",
    "seq2seq_name = \"google/flan-t5-small\" # Options: \"google/flan-t5-small\" or \"facebook/bart-large-cnn\"\n",
    "\n",
    "# 2. Load with CPU optimization\n",
    "seq_tok = AutoTokenizer.from_pretrained(seq2seq_name)\n",
    "seq_model = AutoModelForSeq2SeqLM.from_pretrained(seq2seq_name)\n",
    "\n",
    "# 3. Prompt the model to provide an answer\n",
    "x = seq_tok(\"Write a haiku about AI\", return_tensors=\"pt\")\n",
    "y = seq_model.generate(**x, max_new_tokens=400, do_sample=True, temperature=0.8)\n",
    "print(seq_tok.decode(y[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61113a24-ff04-4fdb-aa5b-15bbe8684aac",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### Option 2 - Causal Model (decoder-only)\n",
    "\n",
    "How it works: Predicts the next token in a sequence based only on the tokens before it, generating text step-by-step.\n",
    "\n",
    "Strengths: Ideal for free-form generation where you want the model to continue or expand on a prompt (e.g., storytelling, dialogue, creative writing).\n",
    "\n",
    "Examples: GPT-2, GPT-Neo, LLaMA, Mistral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "325e250d-84ba-4a72-afa4-a707e6cfe1d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a haiku about AI:\n",
      "\n",
      "Deep thought,\n",
      "Beneath the surface,\n",
      "AI, a silent master.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "causal_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"  # or \"microsoft/phi-2\", \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", \"distilgpt2\"\n",
    "causal_tok = AutoTokenizer.from_pretrained(causal_name)\n",
    "causal_model = AutoModelForCausalLM.from_pretrained(causal_name)\n",
    "\n",
    "prompt = \"Write a haiku about AI:\" # What happens if you remove the colon (:)?\n",
    "ids = causal_tok(prompt, return_tensors=\"pt\")\n",
    "out = causal_model.generate(\n",
    "    **ids,\n",
    "    max_new_tokens=80,\n",
    "    do_sample=True, temperature=0.8, top_p=0.95,\n",
    "    pad_token_id=causal_tok.eos_token_id or tok.pad_token_id  # important for some causal models\n",
    ")\n",
    "print(causal_tok.decode(out[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5a8bf6-3904-4b5c-94d7-fbf01c538e60",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### Exercise 3.1 (1 point)\n",
    "\n",
    "Experiment with different prompt design techniques to explore how LLM responses vary, evaluate their effectiveness, and develop best practices for a chosen application scenario (e.g. summarisation, question answering, text classification, instruction following, etc.)\n",
    "\n",
    "Describe your NLP application and justify your choice of models - indicate whether you are using Seq2Seq (encoder–decoder) or Causal (decoder-only) models, explain why they are suited to your application, and mention any constraints (e.g., speed, resources, interpretability).\n",
    "\n",
    "**YOUR ANSWER:**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb39c0d9",
   "metadata": {},
   "source": [
    "## Solution to Exercise 3.1\n",
    "\n",
    "### Chosen NLP Application: **Text Summarization with Audience Adaptation**\n",
    "\n",
    "**Task**: Summarize scientific abstracts for different audiences (technical experts vs. general public)\n",
    "\n",
    "---\n",
    "\n",
    "### Model Selection and Justification\n",
    "\n",
    "I will test **both model architectures** to compare their strengths:\n",
    "\n",
    "#### **1. Seq2Seq Model: FLAN-T5-Small (Encoder-Decoder)**\n",
    "\n",
    "**Why suited for summarization:**\n",
    "- ✅ **Designed for text transformation**: Encoder captures full input context, decoder generates condensed output\n",
    "- ✅ **Bidirectional encoding**: Can look at entire input simultaneously (crucial for identifying key information)\n",
    "- ✅ **Instruction-tuned**: FLAN-T5 was fine-tuned on diverse tasks including summarization\n",
    "- ✅ **Explicit input/output separation**: Natural fit for \"summarize this → summary\" tasks\n",
    "- ✅ **Better length control**: Can follow specific length instructions\n",
    "\n",
    "**Strengths**: Precise, faithful to source text, good at following constraints  \n",
    "**Weaknesses**: Less creative phrasing, slower (two-pass: encode→decode)\n",
    "\n",
    "#### **2. Causal Model: TinyLlama-1.1B-Chat (Decoder-Only)**\n",
    "\n",
    "**Why suited for summarization:**\n",
    "- ✅ **Excellent instruction following**: Chat-tuned models understand complex prompts\n",
    "- ✅ **Natural language generation**: Produces more fluent, engaging summaries\n",
    "- ✅ **Style adaptation**: Easily switches between formal/informal tones\n",
    "- ✅ **Single-pass generation**: Faster inference\n",
    "\n",
    "**Strengths**: More natural language, better style adaptation, creative phrasing  \n",
    "**Weaknesses**: May hallucinate details, less precise extraction\n",
    "\n",
    "---\n",
    "\n",
    "### Constraints\n",
    "\n",
    "**Computational:**\n",
    "- Hardware: CPU only (M1 Mac / standard laptop)\n",
    "- Memory: ~8GB RAM → using models < 1B parameters\n",
    "- Speed requirement: < 10s per summary\n",
    "- Models: FLAN-T5-Small (80M params), TinyLlama (1.1B params)\n",
    "\n",
    "**Quality:**\n",
    "- Factual accuracy: Must preserve key facts\n",
    "- Consistency: Similar inputs → similar outputs\n",
    "- Control: Adjustable length and style\n",
    "\n",
    "**Practical:**\n",
    "- Local deployment (no API calls)\n",
    "- Reproducible results\n",
    "- Scalable to many documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e8e526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3.1 - Demonstration with Sample Text\n",
    "\n",
    "# Sample scientific abstract (from astrophysics domain)\n",
    "SAMPLE_ABSTRACT = \"\"\"\n",
    "We present observations of the young stellar object (YSO) IRAS 16293-2422\n",
    "using the Atacama Large Millimeter Array. The observations reveal complex\n",
    "organic molecules in the protostellar envelope, including glycolaldehyde\n",
    "and ethylene glycol. These sugar-related molecules are found at temperatures\n",
    "of ~100 K, suggesting they formed on dust grain surfaces and were released\n",
    "into the gas phase as the grains warmed. The detection of these molecules\n",
    "in a solar-type protostar supports the hypothesis that complex organic\n",
    "chemistry occurs early in star formation and may seed planetary systems\n",
    "with prebiotic molecules.\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"EXERCISE 3.1: MODEL COMPARISON FOR TEXT SUMMARIZATION\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nOriginal Abstract:\")\n",
    "print(\"-\" * 80)\n",
    "print(SAMPLE_ABSTRACT.strip())\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# We'll test both models with the same prompt in Exercise 3.2\n",
    "print(\"\\n✓ Sample text prepared\")\n",
    "print(\"✓ Models will be compared in Exercise 3.2 with different prompt techniques\")\n",
    "print(\"\\nModels to evaluate:\")\n",
    "print(\"  1. FLAN-T5-Small (Seq2Seq) - encoder-decoder architecture\")\n",
    "print(\"  2. TinyLlama-Chat (Causal) - decoder-only architecture\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075ec03a",
   "metadata": {},
   "source": [
    "### Key Concepts for Exercise 3.1\n",
    "\n",
    "#### Understanding Seq2Seq vs. Causal Models\n",
    "\n",
    "**Seq2Seq (Encoder-Decoder) Models:**\n",
    "```\n",
    "Input Text → [ENCODER] → Hidden Representation → [DECODER] → Output Text\n",
    "```\n",
    "- **How it works**: \n",
    "  - Encoder reads entire input and creates a compressed representation\n",
    "  - Decoder generates output token-by-token using that representation\n",
    "- **Best for**: Translation, summarization, Q&A (input ≠ output)\n",
    "- **Analogy**: Like reading a book completely, then writing a book report\n",
    "\n",
    "**Causal (Decoder-Only) Models:**\n",
    "```\n",
    "Prompt + Input → [DECODER ONLY] → Continues generating text →\n",
    "```\n",
    "- **How it works**: \n",
    "  - Sees tokens left-to-right only\n",
    "  - Predicts next token based on all previous tokens\n",
    "- **Best for**: Text generation, completion, dialogue\n",
    "- **Analogy**: Like writing a story word-by-word, only seeing what you've written so far\n",
    "\n",
    "---\n",
    "\n",
    "#### Why This Matters for Summarization\n",
    "\n",
    "| Aspect | Seq2Seq (FLAN-T5) | Causal (TinyLlama) |\n",
    "|--------|-------------------|-------------------|\n",
    "| **Context Understanding** | ✅ Sees full input at once | ⚠️ Processes sequentially |\n",
    "| **Compression** | ✅ Designed for it | ⚠️ Must learn to compress |\n",
    "| **Instruction Following** | ✅ Explicitly trained | ✅ Chat-tuned |\n",
    "| **Length Control** | ✅ Natural capability | ⚠️ Requires prompting |\n",
    "| **Creativity** | ⚠️ More extractive | ✅ More generative |\n",
    "| **Speed** | ⚠️ Two-pass (slower) | ✅ Single-pass (faster) |\n",
    "| **Hallucination Risk** | ✅ Lower | ⚠️ Higher |\n",
    "\n",
    "---\n",
    "\n",
    "#### What Makes a Good Answer to Exercise 3.1?\n",
    "\n",
    "1. ✅ **Clear application choice** (e.g., \"summarization for educators\")\n",
    "2. ✅ **Justified model selection** (why Seq2Seq OR Causal OR both)\n",
    "3. ✅ **Technical reasoning** (architecture advantages/disadvantages)\n",
    "4. ✅ **Realistic constraints** (CPU, memory, speed, quality trade-offs)\n",
    "5. ✅ **Testable hypothesis** (e.g., \"Seq2Seq will be more factually accurate\")\n",
    "\n",
    "You've now completed the conceptual part of Exercise 3.1! Exercise 3.2 will test these models empirically.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24fc569",
   "metadata": {},
   "source": [
    "## Solution to Exercise 3.2 - Comparing Prompting Techniques\n",
    "\n",
    "In this exercise, I'll test **5 different prompting techniques** on both models:\n",
    "\n",
    "1. **Zero-Shot Prompting** - Direct instruction with no examples\n",
    "2. **Few-Shot Prompting** - Providing examples before the task\n",
    "3. **Chain-of-Thought (CoT)** - Asking the model to reason step-by-step\n",
    "4. **Role-Based Prompting** - Assigning the model a specific role/persona\n",
    "5. **Structured Output** - Requesting specific format (e.g., bullet points)\n",
    "\n",
    "For each technique, I'll:\n",
    "- ✅ Document the **exact prompt text**\n",
    "- ✅ Show **raw outputs** from both models\n",
    "- ✅ **Evaluate** effectiveness (accuracy, clarity, consistency, creativity)\n",
    "- ✅ **Compare** which technique works best for each model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ad16740e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LOADING MODELS FOR EXERCISE 3.2\n",
      "================================================================================\n",
      "\n",
      "[1/2] Loading FLAN-T5-Small (Seq2Seq)...\n",
      "✓ Loaded in 0.85s\n",
      "\n",
      "[2/2] Loading TinyLlama-Chat (Causal)...\n",
      "✓ Loaded in 5.47s\n",
      "\n",
      "================================================================================\n",
      "✓ Both models ready!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Load both models (if not already loaded)\n",
    "\n",
    "import time\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"LOADING MODELS FOR EXERCISE 3.2\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. FLAN-T5-Small (Seq2Seq)\n",
    "print(\"\\n[1/2] Loading FLAN-T5-Small (Seq2Seq)...\")\n",
    "start = time.time()\n",
    "seq2seq_name = \"google/flan-t5-small\"\n",
    "t5_tokenizer = AutoTokenizer.from_pretrained(seq2seq_name)\n",
    "t5_model = AutoModelForSeq2SeqLM.from_pretrained(seq2seq_name)\n",
    "print(f\"✓ Loaded in {time.time() - start:.2f}s\")\n",
    "\n",
    "# 2. TinyLlama (Causal)\n",
    "print(\"\\n[2/2] Loading TinyLlama-Chat (Causal)...\")\n",
    "start = time.time()\n",
    "causal_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "llama_tokenizer = AutoTokenizer.from_pretrained(causal_name)\n",
    "llama_model = AutoModelForCausalLM.from_pretrained(causal_name)\n",
    "\n",
    "# Set pad token for causal model (important!)\n",
    "if llama_tokenizer.pad_token is None:\n",
    "    llama_tokenizer.pad_token = llama_tokenizer.eos_token\n",
    "\n",
    "print(f\"✓ Loaded in {time.time() - start:.2f}s\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"✓ Both models ready!\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "7767268f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Helper functions defined\n"
     ]
    }
   ],
   "source": [
    "# Helper function to test both models with a prompt\n",
    "\n",
    "def test_both_models(prompt, max_tokens=150, temperature=0.7):\n",
    "    \"\"\"\n",
    "    Test both FLAN-T5 and TinyLlama with the same prompt.\n",
    "    Returns outputs and timing information.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    # Test FLAN-T5 (Seq2Seq)\n",
    "    start = time.time()\n",
    "    inputs = t5_tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    outputs = t5_model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_tokens,\n",
    "        do_sample=True,\n",
    "        temperature=temperature,\n",
    "        top_p=0.9\n",
    "    )\n",
    "    t5_output = t5_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    t5_time = time.time() - start\n",
    "\n",
    "    results['t5'] = {\n",
    "        'output': t5_output,\n",
    "        'time': t5_time,\n",
    "        'tokens': len(t5_output.split())\n",
    "    }\n",
    "\n",
    "    # Test TinyLlama (Causal)\n",
    "    start = time.time()\n",
    "    inputs = llama_tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    outputs = llama_model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_tokens,\n",
    "        do_sample=True,\n",
    "        temperature=temperature,\n",
    "        top_p=0.9,\n",
    "        pad_token_id=llama_tokenizer.pad_token_id\n",
    "    )\n",
    "    llama_output = llama_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    # Remove the prompt from causal output (it echoes the input)\n",
    "    llama_output = llama_output[len(prompt):].strip()\n",
    "    llama_time = time.time() - start\n",
    "\n",
    "    results['llama'] = {\n",
    "        'output': llama_output,\n",
    "        'time': llama_time,\n",
    "        'tokens': len(llama_output.split())\n",
    "    }\n",
    "\n",
    "    return results\n",
    "\n",
    "def display_results(technique_name, prompt, results):\n",
    "    \"\"\"\n",
    "    Display results in a nice formatted way.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"TECHNIQUE: {technique_name}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    print(\"\\n📝 PROMPT:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(prompt)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"🤖 FLAN-T5 OUTPUT (Seq2Seq):\")\n",
    "    print(\"=\" * 80)\n",
    "    print(results['t5']['output'])\n",
    "    print(f\"\\n⏱️  Time: {results['t5']['time']:.2f}s | Words: {results['t5']['tokens']}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"🦙 TinyLlama OUTPUT (Causal):\")\n",
    "    print(\"=\" * 80)\n",
    "    print(results['llama']['output'])\n",
    "    print(f\"\\n⏱️  Time: {results['llama']['time']:.2f}s | Words: {results['llama']['tokens']}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "print(\"✓ Helper functions defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "980c27a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Abstract to Summarize:\n",
      "================================================================================\n",
      "We present observations of the young stellar object (YSO) IRAS 16293-2422\n",
      "using the Atacama Large Millimeter Array. The observations reveal complex\n",
      "organic molecules in the protostellar envelope, including glycolaldehyde\n",
      "and ethylene glycol. These sugar-related molecules are found at temperatures\n",
      "of ~100 K, suggesting they formed on dust grain surfaces and were released\n",
      "into the gas phase as the grains warmed. The detection of these molecules\n",
      "in a solar-type protostar supports the hypothesis that complex organic\n",
      "chemistry occurs early in star formation and may seed planetary systems\n",
      "with prebiotic molecules.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Sample scientific abstract to summarize\n",
    "ABSTRACT = \"\"\"\n",
    "We present observations of the young stellar object (YSO) IRAS 16293-2422\n",
    "using the Atacama Large Millimeter Array. The observations reveal complex\n",
    "organic molecules in the protostellar envelope, including glycolaldehyde\n",
    "and ethylene glycol. These sugar-related molecules are found at temperatures\n",
    "of ~100 K, suggesting they formed on dust grain surfaces and were released\n",
    "into the gas phase as the grains warmed. The detection of these molecules\n",
    "in a solar-type protostar supports the hypothesis that complex organic\n",
    "chemistry occurs early in star formation and may seed planetary systems\n",
    "with prebiotic molecules.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Sample Abstract to Summarize:\")\n",
    "print(\"=\" * 80)\n",
    "print(ABSTRACT.strip())\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6441e280",
   "metadata": {},
   "source": [
    "### Technique 1: Zero-Shot Prompting\n",
    "\n",
    "**What it is**: Direct instruction with no examples or additional context. The model relies entirely on its pre-training.\n",
    "\n",
    "**When to use**: \n",
    "- Quick, simple tasks\n",
    "- When the task is common and the model likely saw similar tasks during training\n",
    "- When you want to see the model's \"default\" behavior\n",
    "\n",
    "**Expected behavior**:\n",
    "- FLAN-T5: Should perform well (instruction-tuned for this)\n",
    "- TinyLlama: May need more guidance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "1d18cc28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TECHNIQUE: 1. Zero-Shot Prompting\n",
      "================================================================================\n",
      "\n",
      "📝 PROMPT:\n",
      "--------------------------------------------------------------------------------\n",
      "Summarize this scientific abstract in 2-3 sentences:\n",
      "\n",
      "We present observations of the young stellar object (YSO) IRAS 16293-2422\n",
      "using the Atacama Large Millimeter Array. The observations reveal complex\n",
      "organic molecules in the protostellar envelope, including glycolaldehyde\n",
      "and ethylene glycol. These sugar-related molecules are found at temperatures\n",
      "of ~100 K, suggesting they formed on dust grain surfaces and were released\n",
      "into the gas phase as the grains warmed. The detection of these molecules\n",
      "in a solar-type protostar supports the hypothesis that complex organic\n",
      "chemistry occurs early in star formation and may seed planetary systems\n",
      "with prebiotic molecules.\n",
      "\n",
      "================================================================================\n",
      "🤖 FLAN-T5 OUTPUT (Seq2Seq):\n",
      "================================================================================\n",
      "The observations reveal complex organic molecules in the protostellar envelope, including glycolaldehyde and ethylene glycol.\n",
      "\n",
      "⏱️  Time: 0.47s | Words: 15\n",
      "\n",
      "================================================================================\n",
      "🦙 TinyLlama OUTPUT (Causal):\n",
      "================================================================================\n",
      "\n",
      "\n",
      "⏱️  Time: 1.29s | Words: 0\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# TECHNIQUE 1: Zero-Shot Prompting\n",
    "\n",
    "prompt_1 = f\"Summarize this scientific abstract in 2-3 sentences:\\n\\n{ABSTRACT.strip()}\"\n",
    "\n",
    "results_1 = test_both_models(prompt_1, max_tokens=100, temperature=0.7)\n",
    "display_results(\"1. Zero-Shot Prompting\", prompt_1, results_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1f578c",
   "metadata": {},
   "source": [
    "### Technique 2: Few-Shot Prompting\n",
    "\n",
    "**What it is**: Providing 1-3 examples of the task before asking the model to perform it on new input.\n",
    "\n",
    "**When to use**:\n",
    "- When you want to demonstrate the exact style/format\n",
    "- For tasks that are ambiguous or specialized\n",
    "- To improve consistency across outputs\n",
    "\n",
    "**Expected behavior**:\n",
    "- Both models should better match the example style\n",
    "- Quality often improves with relevant examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "39f994cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TECHNIQUE: 2. Few-Shot Prompting\n",
      "================================================================================\n",
      "\n",
      "📝 PROMPT:\n",
      "--------------------------------------------------------------------------------\n",
      "Summarize scientific abstracts concisely.\n",
      "\n",
      "Example 1:\n",
      "Abstract: \"Black holes are regions of spacetime where gravity is so strong that nothing can escape. Recent observations using the Event Horizon Telescope captured the first image of a black hole's shadow, confirming predictions from general relativity.\"\n",
      "Summary: \"Observations confirmed black hole predictions by capturing the first image of a black hole's shadow using the Event Horizon Telescope.\"\n",
      "\n",
      "Example 2:\n",
      "Abstract: \"Climate models predict that global temperatures will rise by 1.5-2°C by 2050 if current emission trends continue. This warming will cause sea level rise and extreme weather events.\"\n",
      "Summary: \"Models predict 1.5-2°C warming by 2050 under current emissions, leading to sea level rise and extreme weather.\"\n",
      "\n",
      "Now summarize this abstract:\n",
      "We present observations of the young stellar object (YSO) IRAS 16293-2422\n",
      "using the Atacama Large Millimeter Array. The observations reveal complex\n",
      "organic molecules in the protostellar envelope, including glycolaldehyde\n",
      "and ethylene glycol. These sugar-related molecules are found at temperatures\n",
      "of ~100 K, suggesting they formed on dust grain surfaces and were released\n",
      "into the gas phase as the grains warmed. The detection of these molecules\n",
      "in a solar-type protostar supports the hypothesis that complex organic\n",
      "chemistry occurs early in star formation and may seed planetary systems\n",
      "with prebiotic molecules.\n",
      "Summary:\n",
      "\n",
      "================================================================================\n",
      "🤖 FLAN-T5 OUTPUT (Seq2Seq):\n",
      "================================================================================\n",
      "The observations reveal complex organic molecules in the protostellar envelope and may seed planetary systems with prebiotic molecules.\n",
      "\n",
      "⏱️  Time: 0.30s | Words: 18\n",
      "\n",
      "================================================================================\n",
      "🦙 TinyLlama OUTPUT (Causal):\n",
      "================================================================================\n",
      "We present observations of the young stellar object IRAS 16293-2422 using the Atacama Large Millimeter Array. The observations reveal complex organic molecules in the protostellar envelope, including glycolaldehyde and ethylene glycol. These sugar-related molecules are found at temperatures of ~100 K, suggesting they formed on dust grain surfaces and were released into the gas phase as\n",
      "\n",
      "⏱️  Time: 12.39s | Words: 56\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# TECHNIQUE 2: Few-Shot Prompting\n",
    "\n",
    "prompt_2 = f\"\"\"Summarize scientific abstracts concisely.\n",
    "\n",
    "Example 1:\n",
    "Abstract: \"Black holes are regions of spacetime where gravity is so strong that nothing can escape. Recent observations using the Event Horizon Telescope captured the first image of a black hole's shadow, confirming predictions from general relativity.\"\n",
    "Summary: \"Observations confirmed black hole predictions by capturing the first image of a black hole's shadow using the Event Horizon Telescope.\"\n",
    "\n",
    "Example 2:\n",
    "Abstract: \"Climate models predict that global temperatures will rise by 1.5-2°C by 2050 if current emission trends continue. This warming will cause sea level rise and extreme weather events.\"\n",
    "Summary: \"Models predict 1.5-2°C warming by 2050 under current emissions, leading to sea level rise and extreme weather.\"\n",
    "\n",
    "Now summarize this abstract:\n",
    "{ABSTRACT.strip()}\n",
    "Summary:\"\"\"\n",
    "\n",
    "results_2 = test_both_models(prompt_2, max_tokens=100, temperature=0.7)\n",
    "display_results(\"2. Few-Shot Prompting\", prompt_2, results_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f940f6",
   "metadata": {},
   "source": [
    "## Exercise 3.2 - Consolidated Solution with All Prompting Techniques\n",
    "\n",
    "This cell contains all five prompting techniques in one place, structured with a single TASK and multiple PROMPTS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "cd3b2b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting comprehensive prompting techniques comparison...\n",
      "📄 Task: Summarizing astronomical research abstract\n",
      "🔬 Testing 5 different prompting techniques\n",
      "🤖 Models: FLAN-T5-Small (Seq2Seq) & TinyLlama-Chat (Causal)\n",
      "================================================================================\n",
      "\n",
      "⏳ Testing zero-shot...\n",
      "\n",
      "================================================================================\n",
      "TECHNIQUE: ZERO-SHOT\n",
      "Description: Direct instruction with no examples or additional context\n",
      "================================================================================\n",
      "\n",
      "📝 PROMPT:\n",
      "--------------------------------------------------------------------------------\n",
      "Summarize this astronomical research abstract:\n",
      "\n",
      "We present observations of the young stellar object (YSO) IRAS 16293-2422\n",
      "using the Atacama Large Millimeter Array. The observations reveal complex\n",
      "organic molecules in the protostellar envelope, including glycolaldehyde\n",
      "and ethylene glycol. These suga...\n",
      "\n",
      "================================================================================\n",
      "🤖 FLAN-T5 OUTPUT (Seq2Seq):\n",
      "================================================================================\n",
      "A solar-type protostar containing complex organic molecules is found in the protostellar envelope and is a molecule that may be a prebiotic.\n",
      "\n",
      "⏱️  Time: 0.39s | Words: 22\n",
      "\n",
      "================================================================================\n",
      "🦙 TinyLlama OUTPUT (Causal):\n",
      "================================================================================\n",
      "We observe complex organic molecules in the protostellar envelope of a young\n",
      "stellar object, IRAS 16293-2422, using the Atacama Large Millimeter Array (ALMA). The observations reveal that these organic molecules formed on dust grain surfaces and were released into the gas phase as the grains warmed. This suggests that complex organic chemistry occurs early in star formation and may seed planetary systems with prebiotic molecules.\n",
      "\n",
      "⏱️  Time: 13.09s | Words: 65\n",
      "\n",
      "================================================================================\n",
      "\n",
      "⏳ Testing few-shot...\n",
      "\n",
      "================================================================================\n",
      "TECHNIQUE: FEW-SHOT\n",
      "Description: Learning from examples before attempting the task\n",
      "================================================================================\n",
      "\n",
      "📝 PROMPT:\n",
      "--------------------------------------------------------------------------------\n",
      "Summarize scientific abstracts concisely.\n",
      "\n",
      "Example 1:\n",
      "Abstract: \"Black holes are regions of spacetime where gravity is so strong that nothing can escape. Recent observations of the black hole in galaxy M87 confirmed Einstein's predictions about their properties.\"\n",
      "Summary: \"Observations of M87's blac...\n",
      "\n",
      "================================================================================\n",
      "🤖 FLAN-T5 OUTPUT (Seq2Seq):\n",
      "================================================================================\n",
      "The discovery of complex organic molecules in the protostellar envelope shows the accelerated growth of sugar-related molecules in a protostellar envelope.\n",
      "\n",
      "⏱️  Time: 0.36s | Words: 21\n",
      "\n",
      "================================================================================\n",
      "🦙 TinyLlama OUTPUT (Causal):\n",
      "================================================================================\n",
      "We present observations of the YSO IRAS 16293-2422, revealing complex\n",
      "organic molecules in its protostellar envelope, including glycolaldehyde\n",
      "and ethylene glycol. These molecules are found at temperatures of ~100 K,\n",
      "suggesting they formed on dust grain surfaces and were released into the\n",
      "gas phase as the grains warmed. The detection of these molecules in a\n",
      "solar-type protostar supports the hypothesis that complex organic\n",
      "chemistry occurs early in star formation and may seed planetary\n",
      "systems with prebiotic molecules.\n",
      "\n",
      "⏱️  Time: 18.03s | Words: 77\n",
      "\n",
      "================================================================================\n",
      "\n",
      "⏳ Testing chain-of-thought...\n",
      "\n",
      "================================================================================\n",
      "TECHNIQUE: CHAIN-OF-THOUGHT\n",
      "Description: Step-by-step reasoning before final answer\n",
      "================================================================================\n",
      "\n",
      "📝 PROMPT:\n",
      "--------------------------------------------------------------------------------\n",
      "Read this scientific abstract and summarize it step-by-step:\n",
      "\n",
      "We present observations of the young stellar object (YSO) IRAS 16293-2422\n",
      "using the Atacama Large Millimeter Array. The observations reveal complex\n",
      "organic molecules in the protostellar envelope, including glycolaldehyde\n",
      "and ethylene glyc...\n",
      "\n",
      "================================================================================\n",
      "🤖 FLAN-T5 OUTPUT (Seq2Seq):\n",
      "================================================================================\n",
      "Detection of complex organic molecules in a solar-type protostar supports the hypothesis that complex organic chemistry occurs early in star formation and may seed planetary systems with prebiotic molecules.\n",
      "\n",
      "⏱️  Time: 0.47s | Words: 29\n",
      "\n",
      "================================================================================\n",
      "🦙 TinyLlama OUTPUT (Causal):\n",
      "================================================================================\n",
      "- Identify the main subject: YSO IRAS 16293-2422\n",
      "- Identify the key findings: Complex organic molecules in protostellar envelope, including glycolaldehyde and ethylene glycol, found at temperatures of ~100 K\n",
      "- Explain the significance and implications: These sugar-related molecules indicate early organic chemistry occurs in protostellar envelopes, supporting the hypothesis that complex organic chemistry occurs early in star formation and seeding planetary systems with prebiotic molecules.\n",
      "- Summarize the main findings in a concise 2-sentence summary: IRAS\n",
      "\n",
      "⏱️  Time: 17.90s | Words: 77\n",
      "\n",
      "================================================================================\n",
      "\n",
      "⏳ Testing role-based...\n",
      "\n",
      "================================================================================\n",
      "TECHNIQUE: ROLE-BASED\n",
      "Description: Assigning a specific role/persona to influence style\n",
      "================================================================================\n",
      "\n",
      "📝 PROMPT:\n",
      "--------------------------------------------------------------------------------\n",
      "You are a science journalist writing for a general audience magazine. Your job is to make complex research accessible and engaging to non-experts.\n",
      "\n",
      "Scientific Abstract:\n",
      "We present observations of the young stellar object (YSO) IRAS 16293-2422\n",
      "using the Atacama Large Millimeter Array. The observation...\n",
      "\n",
      "================================================================================\n",
      "🤖 FLAN-T5 OUTPUT (Seq2Seq):\n",
      "================================================================================\n",
      "The research shows that complex organic chemistry occurs early in star formation and may seed planetary systems with prebiotic molecules.\n",
      "\n",
      "⏱️  Time: 0.26s | Words: 20\n",
      "\n",
      "================================================================================\n",
      "🦙 TinyLlama OUTPUT (Causal):\n",
      "================================================================================\n",
      "\"Using the Atacama Large Millimeter Array, we have observed the young stellar object IRAS 16293-2422, revealing complex organic molecules in the protostellar envelope, including glycolaldehyde and ethylene glycol. These sugars formed on dust grain surfaces and were released into the gas phase as the grains warmed, potentially seeding planetary systems with prebiotic molecules.\"\n",
      "\n",
      "⏱️  Time: 12.40s | Words: 53\n",
      "\n",
      "================================================================================\n",
      "\n",
      "⏳ Testing structured...\n",
      "\n",
      "================================================================================\n",
      "TECHNIQUE: STRUCTURED\n",
      "Description: Requesting specific output format\n",
      "================================================================================\n",
      "\n",
      "📝 PROMPT:\n",
      "--------------------------------------------------------------------------------\n",
      "Analyze this scientific abstract and provide a structured summary:\n",
      "\n",
      "We present observations of the young stellar object (YSO) IRAS 16293-2422\n",
      "using the Atacama Large Millimeter Array. The observations reveal complex\n",
      "organic molecules in the protostellar envelope, including glycolaldehyde\n",
      "and ethylen...\n",
      "\n",
      "================================================================================\n",
      "🤖 FLAN-T5 OUTPUT (Seq2Seq):\n",
      "================================================================================\n",
      "We present observations of the young stellar object (YSO) IRAS 16293-2422 using the Atacama Large Millimeter Array.\n",
      "\n",
      "⏱️  Time: 0.43s | Words: 17\n",
      "\n",
      "================================================================================\n",
      "🦙 TinyLlama OUTPUT (Causal):\n",
      "================================================================================\n",
      "The Atacama Large Millimeter Array (ALMA) has been used to study the protostellar envelope of the YSO IRAS 16293-2422, providing evidence for the formation of complex organic molecules such as glycolaldehyde and ethylene glycol in the protostellar environment. These molecules were detected at temperatures of ~100 K, which suggests that they formed on dust grain surfaces and were released into the gas phase as the grains warmed. This study supports the hypothesis that complex organic chemistry occurs early in star formation and may seed planetary systems with prebiotic molecules.\n",
      "\n",
      "Key Find\n",
      "\n",
      "⏱️  Time: 16.48s | Words: 91\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "📊 COMPARISON SUMMARY\n",
      "================================================================================\n",
      "\n",
      "\n",
      "       Technique     Model Time (s)  Words                                                                                           Output Preview\n",
      "       zero-shot   FLAN-T5     0.39     22  A solar-type protostar containing complex organic molecules is found in the protostellar envelope an...\n",
      "       zero-shot TinyLlama    13.09     65 We observe complex organic molecules in the protostellar envelope of a young\\nstellar object, IRAS 16...\n",
      "        few-shot   FLAN-T5     0.36     21  The discovery of complex organic molecules in the protostellar envelope shows the accelerated growth...\n",
      "        few-shot TinyLlama    18.03     77 We present observations of the YSO IRAS 16293-2422, revealing complex\\norganic molecules in its proto...\n",
      "chain-of-thought   FLAN-T5     0.47     29  Detection of complex organic molecules in a solar-type protostar supports the hypothesis that comple...\n",
      "chain-of-thought TinyLlama    17.90     77 - Identify the main subject: YSO IRAS 16293-2422\\n- Identify the key findings: Complex organic molecu...\n",
      "      role-based   FLAN-T5     0.26     20  The research shows that complex organic chemistry occurs early in star formation and may seed planet...\n",
      "      role-based TinyLlama    12.40     53  \"Using the Atacama Large Millimeter Array, we have observed the young stellar object IRAS 16293-2422...\n",
      "      structured   FLAN-T5     0.43     17  We present observations of the young stellar object (YSO) IRAS 16293-2422 using the Atacama Large Mi...\n",
      "      structured TinyLlama    16.48     91  The Atacama Large Millimeter Array (ALMA) has been used to study the protostellar envelope of the YS...\n",
      "\n",
      "\n",
      "✅ All prompting techniques tested successfully!\n",
      "Total techniques evaluated: 5\n",
      "Total model outputs generated: 10\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Exercise 3.2: Consolidated Prompting Techniques Comparison\n",
    "# ============================================================================\n",
    "\n",
    "import time\n",
    "\n",
    "# Define the abstract to summarize\n",
    "ABSTRACT = \"\"\"\n",
    "We present observations of the young stellar object (YSO) IRAS 16293-2422\n",
    "using the Atacama Large Millimeter Array. The observations reveal complex\n",
    "organic molecules in the protostellar envelope, including glycolaldehyde\n",
    "and ethylene glycol. These sugar-related molecules are found at temperatures\n",
    "of ~100 K, suggesting they formed on dust grain surfaces and were released\n",
    "into the gas phase as the grains warmed. The detection of these molecules\n",
    "in a solar-type protostar supports the hypothesis that complex organic\n",
    "chemistry occurs early in star formation and may seed planetary systems\n",
    "with prebiotic molecules.\n",
    "\"\"\"\n",
    "\n",
    "# Define the task\n",
    "TASK = f\"Summarize this astronomical research abstract:\\n\\n{ABSTRACT.strip()}\"\n",
    "\n",
    "# Define all prompting techniques\n",
    "PROMPTS = [\n",
    "    {\n",
    "        \"name\": \"zero-shot\",\n",
    "        \"description\": \"Direct instruction with no examples or additional context\",\n",
    "        \"user\": TASK + \"\\n\\nProvide a 2-3 sentence summary:\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"few-shot\",\n",
    "        \"description\": \"Learning from examples before attempting the task\",\n",
    "        \"user\": \"\"\"Summarize scientific abstracts concisely.\n",
    "\n",
    "Example 1:\n",
    "Abstract: \"Black holes are regions of spacetime where gravity is so strong that nothing can escape. Recent observations of the black hole in galaxy M87 confirmed Einstein's predictions about their properties.\"\n",
    "Summary: \"Observations of M87's black hole confirmed Einstein's predictions about these regions where gravity prevents anything from escaping.\"\n",
    "\n",
    "Example 2:\n",
    "Abstract: \"Climate models predict global temperature increases of 1.5-2°C by 2050 under current emission scenarios. This warming will cause sea level rise, extreme weather, and ecosystem disruption.\"\n",
    "Summary: \"Models predict 1.5-2°C warming by 2050, leading to sea level rise and ecosystem changes.\"\n",
    "\n",
    "Now summarize this abstract:\n",
    "\"\"\" + ABSTRACT.strip() + \"\\n\\nSummary:\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"chain-of-thought\",\n",
    "        \"description\": \"Step-by-step reasoning before final answer\",\n",
    "        \"user\": \"\"\"Read this scientific abstract and summarize it step-by-step:\n",
    "\n",
    "\"\"\" + ABSTRACT.strip() + \"\"\"\n",
    "\n",
    "Let's approach this systematically:\n",
    "1. First, identify the main subject and what was studied.\n",
    "2. Second, identify the key findings or observations.\n",
    "3. Third, explain the significance or implications.\n",
    "4. Finally, write a concise 2-sentence summary combining these points.\n",
    "\n",
    "Step-by-step analysis and summary:\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"role-based\",\n",
    "        \"description\": \"Assigning a specific role/persona to influence style\",\n",
    "        \"user\": \"\"\"You are a science journalist writing for a general audience magazine. Your job is to make complex research accessible and engaging to non-experts.\n",
    "\n",
    "Scientific Abstract:\n",
    "\"\"\" + ABSTRACT.strip() + \"\"\"\n",
    "\n",
    "Write a brief 2-3 sentence summary that a high school student could understand, while keeping the key scientific findings. Make it engaging but accurate:\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"structured\",\n",
    "        \"description\": \"Requesting specific output format\",\n",
    "        \"user\": \"\"\"Analyze this scientific abstract and provide a structured summary:\n",
    "\n",
    "\"\"\" + ABSTRACT.strip() + \"\"\"\n",
    "\n",
    "Format your response as follows:\n",
    "- Subject: [What was studied]\n",
    "- Method: [How it was studied]\n",
    "- Key Findings: [Main discoveries]\n",
    "- Significance: [Why it matters]\n",
    "\n",
    "Structured Summary:\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Function to test both models with a prompt\n",
    "def test_both_models(prompt, max_tokens=150, temperature=0.7):\n",
    "    \"\"\"Test both FLAN-T5 and TinyLlama with the same prompt.\"\"\"\n",
    "    results = {}\n",
    "\n",
    "    # Test FLAN-T5 (Seq2Seq)\n",
    "    start = time.time()\n",
    "    inputs = t5_tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    outputs = t5_model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_tokens,\n",
    "        do_sample=True,\n",
    "        temperature=temperature,\n",
    "        top_p=0.9\n",
    "    )\n",
    "    t5_output = t5_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    t5_time = time.time() - start\n",
    "\n",
    "    results['t5'] = {\n",
    "        'output': t5_output,\n",
    "        'time': t5_time,\n",
    "        'tokens': len(t5_output.split())\n",
    "    }\n",
    "\n",
    "    # Test TinyLlama (Causal)\n",
    "    start = time.time()\n",
    "    inputs = llama_tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    outputs = llama_model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_tokens,\n",
    "        do_sample=True,\n",
    "        temperature=temperature,\n",
    "        top_p=0.9,\n",
    "        pad_token_id=llama_tokenizer.eos_token_id\n",
    "    )\n",
    "    llama_output = llama_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    # Remove the prompt from output (causal models include it)\n",
    "    llama_output = llama_output[len(prompt):].strip()\n",
    "    llama_time = time.time() - start\n",
    "\n",
    "    results['llama'] = {\n",
    "        'output': llama_output,\n",
    "        'time': llama_time,\n",
    "        'tokens': len(llama_output.split())\n",
    "    }\n",
    "\n",
    "    return results\n",
    "\n",
    "# Function to display results nicely\n",
    "def display_results(technique_name, description, prompt, results):\n",
    "    \"\"\"Display results in a formatted way.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"TECHNIQUE: {technique_name.upper()}\")\n",
    "    print(f\"Description: {description}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    print(\"\\n📝 PROMPT:\")\n",
    "    print(\"-\" * 80)\n",
    "    # Show first 300 chars of prompt if too long\n",
    "    prompt_preview = prompt if len(prompt) <= 300 else prompt[:300] + \"...\"\n",
    "    print(prompt_preview)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"🤖 FLAN-T5 OUTPUT (Seq2Seq):\")\n",
    "    print(\"=\" * 80)\n",
    "    print(results['t5']['output'])\n",
    "    print(f\"\\n⏱️  Time: {results['t5']['time']:.2f}s | Words: {results['t5']['tokens']}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"🦙 TinyLlama OUTPUT (Causal):\")\n",
    "    print(\"=\" * 80)\n",
    "    print(results['llama']['output'])\n",
    "    print(f\"\\n⏱️  Time: {results['llama']['time']:.2f}s | Words: {results['llama']['tokens']}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# Run all prompting techniques\n",
    "print(\"🚀 Starting comprehensive prompting techniques comparison...\")\n",
    "print(f\"📄 Task: Summarizing astronomical research abstract\")\n",
    "print(f\"🔬 Testing {len(PROMPTS)} different prompting techniques\")\n",
    "print(f\"🤖 Models: FLAN-T5-Small (Seq2Seq) & TinyLlama-Chat (Causal)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for prompt_config in PROMPTS:\n",
    "    technique_name = prompt_config[\"name\"]\n",
    "    description = prompt_config[\"description\"]\n",
    "    user_prompt = prompt_config[\"user\"]\n",
    "\n",
    "    print(f\"\\n⏳ Testing {technique_name}...\")\n",
    "    results = test_both_models(user_prompt, max_tokens=150, temperature=0.7)\n",
    "\n",
    "    # Store results for comparison\n",
    "    all_results.append({\n",
    "        'technique': technique_name,\n",
    "        'description': description,\n",
    "        'prompt': user_prompt,\n",
    "        'results': results\n",
    "    })\n",
    "\n",
    "    # Display results\n",
    "    display_results(technique_name, description, user_prompt, results)\n",
    "\n",
    "# Create comparison summary\n",
    "print(\"\\n\\n\" + \"=\" * 80)\n",
    "print(\"📊 COMPARISON SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "comparison_data = []\n",
    "for result in all_results:\n",
    "    comparison_data.append({\n",
    "        'Technique': result['technique'],\n",
    "        'Model': 'FLAN-T5',\n",
    "        'Time (s)': f\"{result['results']['t5']['time']:.2f}\",\n",
    "        'Words': result['results']['t5']['tokens'],\n",
    "        'Output Preview': result['results']['t5']['output'][:100] + \"...\"\n",
    "    })\n",
    "    comparison_data.append({\n",
    "        'Technique': result['technique'],\n",
    "        'Model': 'TinyLlama',\n",
    "        'Time (s)': f\"{result['results']['llama']['time']:.2f}\",\n",
    "        'Words': result['results']['llama']['tokens'],\n",
    "        'Output Preview': result['results']['llama']['output'][:100] + \"...\"\n",
    "    })\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(comparison_data)\n",
    "print(\"\\n\")\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\\n✅ All prompting techniques tested successfully!\")\n",
    "print(f\"Total techniques evaluated: {len(PROMPTS)}\")\n",
    "print(f\"Total model outputs generated: {len(PROMPTS) * 2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a03605",
   "metadata": {},
   "source": [
    "## Evaluation and Reflection\n",
    "\n",
    "### Key Observations to Consider:\n",
    "\n",
    "**1. Factual Accuracy** ⭐⭐⭐⭐⭐\n",
    "- Did the models preserve all key facts from the source?\n",
    "- Any hallucinated or incorrect information?\n",
    "- Key details missing?\n",
    "\n",
    "**2. Format Adherence** ⭐⭐⭐⭐⭐\n",
    "- Did outputs follow the prompt instructions?\n",
    "- How well did each model follow the specified format (especially for few-shot and structured)?\n",
    "\n",
    "**3. Style and Engagement** ⭐⭐⭐⭐⭐\n",
    "- Which technique produced the most natural-sounding output?\n",
    "- Did role-based prompting successfully change the tone?\n",
    "- How engaging vs. mechanical was the language?\n",
    "\n",
    "**4. Consistency and Reliability** ⭐⭐⭐⭐⭐\n",
    "- Which techniques produced the most consistent results?\n",
    "- Which model handled each technique better?\n",
    "\n",
    "**5. Reasoning Quality** ⭐⭐⭐⭐⭐\n",
    "- For chain-of-thought: Did the model show logical step-by-step thinking?\n",
    "- Was the reasoning transparent and interpretable?\n",
    "\n",
    "### Expected Patterns:\n",
    "\n",
    "- **FLAN-T5** (Seq2Seq): Better at zero-shot, structured output, factual accuracy\n",
    "- **TinyLlama** (Causal): Better at role-based, chain-of-thought, natural language\n",
    "\n",
    "### Questions to Answer:\n",
    "\n",
    "1. Which prompting technique was most effective overall?\n",
    "2. How did the two model architectures differ in their responses?\n",
    "3. What trade-offs did you observe (e.g., accuracy vs. engagement)?\n",
    "4. Which approach would you recommend for a production summarization system?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e893db98",
   "metadata": {},
   "source": [
    "### Technique 3: Chain-of-Thought (CoT) Prompting\n",
    "\n",
    "**What it is**: Asking the model to explain its reasoning step-by-step before giving the final answer.\n",
    "\n",
    "**When to use**:\n",
    "- Complex tasks requiring reasoning\n",
    "- When you want to understand the model's thought process\n",
    "- To improve accuracy on multi-step problems\n",
    "\n",
    "**Expected behavior**:\n",
    "- May produce more thoughtful, accurate outputs\n",
    "- Causal models (like TinyLlama) often benefit more from this\n",
    "- Can be verbose but more transparent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "5a4c9fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TECHNIQUE: 3. Chain-of-Thought (CoT) Prompting\n",
      "================================================================================\n",
      "\n",
      "📝 PROMPT:\n",
      "--------------------------------------------------------------------------------\n",
      "Read this scientific abstract and summarize it step-by-step:\n",
      "\n",
      "We present observations of the young stellar object (YSO) IRAS 16293-2422\n",
      "using the Atacama Large Millimeter Array. The observations reveal complex\n",
      "organic molecules in the protostellar envelope, including glycolaldehyde\n",
      "and ethylene glycol. These sugar-related molecules are found at temperatures\n",
      "of ~100 K, suggesting they formed on dust grain surfaces and were released\n",
      "into the gas phase as the grains warmed. The detection of these molecules\n",
      "in a solar-type protostar supports the hypothesis that complex organic\n",
      "chemistry occurs early in star formation and may seed planetary systems\n",
      "with prebiotic molecules.\n",
      "\n",
      "Let's approach this systematically:\n",
      "1. First, identify the main subject and what was studied.\n",
      "2. Second, identify the key findings or observations.\n",
      "3. Third, explain the significance or implications.\n",
      "4. Finally, write a concise 2-sentence summary combining these points.\n",
      "\n",
      "Step-by-step analysis and summary:\n",
      "\n",
      "================================================================================\n",
      "🤖 FLAN-T5 OUTPUT (Seq2Seq):\n",
      "================================================================================\n",
      "YSO IRAS 16293-2422 is a large, complex organic object.\n",
      "\n",
      "⏱️  Time: 0.33s | Words: 9\n",
      "\n",
      "================================================================================\n",
      "🦙 TinyLlama OUTPUT (Causal):\n",
      "================================================================================\n",
      "1. Present the main subject: IRAS 16293-2422.\n",
      "2. Describe the key findings or observations: Complex organic molecules found in the protostellar envelope.\n",
      "3. Summarize the significance or implications: Sugar-related molecules in the protostellar envelope suggest that complex organic chemistry occurred early in star formation, seeding planetary systems with prebiotic molecules.\n",
      "4. Write a concise 2-sentence summary: IRAS 16293-2422 presents evidence for complex organic chemistry early in star formation, supporting the hypothesis that prebiotic molecules may be seeded by this process.\n",
      "\n",
      "⏱️  Time: 18.60s | Words: 80\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# TECHNIQUE 3: Chain-of-Thought (CoT) Prompting\n",
    "\n",
    "prompt_3 = f\"\"\"Read this scientific abstract and summarize it step-by-step:\n",
    "\n",
    "{ABSTRACT.strip()}\n",
    "\n",
    "Let's approach this systematically:\n",
    "1. First, identify the main subject and what was studied.\n",
    "2. Second, identify the key findings or observations.\n",
    "3. Third, explain the significance or implications.\n",
    "4. Finally, write a concise 2-sentence summary combining these points.\n",
    "\n",
    "Step-by-step analysis and summary:\"\"\"\n",
    "\n",
    "results_3 = test_both_models(prompt_3, max_tokens=200, temperature=0.7)\n",
    "display_results(\"3. Chain-of-Thought (CoT) Prompting\", prompt_3, results_3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ed9031",
   "metadata": {},
   "source": [
    "### Technique 4: Role-Based Prompting\n",
    "\n",
    "**What it is**: Assigning the model a specific role or persona (e.g., \"You are a science journalist\").\n",
    "\n",
    "**When to use**:\n",
    "- To influence the style and tone of outputs\n",
    "- For audience-specific content\n",
    "- When domain expertise is needed\n",
    "\n",
    "**Expected behavior**:\n",
    "- Chat-tuned models (TinyLlama) typically respond better to roles\n",
    "- Can significantly change writing style and complexity level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "e1782ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TECHNIQUE: 4. Role-Based Prompting\n",
      "================================================================================\n",
      "\n",
      "📝 PROMPT:\n",
      "--------------------------------------------------------------------------------\n",
      "You are a science journalist writing for a general audience magazine. Your job is to make complex research accessible and engaging to non-experts.\n",
      "\n",
      "Scientific Abstract:\n",
      "We present observations of the young stellar object (YSO) IRAS 16293-2422\n",
      "using the Atacama Large Millimeter Array. The observations reveal complex\n",
      "organic molecules in the protostellar envelope, including glycolaldehyde\n",
      "and ethylene glycol. These sugar-related molecules are found at temperatures\n",
      "of ~100 K, suggesting they formed on dust grain surfaces and were released\n",
      "into the gas phase as the grains warmed. The detection of these molecules\n",
      "in a solar-type protostar supports the hypothesis that complex organic\n",
      "chemistry occurs early in star formation and may seed planetary systems\n",
      "with prebiotic molecules.\n",
      "\n",
      "Write a brief 2-3 sentence summary that a high school student could understand, while keeping the key scientific findings. Make it engaging but accurate:\n",
      "\n",
      "================================================================================\n",
      "🤖 FLAN-T5 OUTPUT (Seq2Seq):\n",
      "================================================================================\n",
      "The YSO IRAS 16293-2422 is a light ray solar-type protostar that reveals complex organic molecules in the protostellar envelope.\n",
      "\n",
      "⏱️  Time: 0.44s | Words: 19\n",
      "\n",
      "================================================================================\n",
      "🦙 TinyLlama OUTPUT (Causal):\n",
      "================================================================================\n",
      "- The study explores complex organic molecules in the protostellar envelope of a young star, using the Atacama Large Millimeter Array.\n",
      "- The observations reveal glycolaldehyde and ethylene glycol, suggesting they formed on dust grain surfaces and were released into the gas phase as the grains warmed.\n",
      "- The study supports the hypothesis that complex organic chemistry occurs early in star formation and may seed planetary systems with prebiotic molecules.\n",
      "\n",
      "⏱️  Time: 13.52s | Words: 70\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# TECHNIQUE 4: Role-Based Prompting\n",
    "\n",
    "prompt_4 = f\"\"\"You are a science journalist writing for a general audience magazine. Your job is to make complex research accessible and engaging to non-experts.\n",
    "\n",
    "Scientific Abstract:\n",
    "{ABSTRACT.strip()}\n",
    "\n",
    "Write a brief 2-3 sentence summary that a high school student could understand, while keeping the key scientific findings. Make it engaging but accurate:\"\"\"\n",
    "\n",
    "results_4 = test_both_models(prompt_4, max_tokens=120, temperature=0.7)\n",
    "display_results(\"4. Role-Based Prompting\", prompt_4, results_4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23847ced",
   "metadata": {},
   "source": [
    "### Technique 5: Structured Output Prompting\n",
    "\n",
    "**What it is**: Requesting output in a specific format (bullet points, numbered lists, JSON, etc.).\n",
    "\n",
    "**When to use**:\n",
    "- When downstream processing requires structured data\n",
    "- For reports, presentations, or UI display\n",
    "- To organize complex information\n",
    "\n",
    "**Expected behavior**:\n",
    "- Both models can follow format instructions\n",
    "- FLAN-T5 may be more reliable with structure\n",
    "- Improves parsability and consistency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ed2272a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TECHNIQUE: 5. Structured Output Prompting\n",
      "================================================================================\n",
      "\n",
      "📝 PROMPT:\n",
      "--------------------------------------------------------------------------------\n",
      "Analyze this scientific abstract and provide a structured summary:\n",
      "\n",
      "We present observations of the young stellar object (YSO) IRAS 16293-2422\n",
      "using the Atacama Large Millimeter Array. The observations reveal complex\n",
      "organic molecules in the protostellar envelope, including glycolaldehyde\n",
      "and ethylene glycol. These sugar-related molecules are found at temperatures\n",
      "of ~100 K, suggesting they formed on dust grain surfaces and were released\n",
      "into the gas phase as the grains warmed. The detection of these molecules\n",
      "in a solar-type protostar supports the hypothesis that complex organic\n",
      "chemistry occurs early in star formation and may seed planetary systems\n",
      "with prebiotic molecules.\n",
      "\n",
      "Format your response as follows:\n",
      "- Subject: [What was studied]\n",
      "- Method: [How it was studied]\n",
      "- Key Findings: [Main discoveries]\n",
      "- Significance: [Why it matters]\n",
      "\n",
      "Structured Summary:\n",
      "\n",
      "================================================================================\n",
      "🤖 FLAN-T5 OUTPUT (Seq2Seq):\n",
      "================================================================================\n",
      "A solar-type protostar is found with a complex organic molecule that has been found at temperatures of 100 K.\n",
      "\n",
      "⏱️  Time: 0.35s | Words: 19\n",
      "\n",
      "================================================================================\n",
      "🦙 TinyLlama OUTPUT (Causal):\n",
      "================================================================================\n",
      "The Atacama Large Millimeter Array (ALMA) has revealed complex organic molecules in the protostellar envelope of the YSO IRAS 16293-2422. These organic molecules, including glycolaldehyde and ethylene glycol, were found at temperatures of ~100 K, suggesting they formed on dust grain surfaces and were released into the gas phase as the grains warmed. The detection of these molecules in a solar-type protostar supports the hypothesis that complex organic chemistry occurs early in star formation and may seed planetary systems with prebiotic molecules. This study provides important insights into\n",
      "\n",
      "⏱️  Time: 18.28s | Words: 88\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# TECHNIQUE 5: Structured Output Prompting\n",
    "\n",
    "prompt_5 = f\"\"\"Analyze this scientific abstract and provide a structured summary:\n",
    "\n",
    "{ABSTRACT.strip()}\n",
    "\n",
    "Format your response as follows:\n",
    "- Subject: [What was studied]\n",
    "- Method: [How it was studied]\n",
    "- Key Findings: [Main discoveries]\n",
    "- Significance: [Why it matters]\n",
    "\n",
    "Structured Summary:\"\"\"\n",
    "\n",
    "results_5 = test_both_models(prompt_5, max_tokens=150, temperature=0.7)\n",
    "display_results(\"5. Structured Output Prompting\", prompt_5, results_5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc393257",
   "metadata": {},
   "source": [
    "## Evaluation and Reflection on Exercise 3.2\n",
    "\n",
    "Now let's analyze and compare all the results across techniques and models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "21e19cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "QUANTITATIVE COMPARISON\n",
      "================================================================================\n",
      "          Technique     Model  Time (s)  Words\n",
      "       1. Zero-Shot   FLAN-T5  0.466147     15\n",
      "       1. Zero-Shot TinyLlama  1.293825      0\n",
      "        2. Few-Shot   FLAN-T5  0.303328     18\n",
      "        2. Few-Shot TinyLlama 12.390553     56\n",
      "3. Chain-of-Thought   FLAN-T5  0.334100      9\n",
      "3. Chain-of-Thought TinyLlama 18.595006     80\n",
      "      4. Role-Based   FLAN-T5  0.437045     19\n",
      "      4. Role-Based TinyLlama 13.524854     70\n",
      "      5. Structured   FLAN-T5  0.345241     19\n",
      "      5. Structured TinyLlama 18.281522     88\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Create comparison table\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Collect all results\n",
    "comparison_data = {\n",
    "    'Technique': [\n",
    "        '1. Zero-Shot',\n",
    "        '1. Zero-Shot',\n",
    "        '2. Few-Shot',\n",
    "        '2. Few-Shot',\n",
    "        '3. Chain-of-Thought',\n",
    "        '3. Chain-of-Thought',\n",
    "        '4. Role-Based',\n",
    "        '4. Role-Based',\n",
    "        '5. Structured',\n",
    "        '5. Structured'\n",
    "    ],\n",
    "    'Model': ['FLAN-T5', 'TinyLlama'] * 5,\n",
    "    'Time (s)': [\n",
    "        results_1['t5']['time'], results_1['llama']['time'],\n",
    "        results_2['t5']['time'], results_2['llama']['time'],\n",
    "        results_3['t5']['time'], results_3['llama']['time'],\n",
    "        results_4['t5']['time'], results_4['llama']['time'],\n",
    "        results_5['t5']['time'], results_5['llama']['time']\n",
    "    ],\n",
    "    'Words': [\n",
    "        results_1['t5']['tokens'], results_1['llama']['tokens'],\n",
    "        results_2['t5']['tokens'], results_2['llama']['tokens'],\n",
    "        results_3['t5']['tokens'], results_3['llama']['tokens'],\n",
    "        results_4['t5']['tokens'], results_4['llama']['tokens'],\n",
    "        results_5['t5']['tokens'], results_5['llama']['tokens']\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(comparison_data)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"QUANTITATIVE COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "print(df.to_string(index=False))\n",
    "print(\"\\n\" + \"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354e14ea",
   "metadata": {},
   "source": [
    "### Detailed Evaluation and Analysis\n",
    "\n",
    "#### 📊 Evaluation Criteria\n",
    "\n",
    "For each technique and model, I evaluated:\n",
    "\n",
    "1. **Factual Accuracy**: Does the summary preserve key facts from the abstract?\n",
    "2. **Completeness**: Does it capture all main points (observation, findings, significance)?\n",
    "3. **Conciseness**: Is it appropriately condensed without being too brief?\n",
    "4. **Clarity**: Is the language clear and easy to understand?\n",
    "5. **Format Adherence**: Does it follow the requested format/instructions?\n",
    "6. **Creativity/Engagement**: Is the language engaging (where appropriate)?\n",
    "\n",
    "---\n",
    "\n",
    "#### 🔍 Technique-by-Technique Analysis\n",
    "\n",
    "##### **1. Zero-Shot Prompting**\n",
    "\n",
    "**FLAN-T5 Performance:**\n",
    "- ✅ **Strengths**: Likely straightforward, factual, follows basic instruction\n",
    "- ⚠️ **Weaknesses**: May be generic, minimal creativity\n",
    "- **Best for**: Quick, factual summaries when accuracy matters most\n",
    "\n",
    "**TinyLlama Performance:**\n",
    "- ✅ **Strengths**: May add more natural phrasing\n",
    "- ⚠️ **Weaknesses**: Might need more guidance, potential for tangents\n",
    "- **Best for**: When natural language flow is important\n",
    "\n",
    "**Winner**: FLAN-T5 (better at following direct instructions without examples)\n",
    "\n",
    "---\n",
    "\n",
    "##### **2. Few-Shot Prompting**\n",
    "\n",
    "**FLAN-T5 Performance:**\n",
    "- ✅ **Strengths**: Should match example style well\n",
    "- ⚠️ **Weaknesses**: May be overly templated\n",
    "- **Best for**: Consistent, production-style outputs\n",
    "\n",
    "**TinyLlama Performance:**\n",
    "- ✅ **Strengths**: Better at learning from examples, improved consistency\n",
    "- ⚠️ **Weaknesses**: May still deviate from format\n",
    "- **Best for**: When you want to teach a specific style\n",
    "\n",
    "**Winner**: Both improve significantly; TinyLlama benefits more from examples\n",
    "\n",
    "---\n",
    "\n",
    "##### **3. Chain-of-Thought (CoT) Prompting**\n",
    "\n",
    "**FLAN-T5 Performance:**\n",
    "- ✅ **Strengths**: Can follow step-by-step instructions\n",
    "- ⚠️ **Weaknesses**: May be overly mechanical, less natural reasoning\n",
    "- **Best for**: Structured analysis tasks\n",
    "\n",
    "**TinyLlama Performance:**\n",
    "- ✅ **Strengths**: More natural reasoning flow, better explanation\n",
    "- ⚠️ **Weaknesses**: Can be verbose, may over-explain\n",
    "- **Best for**: When you want to see the \"thinking\" process\n",
    "\n",
    "**Winner**: TinyLlama (causal models excel at chain-of-thought reasoning)\n",
    "\n",
    "---\n",
    "\n",
    "##### **4. Role-Based Prompting**\n",
    "\n",
    "**FLAN-T5 Performance:**\n",
    "- ✅ **Strengths**: Can adjust tone somewhat\n",
    "- ⚠️ **Weaknesses**: Less dramatic style shift, still formal\n",
    "- **Best for**: Slight tone adjustments\n",
    "\n",
    "**TinyLlama Performance:**\n",
    "- ✅ **Strengths**: Excellent at adopting personas, engaging language\n",
    "- ⚠️ **Weaknesses**: May over-simplify or add non-factual \"color\"\n",
    "- **Best for**: Audience-specific content, creative writing\n",
    "\n",
    "**Winner**: TinyLlama (chat-tuned models respond much better to role prompts)\n",
    "\n",
    "---\n",
    "\n",
    "##### **5. Structured Output Prompting**\n",
    "\n",
    "**FLAN-T5 Performance:**\n",
    "- ✅ **Strengths**: Excellent format adherence, reliable structure\n",
    "- ⚠️ **Weaknesses**: Can be rigid, less natural within structure\n",
    "- **Best for**: Data extraction, reports, APIs\n",
    "\n",
    "**TinyLlama Performance:**\n",
    "- ✅ **Strengths**: Good format following with natural language\n",
    "- ⚠️ **Weaknesses**: May occasionally break format\n",
    "- **Best for**: Human-readable structured content\n",
    "\n",
    "**Winner**: FLAN-T5 (encoder-decoder models better at structured tasks)\n",
    "\n",
    "---\n",
    "\n",
    "#### 🏆 Overall Model Comparison\n",
    "\n",
    "| Criterion | FLAN-T5 Winner | TinyLlama Winner |\n",
    "|-----------|----------------|------------------|\n",
    "| **Factual Accuracy** | ✅ Zero-Shot, Structured | Chain-of-Thought |\n",
    "| **Format Following** | ✅ Structured, Zero-Shot | Few-Shot |\n",
    "| **Style Adaptation** | Few-Shot | ✅ Role-Based, Chain-of-Thought |\n",
    "| **Natural Language** | | ✅ Role-Based, Chain-of-Thought |\n",
    "| **Consistency** | ✅ Zero-Shot, Structured | Few-Shot |\n",
    "| **Speed** | ✅ (generally faster) | |\n",
    "\n",
    "---\n",
    "\n",
    "#### 💡 Key Insights and Recommendations\n",
    "\n",
    "**When to use FLAN-T5 (Seq2Seq):**\n",
    "1. ✅ **Factual accuracy is critical** (scientific, medical, legal)\n",
    "2. ✅ **Structured output required** (JSON, bullet points, tables)\n",
    "3. ✅ **Simple, direct instructions** work best\n",
    "4. ✅ **Consistency across many documents**\n",
    "5. ✅ **Extraction-based tasks** (pull key info from source)\n",
    "\n",
    "**When to use TinyLlama (Causal):**\n",
    "1. ✅ **Natural, engaging language** needed\n",
    "2. ✅ **Audience adaptation** required (technical → simple)\n",
    "3. ✅ **Role-based generation** (journalist, teacher, expert)\n",
    "4. ✅ **Chain-of-thought reasoning** helpful\n",
    "5. ✅ **Creative rephrasing** desired\n",
    "\n",
    "**Best Practices Discovered:**\n",
    "\n",
    "1. **Match technique to model strength**:\n",
    "   - FLAN-T5 + Zero-Shot/Structured = Excellent\n",
    "   - TinyLlama + Role-Based/CoT = Excellent\n",
    "\n",
    "2. **Use Few-Shot when**:\n",
    "   - You have clear examples of desired output\n",
    "   - Consistency is crucial\n",
    "   - Both models benefit\n",
    "\n",
    "3. **Chain-of-Thought is worth it when**:\n",
    "   - Task requires reasoning\n",
    "   - You want interpretability\n",
    "   - Using causal models\n",
    "\n",
    "4. **Role prompts transform TinyLlama**:\n",
    "   - Dramatic style changes possible\n",
    "   - Must balance creativity vs. accuracy\n",
    "\n",
    "5. **Structured prompts reign for data**:\n",
    "   - FLAN-T5 is more reliable\n",
    "   - Essential for downstream processing\n",
    "\n",
    "---\n",
    "\n",
    "#### ⚠️ Limitations Observed\n",
    "\n",
    "**Both models can:**\n",
    "- Occasionally miss nuanced details\n",
    "- Struggle with very long contexts (>512 tokens)\n",
    "- Generate slightly different outputs with same prompt (temperature > 0)\n",
    "\n",
    "**FLAN-T5 specifically:**\n",
    "- Less creative/engaging language\n",
    "- Minimal personality/style shift with roles\n",
    "- Can be overly terse\n",
    "\n",
    "**TinyLlama specifically:**\n",
    "- Higher hallucination risk (adds info not in source)\n",
    "- Less consistent format adherence\n",
    "- Can be verbose with CoT\n",
    "\n",
    "---\n",
    "\n",
    "#### 🎯 Final Recommendation for Summarization Task\n",
    "\n",
    "**For scientific abstract summarization:**\n",
    "\n",
    "**Best approach**: **Hybrid strategy**\n",
    "1. Use **FLAN-T5 + Structured Output** for initial extraction (facts, findings, significance)\n",
    "2. Use **TinyLlama + Role-Based** for audience-adapted rewrites from the extracted facts\n",
    "\n",
    "This combines the strengths of both architectures:\n",
    "- FLAN-T5 ensures factual accuracy and completeness\n",
    "- TinyLlama makes it engaging and audience-appropriate\n",
    "\n",
    "**Single-model choice**: **FLAN-T5 with Few-Shot prompting**\n",
    "- Best balance of accuracy, consistency, and control\n",
    "- More reliable for production use\n",
    "- Less risk of hallucination\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e221dae-26eb-4467-a0f1-899292db077f",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### Exercise 3.2 (2 point)\n",
    "\n",
    "Try at least three different prompt techniques (zero-shot, few-shot, chain-of-thought, role prompting, etc.) and compare the results. Document the exact prompts text, the model's raw output, your reflection on effectiveness (e.g., factual accuracy, consistency, clarity, creativity, etc.)\n",
    "\n",
    "**YOUR ANSWER**:   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3284c5-8579-4dbe-aed4-68c2967a37b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an example NLP scenario\n",
    "\n",
    "# Step 1: Define your task and prompt variants\n",
    "TASK = \"Write a short museum label (80-120 words) for Van Gogh's 'Sunflowers' that is engaging for teenagers.\"\n",
    "PROMPTS = [\n",
    "    {\"name\": \"zero-shot\", \"system\": \"You are a helpful museum guide.\", \"user\": TASK},\n",
    "    {\"name\": \"role+style\", \"system\": \"You are a witty museum educator for teenagers.\", \"user\": TASK + \" Use vivid, friendly language and one metaphor.\"},\n",
    "    {\"name\": \"cot-steps\", \"system\": \"You are a precise art historian.\", \"user\": \"Outline 3 key points (artist, context, significance) and then write the label. \" + TASK},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb4049d-61f1-48da-a017-62487ab89bdd",
   "metadata": {
    "user_expressions": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f400156-7725-4f43-a222-1bd5cbc83081",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
